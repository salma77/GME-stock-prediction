{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading data\n",
    "GME = pd.read_csv(\"GME.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-21</td>\n",
       "      <td>4.75</td>\n",
       "      <td>4.75</td>\n",
       "      <td>4.55</td>\n",
       "      <td>4.59</td>\n",
       "      <td>4.59</td>\n",
       "      <td>3532100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>4.55</td>\n",
       "      <td>4.64</td>\n",
       "      <td>4.46</td>\n",
       "      <td>4.56</td>\n",
       "      <td>4.56</td>\n",
       "      <td>2627500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>4.55</td>\n",
       "      <td>4.64</td>\n",
       "      <td>4.46</td>\n",
       "      <td>4.62</td>\n",
       "      <td>4.62</td>\n",
       "      <td>1880200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2020-01-24</td>\n",
       "      <td>4.64</td>\n",
       "      <td>4.64</td>\n",
       "      <td>4.25</td>\n",
       "      <td>4.32</td>\n",
       "      <td>4.32</td>\n",
       "      <td>4163600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2020-01-27</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.35</td>\n",
       "      <td>4.16</td>\n",
       "      <td>4.28</td>\n",
       "      <td>4.28</td>\n",
       "      <td>2122500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Open  High   Low  Close  Adj Close   Volume\n",
       "0  2020-01-21  4.75  4.75  4.55   4.59       4.59  3532100\n",
       "1  2020-01-22  4.55  4.64  4.46   4.56       4.56  2627500\n",
       "2  2020-01-23  4.55  4.64  4.46   4.62       4.62  1880200\n",
       "3  2020-01-24  4.64  4.64  4.25   4.32       4.32  4163600\n",
       "4  2020-01-27  4.20  4.35  4.16   4.28       4.28  2122500"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GME.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note:* we only need the Date and Close columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "GME = GME[['Date', 'Close']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-21</td>\n",
       "      <td>4.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>4.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>4.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2020-01-24</td>\n",
       "      <td>4.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2020-01-27</td>\n",
       "      <td>4.28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Close\n",
       "0  2020-01-21   4.59\n",
       "1  2020-01-22   4.56\n",
       "2  2020-01-23   4.62\n",
       "3  2020-01-24   4.32\n",
       "4  2020-01-27   4.28"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GME.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 257 entries, 0 to 256\n",
      "Data columns (total 2 columns):\n",
      "Date     257 non-null object\n",
      "Close    257 non-null float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 4.1+ KB\n"
     ]
    }
   ],
   "source": [
    "GME.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Prog\\Anaconda2019\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#Converting date column into datetime \n",
    "GME.Time = pd.to_datetime(GME.Date, format = '%Y/%m/%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot of the GME stock price dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_GME = GME.set_index('Date')\n",
    "plot_GME['Close'].plot(figsize=(20,5));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_GME = GME.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>252</td>\n",
       "      <td>2021-01-20</td>\n",
       "      <td>39.119999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>253</td>\n",
       "      <td>2021-01-21</td>\n",
       "      <td>43.029999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>254</td>\n",
       "      <td>2021-01-22</td>\n",
       "      <td>65.010002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>255</td>\n",
       "      <td>2021-01-25</td>\n",
       "      <td>76.790001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>256</td>\n",
       "      <td>2021-01-26</td>\n",
       "      <td>147.979996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date       Close\n",
       "252  2021-01-20   39.119999\n",
       "253  2021-01-21   43.029999\n",
       "254  2021-01-22   65.010002\n",
       "255  2021-01-25   76.790001\n",
       "256  2021-01-26  147.979996"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_GME.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date     0\n",
      "Close    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(new_GME.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_GME = new_GME.drop('Date', axis=1)\n",
    "new_GME = new_GME.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4.28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Close\n",
       "0   4.59\n",
       "1   4.56\n",
       "2   4.62\n",
       "3   4.32\n",
       "4   4.28"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_GME.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = new_GME.values\n",
    "T = T.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = T[~np.isnan(T)]\n",
    "T = np.reshape(T, (-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Min-max Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "T = scaler.fit_transform(T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test/Train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(T)*0.8)\n",
    "test_size = int(len(T)-train_size)\n",
    "train = T[0:train_size, :]\n",
    "test = T[train_size: , :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method for creating features for the time series data\n",
    "def create_features(data, window_size):\n",
    "    X, Y = [], []\n",
    "    for i in range(len(data) - window_size - 1):\n",
    "        window = data[i:(i + window_size), 0]\n",
    "        X.append(window)\n",
    "        Y.append(data[i + window_size, 0])\n",
    "    return np.array(X), np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assuming 5 trading days per week\n",
    "window_size = 20\n",
    "X_train, Y_train = create_features(train, window_size)\n",
    "\n",
    "X_test, Y_test = create_features(test, window_size)\n",
    "\n",
    "#Reshaping to the format of [samples, time steps, features] (the format that lstm needs)\n",
    "\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "#To check for a data leak\n",
    "def isLeak(T_shape, train_shape, test_shape):\n",
    "    return not(T_shape[0] == (train_shape[0] + test_shape[0]))\n",
    "\n",
    "print(isLeak(T.shape, train.shape, test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the LSTM RNN Model\n",
    "Below, we build a LSTM model that consists of one LSTM layer with a density of 50 neurons and a RELU activation function, as well as a Dropout regularization layer. We add a model checkpoint that is looking to minimize the validation set's loss. We save each model that consists of a lower validation loss compared to any model that came before it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting seed\n",
    "tf.random.set_seed(11)\n",
    "np.random.seed(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(units=50, activation='relu', input_shape=(X_train.shape[1], window_size)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "os.system(\"mkdir GME1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 184 samples, validate on 31 samples\n",
      "Epoch 1/3000\n",
      "184/184 [==============================] - 1s 7ms/step - loss: 5.8996e-04 - val_loss: 0.0255\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.02548, saving model to ./model_epoch_01.hdf5\n",
      "Epoch 2/3000\n",
      "184/184 [==============================] - 0s 81us/step - loss: 3.9002e-04 - val_loss: 0.0231\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.02548 to 0.02309, saving model to ./model_epoch_02.hdf5\n",
      "Epoch 3/3000\n",
      "184/184 [==============================] - ETA: 0s - loss: 3.1914e-0 - 0s 81us/step - loss: 2.8604e-04 - val_loss: 0.0209\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.02309 to 0.02091, saving model to ./model_epoch_03.hdf5\n",
      "Epoch 4/3000\n",
      "184/184 [==============================] - 0s 81us/step - loss: 2.3304e-04 - val_loss: 0.0190\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.02091 to 0.01901, saving model to ./model_epoch_04.hdf5\n",
      "Epoch 5/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.0856e-04 - val_loss: 0.0174\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.01901 to 0.01740, saving model to ./model_epoch_05.hdf5\n",
      "Epoch 6/3000\n",
      "184/184 [==============================] - 0s 81us/step - loss: 2.4462e-04 - val_loss: 0.0161\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.01740 to 0.01612, saving model to ./model_epoch_06.hdf5\n",
      "Epoch 7/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.8021e-04 - val_loss: 0.0151\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.01612 to 0.01514, saving model to ./model_epoch_07.hdf5\n",
      "Epoch 8/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.9521e-04 - val_loss: 0.0144\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.01514 to 0.01442, saving model to ./model_epoch_08.hdf5\n",
      "Epoch 9/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 3.0804e-04 - val_loss: 0.0139\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.01442 to 0.01394, saving model to ./model_epoch_09.hdf5\n",
      "Epoch 10/3000\n",
      "184/184 [==============================] - 0s 136us/step - loss: 3.1092e-04 - val_loss: 0.0137\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.01394 to 0.01366, saving model to ./model_epoch_10.hdf5\n",
      "Epoch 11/3000\n",
      "184/184 [==============================] - 0s 147us/step - loss: 2.9222e-04 - val_loss: 0.0135\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.01366 to 0.01351, saving model to ./model_epoch_11.hdf5\n",
      "Epoch 12/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.5821e-04 - val_loss: 0.0134\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.01351 to 0.01343, saving model to ./model_epoch_12.hdf5\n",
      "Epoch 13/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.3868e-04 - val_loss: 0.0134\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.01343 to 0.01336, saving model to ./model_epoch_13.hdf5\n",
      "Epoch 14/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.0033e-04 - val_loss: 0.0133\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.01336 to 0.01327, saving model to ./model_epoch_14.hdf5\n",
      "Epoch 15/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 1.8037e-04 - val_loss: 0.0131\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.01327 to 0.01313, saving model to ./model_epoch_15.hdf5\n",
      "Epoch 16/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 1.6363e-04 - val_loss: 0.0129\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.01313 to 0.01293, saving model to ./model_epoch_16.hdf5\n",
      "Epoch 17/3000\n",
      "184/184 [==============================] - 0s 174us/step - loss: 1.5035e-04 - val_loss: 0.0126\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.01293 to 0.01264, saving model to ./model_epoch_17.hdf5\n",
      "Epoch 18/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 1.3673e-04 - val_loss: 0.0123\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.01264 to 0.01233, saving model to ./model_epoch_18.hdf5\n",
      "Epoch 19/3000\n",
      "184/184 [==============================] - 0s 130us/step - loss: 1.3225e-04 - val_loss: 0.0120\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.01233 to 0.01203, saving model to ./model_epoch_19.hdf5\n",
      "Epoch 20/3000\n",
      "184/184 [==============================] - 0s 261us/step - loss: 1.3510e-04 - val_loss: 0.0117\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.01203 to 0.01169, saving model to ./model_epoch_20.hdf5\n",
      "Epoch 21/3000\n",
      "184/184 [==============================] - 0s 217us/step - loss: 1.2204e-04 - val_loss: 0.0113\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.01169 to 0.01133, saving model to ./model_epoch_21.hdf5\n",
      "Epoch 22/3000\n",
      "184/184 [==============================] - 0s 310us/step - loss: 1.1521e-04 - val_loss: 0.0110\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.01133 to 0.01097, saving model to ./model_epoch_22.hdf5\n",
      "Epoch 23/3000\n",
      "184/184 [==============================] - 0s 119us/step - loss: 1.1562e-04 - val_loss: 0.0106\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.01097 to 0.01063, saving model to ./model_epoch_23.hdf5\n",
      "Epoch 24/3000\n",
      "184/184 [==============================] - 0s 141us/step - loss: 1.2180e-04 - val_loss: 0.0103\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.01063 to 0.01034, saving model to ./model_epoch_24.hdf5\n",
      "Epoch 25/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 1.0461e-04 - val_loss: 0.0101\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.01034 to 0.01013, saving model to ./model_epoch_25.hdf5\n",
      "Epoch 26/3000\n",
      "184/184 [==============================] - 0s 277us/step - loss: 1.0579e-04 - val_loss: 0.0100\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.01013 to 0.00997, saving model to ./model_epoch_26.hdf5\n",
      "Epoch 27/3000\n",
      "184/184 [==============================] - 0s 174us/step - loss: 9.4760e-05 - val_loss: 0.0098\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.00997 to 0.00981, saving model to ./model_epoch_27.hdf5\n",
      "Epoch 28/3000\n",
      "184/184 [==============================] - 0s 196us/step - loss: 9.4339e-05 - val_loss: 0.0096\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.00981 to 0.00965, saving model to ./model_epoch_28.hdf5\n",
      "Epoch 29/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 8.1567e-05 - val_loss: 0.0095\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.00965 to 0.00949, saving model to ./model_epoch_29.hdf5\n",
      "Epoch 30/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 7.5992e-05 - val_loss: 0.0093\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.00949 to 0.00931, saving model to ./model_epoch_30.hdf5\n",
      "Epoch 31/3000\n",
      "184/184 [==============================] - 0s 81us/step - loss: 9.4390e-05 - val_loss: 0.0091\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.00931 to 0.00911, saving model to ./model_epoch_31.hdf5\n",
      "Epoch 32/3000\n",
      "184/184 [==============================] - 0s 179us/step - loss: 7.9427e-05 - val_loss: 0.0089\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.00911 to 0.00889, saving model to ./model_epoch_32.hdf5\n",
      "Epoch 33/3000\n",
      "184/184 [==============================] - ETA: 0s - loss: 5.3462e-0 - 0s 212us/step - loss: 8.1205e-05 - val_loss: 0.0087\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.00889 to 0.00869, saving model to ./model_epoch_33.hdf5\n",
      "Epoch 34/3000\n",
      "184/184 [==============================] - 0s 157us/step - loss: 8.0497e-05 - val_loss: 0.0085\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.00869 to 0.00850, saving model to ./model_epoch_34.hdf5\n",
      "Epoch 35/3000\n",
      "184/184 [==============================] - 0s 190us/step - loss: 7.6978e-05 - val_loss: 0.0084\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.00850 to 0.00835, saving model to ./model_epoch_35.hdf5\n",
      "Epoch 36/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 7.6239e-05 - val_loss: 0.0083\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.00835 to 0.00827, saving model to ./model_epoch_36.hdf5\n",
      "Epoch 37/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 6.2814e-05 - val_loss: 0.0082\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.00827 to 0.00823, saving model to ./model_epoch_37.hdf5\n",
      "Epoch 38/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 7.0594e-05 - val_loss: 0.0082\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.00823 to 0.00818, saving model to ./model_epoch_38.hdf5\n",
      "Epoch 39/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 7.2012e-05 - val_loss: 0.0081\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.00818 to 0.00813, saving model to ./model_epoch_39.hdf5\n",
      "Epoch 40/3000\n",
      "184/184 [==============================] - 0s 288us/step - loss: 5.8047e-05 - val_loss: 0.0081\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00040: val_loss improved from 0.00813 to 0.00808, saving model to ./model_epoch_40.hdf5\n",
      "Epoch 41/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 6.4057e-05 - val_loss: 0.0080\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.00808 to 0.00799, saving model to ./model_epoch_41.hdf5\n",
      "Epoch 42/3000\n",
      "184/184 [==============================] - 0s 119us/step - loss: 6.5329e-05 - val_loss: 0.0079\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.00799 to 0.00787, saving model to ./model_epoch_42.hdf5\n",
      "Epoch 43/3000\n",
      "184/184 [==============================] - 0s 141us/step - loss: 5.6625e-05 - val_loss: 0.0078\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.00787 to 0.00777, saving model to ./model_epoch_43.hdf5\n",
      "Epoch 44/3000\n",
      "184/184 [==============================] - 0s 119us/step - loss: 5.4594e-05 - val_loss: 0.0077\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.00777 to 0.00770, saving model to ./model_epoch_44.hdf5\n",
      "Epoch 45/3000\n",
      "184/184 [==============================] - 0s 81us/step - loss: 7.2647e-05 - val_loss: 0.0077\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.00770 to 0.00768, saving model to ./model_epoch_45.hdf5\n",
      "Epoch 46/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 6.0584e-05 - val_loss: 0.0077\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.00768\n",
      "Epoch 47/3000\n",
      "184/184 [==============================] - 0s 310us/step - loss: 6.0282e-05 - val_loss: 0.0077\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.00768 to 0.00767, saving model to ./model_epoch_47.hdf5\n",
      "Epoch 48/3000\n",
      "184/184 [==============================] - 0s 456us/step - loss: 5.8617e-05 - val_loss: 0.0077\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.00767 to 0.00766, saving model to ./model_epoch_48.hdf5\n",
      "Epoch 49/3000\n",
      "184/184 [==============================] - 0s 185us/step - loss: 6.7383e-05 - val_loss: 0.0076\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.00766 to 0.00763, saving model to ./model_epoch_49.hdf5\n",
      "Epoch 50/3000\n",
      "184/184 [==============================] - 0s 168us/step - loss: 6.6827e-05 - val_loss: 0.0076\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.00763 to 0.00756, saving model to ./model_epoch_50.hdf5\n",
      "Epoch 51/3000\n",
      "184/184 [==============================] - 0s 158us/step - loss: 5.7090e-05 - val_loss: 0.0074\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.00756 to 0.00742, saving model to ./model_epoch_51.hdf5\n",
      "Epoch 52/3000\n",
      "184/184 [==============================] - ETA: 0s - loss: 3.1188e-0 - 0s 299us/step - loss: 6.9748e-05 - val_loss: 0.0073\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.00742 to 0.00730, saving model to ./model_epoch_52.hdf5\n",
      "Epoch 53/3000\n",
      "184/184 [==============================] - 0s 174us/step - loss: 6.1392e-05 - val_loss: 0.0073\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.00730 to 0.00728, saving model to ./model_epoch_53.hdf5\n",
      "Epoch 54/3000\n",
      "184/184 [==============================] - 0s 244us/step - loss: 6.3968e-05 - val_loss: 0.0073\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.00728\n",
      "Epoch 55/3000\n",
      "184/184 [==============================] - 0s 147us/step - loss: 5.0314e-05 - val_loss: 0.0074\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.00728\n",
      "Epoch 56/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 6.2784e-05 - val_loss: 0.0074\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.00728\n",
      "Epoch 57/3000\n",
      "184/184 [==============================] - 0s 141us/step - loss: 6.2167e-05 - val_loss: 0.0074\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.00728\n",
      "Epoch 58/3000\n",
      "184/184 [==============================] - 0s 141us/step - loss: 7.0993e-05 - val_loss: 0.0073\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.00728\n",
      "Epoch 59/3000\n",
      "184/184 [==============================] - 0s 304us/step - loss: 6.0671e-05 - val_loss: 0.0074\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.00728\n",
      "Epoch 60/3000\n",
      "184/184 [==============================] - 0s 244us/step - loss: 6.0735e-05 - val_loss: 0.0074\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.00728\n",
      "Epoch 61/3000\n",
      "184/184 [==============================] - 0s 174us/step - loss: 6.2098e-05 - val_loss: 0.0073\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.00728\n",
      "Epoch 62/3000\n",
      "184/184 [==============================] - 0s 196us/step - loss: 5.2613e-05 - val_loss: 0.0073\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.00728\n",
      "Epoch 63/3000\n",
      "184/184 [==============================] - 0s 158us/step - loss: 6.1039e-05 - val_loss: 0.0072\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.00728 to 0.00719, saving model to ./model_epoch_63.hdf5\n",
      "Epoch 64/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 5.2779e-05 - val_loss: 0.0071\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.00719 to 0.00709, saving model to ./model_epoch_64.hdf5\n",
      "Epoch 65/3000\n",
      "184/184 [==============================] - 0s 130us/step - loss: 7.5696e-05 - val_loss: 0.0071\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.00709 to 0.00708, saving model to ./model_epoch_65.hdf5\n",
      "Epoch 66/3000\n",
      "184/184 [==============================] - 0s 141us/step - loss: 6.2905e-05 - val_loss: 0.0072\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.00708\n",
      "Epoch 67/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 5.9754e-05 - val_loss: 0.0072\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.00708\n",
      "Epoch 68/3000\n",
      "184/184 [==============================] - 0s 119us/step - loss: 5.0169e-05 - val_loss: 0.0072\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.00708\n",
      "Epoch 69/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 5.1271e-05 - val_loss: 0.0071\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.00708 to 0.00706, saving model to ./model_epoch_69.hdf5\n",
      "Epoch 70/3000\n",
      "184/184 [==============================] - 0s 255us/step - loss: 6.0050e-05 - val_loss: 0.0070\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.00706 to 0.00700, saving model to ./model_epoch_70.hdf5\n",
      "Epoch 71/3000\n",
      "184/184 [==============================] - 0s 217us/step - loss: 5.7082e-05 - val_loss: 0.0070\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.00700 to 0.00698, saving model to ./model_epoch_71.hdf5\n",
      "Epoch 72/3000\n",
      "184/184 [==============================] - 0s 120us/step - loss: 6.5045e-05 - val_loss: 0.0070\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.00698\n",
      "Epoch 73/3000\n",
      "184/184 [==============================] - 0s 244us/step - loss: 6.1772e-05 - val_loss: 0.0070\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.00698\n",
      "Epoch 74/3000\n",
      "184/184 [==============================] - 0s 141us/step - loss: 6.5041e-05 - val_loss: 0.0071\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.00698\n",
      "Epoch 75/3000\n",
      "184/184 [==============================] - 0s 141us/step - loss: 5.0807e-05 - val_loss: 0.0072\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.00698\n",
      "Epoch 76/3000\n",
      "184/184 [==============================] - 0s 158us/step - loss: 4.7792e-05 - val_loss: 0.0072\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.00698\n",
      "Epoch 77/3000\n",
      "184/184 [==============================] - 0s 120us/step - loss: 5.2193e-05 - val_loss: 0.0072\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.00698\n",
      "Epoch 78/3000\n",
      "184/184 [==============================] - 0s 152us/step - loss: 6.2069e-05 - val_loss: 0.0072\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.00698\n",
      "Epoch 79/3000\n",
      "184/184 [==============================] - 0s 223us/step - loss: 5.8941e-05 - val_loss: 0.0071\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.00698\n",
      "Epoch 80/3000\n",
      "184/184 [==============================] - 0s 288us/step - loss: 5.1502e-05 - val_loss: 0.0071\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.00698\n",
      "Epoch 81/3000\n",
      "184/184 [==============================] - 0s 223us/step - loss: 5.2455e-05 - val_loss: 0.0070\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.00698\n",
      "Epoch 82/3000\n",
      "184/184 [==============================] - 0s 174us/step - loss: 5.2748e-05 - val_loss: 0.0069\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.00698 to 0.00695, saving model to ./model_epoch_82.hdf5\n",
      "Epoch 83/3000\n",
      "184/184 [==============================] - 0s 136us/step - loss: 7.0510e-05 - val_loss: 0.0070\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.00695\n",
      "Epoch 84/3000\n",
      "184/184 [==============================] - 0s 130us/step - loss: 5.4967e-05 - val_loss: 0.0071\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.00695\n",
      "Epoch 85/3000\n",
      "184/184 [==============================] - 0s 136us/step - loss: 5.9072e-05 - val_loss: 0.0072\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.00695\n",
      "Epoch 86/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 125us/step - loss: 5.1644e-05 - val_loss: 0.0071\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.00695\n",
      "Epoch 87/3000\n",
      "184/184 [==============================] - 0s 120us/step - loss: 5.0950e-05 - val_loss: 0.0070\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.00695\n",
      "Epoch 88/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 5.9531e-05 - val_loss: 0.0068\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.00695 to 0.00684, saving model to ./model_epoch_88.hdf5\n",
      "Epoch 89/3000\n",
      "184/184 [==============================] - 0s 141us/step - loss: 5.5253e-05 - val_loss: 0.0068\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.00684 to 0.00682, saving model to ./model_epoch_89.hdf5\n",
      "Epoch 90/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 5.4350e-05 - val_loss: 0.0069\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.00682\n",
      "Epoch 91/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 5.0648e-05 - val_loss: 0.0069\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.00682\n",
      "Epoch 92/3000\n",
      "184/184 [==============================] - 0s 277us/step - loss: 4.3691e-05 - val_loss: 0.0069\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.00682\n",
      "Epoch 93/3000\n",
      "184/184 [==============================] - 0s 250us/step - loss: 5.0914e-05 - val_loss: 0.0068\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.00682 to 0.00682, saving model to ./model_epoch_93.hdf5\n",
      "Epoch 94/3000\n",
      "184/184 [==============================] - 0s 174us/step - loss: 4.7321e-05 - val_loss: 0.0067\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.00682 to 0.00674, saving model to ./model_epoch_94.hdf5\n",
      "Epoch 95/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 5.5411e-05 - val_loss: 0.0066\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.00674 to 0.00664, saving model to ./model_epoch_95.hdf5\n",
      "Epoch 96/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 6.1359e-05 - val_loss: 0.0066\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.00664 to 0.00660, saving model to ./model_epoch_96.hdf5\n",
      "Epoch 97/3000\n",
      "184/184 [==============================] - 0s 228us/step - loss: 5.5651e-05 - val_loss: 0.0066\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.00660\n",
      "Epoch 98/3000\n",
      "184/184 [==============================] - 0s 141us/step - loss: 5.5634e-05 - val_loss: 0.0066\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.00660\n",
      "Epoch 99/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 4.8283e-05 - val_loss: 0.0066\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.00660\n",
      "Epoch 100/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 4.7039e-05 - val_loss: 0.0065\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.00660 to 0.00655, saving model to ./model_epoch_100.hdf5\n",
      "Epoch 101/3000\n",
      "184/184 [==============================] - 0s 255us/step - loss: 5.8929e-05 - val_loss: 0.0064\n",
      "\n",
      "Epoch 00101: val_loss improved from 0.00655 to 0.00645, saving model to ./model_epoch_101.hdf5\n",
      "Epoch 102/3000\n",
      "184/184 [==============================] - 0s 239us/step - loss: 4.4937e-05 - val_loss: 0.0064\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.00645 to 0.00640, saving model to ./model_epoch_102.hdf5\n",
      "Epoch 103/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 4.3470e-05 - val_loss: 0.0064\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.00640\n",
      "Epoch 104/3000\n",
      "184/184 [==============================] - ETA: 0s - loss: 2.3447e-0 - 0s 130us/step - loss: 5.0366e-05 - val_loss: 0.0064\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.00640\n",
      "Epoch 105/3000\n",
      "184/184 [==============================] - 0s 152us/step - loss: 4.6810e-05 - val_loss: 0.0065\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.00640\n",
      "Epoch 106/3000\n",
      "184/184 [==============================] - 0s 152us/step - loss: 5.7433e-05 - val_loss: 0.0064\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.00640\n",
      "Epoch 107/3000\n",
      "184/184 [==============================] - 0s 168us/step - loss: 4.9166e-05 - val_loss: 0.0064\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.00640\n",
      "Epoch 108/3000\n",
      "184/184 [==============================] - 0s 147us/step - loss: 5.2128e-05 - val_loss: 0.0065\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.00640\n",
      "Epoch 109/3000\n",
      "184/184 [==============================] - 0s 141us/step - loss: 5.0717e-05 - val_loss: 0.0065\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.00640\n",
      "Epoch 110/3000\n",
      "184/184 [==============================] - 0s 147us/step - loss: 5.4731e-05 - val_loss: 0.0065\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.00640\n",
      "Epoch 111/3000\n",
      "184/184 [==============================] - 0s 293us/step - loss: 5.3338e-05 - val_loss: 0.0065\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.00640\n",
      "Epoch 112/3000\n",
      "184/184 [==============================] - 0s 272us/step - loss: 4.5001e-05 - val_loss: 0.0065\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.00640\n",
      "Epoch 113/3000\n",
      "184/184 [==============================] - 0s 196us/step - loss: 5.0119e-05 - val_loss: 0.0064\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.00640\n",
      "Epoch 114/3000\n",
      "184/184 [==============================] - 0s 168us/step - loss: 4.5603e-05 - val_loss: 0.0064\n",
      "\n",
      "Epoch 00114: val_loss improved from 0.00640 to 0.00635, saving model to ./model_epoch_114.hdf5\n",
      "Epoch 115/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 5.5131e-05 - val_loss: 0.0063\n",
      "\n",
      "Epoch 00115: val_loss improved from 0.00635 to 0.00630, saving model to ./model_epoch_115.hdf5\n",
      "Epoch 116/3000\n",
      "184/184 [==============================] - 0s 130us/step - loss: 5.5161e-05 - val_loss: 0.0063\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.00630\n",
      "Epoch 117/3000\n",
      "184/184 [==============================] - 0s 130us/step - loss: 4.8845e-05 - val_loss: 0.0063\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.00630\n",
      "Epoch 118/3000\n",
      "184/184 [==============================] - 0s 147us/step - loss: 5.3162e-05 - val_loss: 0.0063\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.00630\n",
      "Epoch 119/3000\n",
      "184/184 [==============================] - 0s 147us/step - loss: 5.0950e-05 - val_loss: 0.0064\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.00630\n",
      "Epoch 120/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 5.0930e-05 - val_loss: 0.0064\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.00630\n",
      "Epoch 121/3000\n",
      "184/184 [==============================] - 0s 131us/step - loss: 5.0165e-05 - val_loss: 0.0063\n",
      "\n",
      "Epoch 00121: val_loss improved from 0.00630 to 0.00625, saving model to ./model_epoch_121.hdf5\n",
      "Epoch 122/3000\n",
      "184/184 [==============================] - 0s 299us/step - loss: 4.6267e-05 - val_loss: 0.0061\n",
      "\n",
      "Epoch 00122: val_loss improved from 0.00625 to 0.00613, saving model to ./model_epoch_122.hdf5\n",
      "Epoch 123/3000\n",
      "184/184 [==============================] - 0s 141us/step - loss: 5.3584e-05 - val_loss: 0.0061\n",
      "\n",
      "Epoch 00123: val_loss improved from 0.00613 to 0.00610, saving model to ./model_epoch_123.hdf5\n",
      "Epoch 124/3000\n",
      "184/184 [==============================] - 0s 201us/step - loss: 4.5492e-05 - val_loss: 0.0061\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.00610\n",
      "Epoch 125/3000\n",
      "184/184 [==============================] - 0s 141us/step - loss: 4.2885e-05 - val_loss: 0.0061\n",
      "\n",
      "Epoch 00125: val_loss improved from 0.00610 to 0.00609, saving model to ./model_epoch_125.hdf5\n",
      "Epoch 126/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 4.9720e-05 - val_loss: 0.0060\n",
      "\n",
      "Epoch 00126: val_loss improved from 0.00609 to 0.00602, saving model to ./model_epoch_126.hdf5\n",
      "Epoch 127/3000\n",
      "184/184 [==============================] - 0s 158us/step - loss: 5.1221e-05 - val_loss: 0.0060\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.00602\n",
      "Epoch 128/3000\n",
      "184/184 [==============================] - 0s 169us/step - loss: 4.3817e-05 - val_loss: 0.0061\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.00602\n",
      "Epoch 129/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 4.8690e-05 - val_loss: 0.0061\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.00602\n",
      "Epoch 130/3000\n",
      "184/184 [==============================] - 0s 136us/step - loss: 4.7299e-05 - val_loss: 0.0060\n",
      "\n",
      "Epoch 00130: val_loss improved from 0.00602 to 0.00601, saving model to ./model_epoch_130.hdf5\n",
      "Epoch 131/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 4.2366e-05 - val_loss: 0.0059\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00131: val_loss improved from 0.00601 to 0.00592, saving model to ./model_epoch_131.hdf5\n",
      "Epoch 132/3000\n",
      "184/184 [==============================] - 0s 136us/step - loss: 4.6614e-05 - val_loss: 0.0059\n",
      "\n",
      "Epoch 00132: val_loss improved from 0.00592 to 0.00586, saving model to ./model_epoch_132.hdf5\n",
      "Epoch 133/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 4.8436e-05 - val_loss: 0.0059\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.00586\n",
      "Epoch 134/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 4.0082e-05 - val_loss: 0.0060\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.00586\n",
      "Epoch 135/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 3.9797e-05 - val_loss: 0.0061\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.00586\n",
      "Epoch 136/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 4.3317e-05 - val_loss: 0.0061\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.00586\n",
      "Epoch 137/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 4.2010e-05 - val_loss: 0.0060\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.00586\n",
      "Epoch 138/3000\n",
      "184/184 [==============================] - 0s 147us/step - loss: 4.7235e-05 - val_loss: 0.0060\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.00586\n",
      "Epoch 139/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 3.9070e-05 - val_loss: 0.0059\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.00586\n",
      "Epoch 140/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 5.2341e-05 - val_loss: 0.0057\n",
      "\n",
      "Epoch 00140: val_loss improved from 0.00586 to 0.00573, saving model to ./model_epoch_140.hdf5\n",
      "Epoch 141/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 4.9733e-05 - val_loss: 0.0057\n",
      "\n",
      "Epoch 00141: val_loss improved from 0.00573 to 0.00569, saving model to ./model_epoch_141.hdf5\n",
      "Epoch 142/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 4.8166e-05 - val_loss: 0.0057\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.00569\n",
      "Epoch 143/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 4.3600e-05 - val_loss: 0.0057\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.00569\n",
      "Epoch 144/3000\n",
      "184/184 [==============================] - 0s 141us/step - loss: 3.8855e-05 - val_loss: 0.0058\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.00569\n",
      "Epoch 145/3000\n",
      "184/184 [==============================] - 0s 331us/step - loss: 4.3133e-05 - val_loss: 0.0058\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.00569\n",
      "Epoch 146/3000\n",
      "184/184 [==============================] - 0s 190us/step - loss: 4.3699e-05 - val_loss: 0.0058\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.00569\n",
      "Epoch 147/3000\n",
      "184/184 [==============================] - 0s 158us/step - loss: 3.8639e-05 - val_loss: 0.0058\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.00569\n",
      "Epoch 148/3000\n",
      "184/184 [==============================] - 0s 168us/step - loss: 5.4769e-05 - val_loss: 0.0057\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.00569\n",
      "Epoch 149/3000\n",
      "184/184 [==============================] - 0s 174us/step - loss: 5.0135e-05 - val_loss: 0.0057\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.00569\n",
      "Epoch 150/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 4.4031e-05 - val_loss: 0.0057\n",
      "\n",
      "Epoch 00150: val_loss improved from 0.00569 to 0.00568, saving model to ./model_epoch_150.hdf5\n",
      "Epoch 151/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 5.1306e-05 - val_loss: 0.0057\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.00568\n",
      "Epoch 152/3000\n",
      "184/184 [==============================] - 0s 147us/step - loss: 3.6802e-05 - val_loss: 0.0058\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.00568\n",
      "Epoch 153/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 4.3462e-05 - val_loss: 0.0058\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.00568\n",
      "Epoch 154/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 4.4276e-05 - val_loss: 0.0057\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.00568\n",
      "Epoch 155/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 4.1972e-05 - val_loss: 0.0057\n",
      "\n",
      "Epoch 00155: val_loss improved from 0.00568 to 0.00567, saving model to ./model_epoch_155.hdf5\n",
      "Epoch 156/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 4.5780e-05 - val_loss: 0.0057\n",
      "\n",
      "Epoch 00156: val_loss improved from 0.00567 to 0.00566, saving model to ./model_epoch_156.hdf5\n",
      "Epoch 157/3000\n",
      "184/184 [==============================] - 0s 266us/step - loss: 3.4995e-05 - val_loss: 0.0057\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.00566\n",
      "Epoch 158/3000\n",
      "184/184 [==============================] - 0s 190us/step - loss: 3.8148e-05 - val_loss: 0.0058\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.00566\n",
      "Epoch 159/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 4.2232e-05 - val_loss: 0.0058\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.00566\n",
      "Epoch 160/3000\n",
      "184/184 [==============================] - 0s 141us/step - loss: 4.1215e-05 - val_loss: 0.0057\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.00566\n",
      "Epoch 161/3000\n",
      "184/184 [==============================] - 0s 152us/step - loss: 4.4508e-05 - val_loss: 0.0057\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.00566\n",
      "Epoch 162/3000\n",
      "184/184 [==============================] - 0s 120us/step - loss: 3.9894e-05 - val_loss: 0.0057\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.00566\n",
      "Epoch 163/3000\n",
      "184/184 [==============================] - 0s 228us/step - loss: 4.6809e-05 - val_loss: 0.0057\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.00566\n",
      "Epoch 164/3000\n",
      "184/184 [==============================] - 0s 136us/step - loss: 4.1011e-05 - val_loss: 0.0058\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.00566\n",
      "Epoch 165/3000\n",
      "184/184 [==============================] - 0s 147us/step - loss: 4.0380e-05 - val_loss: 0.0058\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.00566\n",
      "Epoch 166/3000\n",
      "184/184 [==============================] - 0s 130us/step - loss: 3.7343e-05 - val_loss: 0.0057\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.00566\n",
      "Epoch 167/3000\n",
      "184/184 [==============================] - 0s 196us/step - loss: 4.1871e-05 - val_loss: 0.0056\n",
      "\n",
      "Epoch 00167: val_loss improved from 0.00566 to 0.00556, saving model to ./model_epoch_167.hdf5\n",
      "Epoch 168/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 4.4827e-05 - val_loss: 0.0055\n",
      "\n",
      "Epoch 00168: val_loss improved from 0.00556 to 0.00548, saving model to ./model_epoch_168.hdf5\n",
      "Epoch 169/3000\n",
      "184/184 [==============================] - 0s 212us/step - loss: 4.1126e-05 - val_loss: 0.0054\n",
      "\n",
      "Epoch 00169: val_loss improved from 0.00548 to 0.00539, saving model to ./model_epoch_169.hdf5\n",
      "Epoch 170/3000\n",
      "184/184 [==============================] - 0s 206us/step - loss: 4.6756e-05 - val_loss: 0.0054\n",
      "\n",
      "Epoch 00170: val_loss improved from 0.00539 to 0.00535, saving model to ./model_epoch_170.hdf5\n",
      "Epoch 171/3000\n",
      "184/184 [==============================] - 0s 130us/step - loss: 3.6554e-05 - val_loss: 0.0053\n",
      "\n",
      "Epoch 00171: val_loss improved from 0.00535 to 0.00535, saving model to ./model_epoch_171.hdf5\n",
      "Epoch 172/3000\n",
      "184/184 [==============================] - 0s 130us/step - loss: 3.7720e-05 - val_loss: 0.0053\n",
      "\n",
      "Epoch 00172: val_loss improved from 0.00535 to 0.00533, saving model to ./model_epoch_172.hdf5\n",
      "Epoch 173/3000\n",
      "184/184 [==============================] - 0s 119us/step - loss: 3.5542e-05 - val_loss: 0.0053\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.00533\n",
      "Epoch 174/3000\n",
      "184/184 [==============================] - 0s 120us/step - loss: 5.0843e-05 - val_loss: 0.0053\n",
      "\n",
      "Epoch 00174: val_loss improved from 0.00533 to 0.00529, saving model to ./model_epoch_174.hdf5\n",
      "Epoch 175/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 3.5952e-05 - val_loss: 0.0052\n",
      "\n",
      "Epoch 00175: val_loss improved from 0.00529 to 0.00521, saving model to ./model_epoch_175.hdf5\n",
      "Epoch 176/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 3.8548e-05 - val_loss: 0.0052\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.00521\n",
      "Epoch 177/3000\n",
      "184/184 [==============================] - 0s 119us/step - loss: 3.1695e-05 - val_loss: 0.0053\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.00521\n",
      "Epoch 178/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 201us/step - loss: 3.5554e-05 - val_loss: 0.0054\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.00521\n",
      "Epoch 179/3000\n",
      "184/184 [==============================] - 0s 185us/step - loss: 4.3099e-05 - val_loss: 0.0053\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.00521\n",
      "Epoch 180/3000\n",
      "184/184 [==============================] - 0s 282us/step - loss: 4.1545e-05 - val_loss: 0.0053\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.00521\n",
      "Epoch 181/3000\n",
      "184/184 [==============================] - 0s 185us/step - loss: 3.4739e-05 - val_loss: 0.0052\n",
      "\n",
      "Epoch 00181: val_loss improved from 0.00521 to 0.00516, saving model to ./model_epoch_181.hdf5\n",
      "Epoch 182/3000\n",
      "184/184 [==============================] - 0s 277us/step - loss: 3.9623e-05 - val_loss: 0.0052\n",
      "\n",
      "Epoch 00182: val_loss improved from 0.00516 to 0.00516, saving model to ./model_epoch_182.hdf5\n",
      "Epoch 183/3000\n",
      "184/184 [==============================] - 0s 168us/step - loss: 3.7037e-05 - val_loss: 0.0052\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.00516\n",
      "Epoch 184/3000\n",
      "184/184 [==============================] - 0s 212us/step - loss: 4.3267e-05 - val_loss: 0.0052\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.00516\n",
      "Epoch 185/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 3.5818e-05 - val_loss: 0.0052\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.00516\n",
      "Epoch 186/3000\n",
      "184/184 [==============================] - 0s 97us/step - loss: 3.9240e-05 - val_loss: 0.0052\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.00516\n",
      "Epoch 187/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 3.6603e-05 - val_loss: 0.0052\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.00516\n",
      "Epoch 188/3000\n",
      "184/184 [==============================] - 0s 116us/step - loss: 4.3207e-05 - val_loss: 0.0052\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.00516\n",
      "Epoch 189/3000\n",
      "184/184 [==============================] - 0s 128us/step - loss: 4.1459e-05 - val_loss: 0.0051\n",
      "\n",
      "Epoch 00189: val_loss improved from 0.00516 to 0.00510, saving model to ./model_epoch_189.hdf5\n",
      "Epoch 190/3000\n",
      "184/184 [==============================] - 0s 217us/step - loss: 3.8542e-05 - val_loss: 0.0051\n",
      "\n",
      "Epoch 00190: val_loss improved from 0.00510 to 0.00509, saving model to ./model_epoch_190.hdf5\n",
      "Epoch 191/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 3.2459e-05 - val_loss: 0.0051\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.00509\n",
      "Epoch 192/3000\n",
      "184/184 [==============================] - 0s 130us/step - loss: 3.9758e-05 - val_loss: 0.0052\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.00509\n",
      "Epoch 193/3000\n",
      "184/184 [==============================] - 0s 158us/step - loss: 3.7770e-05 - val_loss: 0.0052\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.00509\n",
      "Epoch 194/3000\n",
      "184/184 [==============================] - 0s 163us/step - loss: 3.4784e-05 - val_loss: 0.0051\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.00509\n",
      "Epoch 195/3000\n",
      "184/184 [==============================] - 0s 136us/step - loss: 3.9829e-05 - val_loss: 0.0050\n",
      "\n",
      "Epoch 00195: val_loss improved from 0.00509 to 0.00499, saving model to ./model_epoch_195.hdf5\n",
      "Epoch 196/3000\n",
      "184/184 [==============================] - 0s 136us/step - loss: 3.2694e-05 - val_loss: 0.0050\n",
      "\n",
      "Epoch 00196: val_loss improved from 0.00499 to 0.00498, saving model to ./model_epoch_196.hdf5\n",
      "Epoch 197/3000\n",
      "184/184 [==============================] - 0s 130us/step - loss: 3.5862e-05 - val_loss: 0.0050\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.00498\n",
      "Epoch 198/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 3.6735e-05 - val_loss: 0.0049\n",
      "\n",
      "Epoch 00198: val_loss improved from 0.00498 to 0.00494, saving model to ./model_epoch_198.hdf5\n",
      "Epoch 199/3000\n",
      "184/184 [==============================] - 0s 277us/step - loss: 3.5701e-05 - val_loss: 0.0048\n",
      "\n",
      "Epoch 00199: val_loss improved from 0.00494 to 0.00484, saving model to ./model_epoch_199.hdf5\n",
      "Epoch 200/3000\n",
      "184/184 [==============================] - 0s 136us/step - loss: 3.5510e-05 - val_loss: 0.0048\n",
      "\n",
      "Epoch 00200: val_loss improved from 0.00484 to 0.00481, saving model to ./model_epoch_200.hdf5\n",
      "Epoch 201/3000\n",
      "184/184 [==============================] - 0s 136us/step - loss: 4.2295e-05 - val_loss: 0.0048\n",
      "\n",
      "Epoch 00201: val_loss improved from 0.00481 to 0.00480, saving model to ./model_epoch_201.hdf5\n",
      "Epoch 202/3000\n",
      "184/184 [==============================] - 0s 141us/step - loss: 3.4305e-05 - val_loss: 0.0049\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 0.00480\n",
      "Epoch 203/3000\n",
      "184/184 [==============================] - 0s 136us/step - loss: 3.9981e-05 - val_loss: 0.0049\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 0.00480\n",
      "Epoch 204/3000\n",
      "184/184 [==============================] - 0s 130us/step - loss: 2.9867e-05 - val_loss: 0.0048\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 0.00480\n",
      "Epoch 205/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 3.6313e-05 - val_loss: 0.0047\n",
      "\n",
      "Epoch 00205: val_loss improved from 0.00480 to 0.00472, saving model to ./model_epoch_205.hdf5\n",
      "Epoch 206/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 3.9705e-05 - val_loss: 0.0047\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 0.00472\n",
      "Epoch 207/3000\n",
      "184/184 [==============================] - 0s 119us/step - loss: 3.8620e-05 - val_loss: 0.0049\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 0.00472\n",
      "Epoch 208/3000\n",
      "184/184 [==============================] - ETA: 0s - loss: 1.5804e-0 - 0s 114us/step - loss: 3.2809e-05 - val_loss: 0.0050\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 0.00472\n",
      "Epoch 209/3000\n",
      "184/184 [==============================] - 0s 282us/step - loss: 3.1630e-05 - val_loss: 0.0050\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 0.00472\n",
      "Epoch 210/3000\n",
      "184/184 [==============================] - 0s 190us/step - loss: 2.5666e-05 - val_loss: 0.0049\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 0.00472\n",
      "Epoch 211/3000\n",
      "184/184 [==============================] - 0s 239us/step - loss: 3.1731e-05 - val_loss: 0.0047\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 0.00472\n",
      "Epoch 212/3000\n",
      "184/184 [==============================] - 0s 130us/step - loss: 3.4677e-05 - val_loss: 0.0047\n",
      "\n",
      "Epoch 00212: val_loss improved from 0.00472 to 0.00470, saving model to ./model_epoch_212.hdf5\n",
      "Epoch 213/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 4.2947e-05 - val_loss: 0.0047\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 0.00470\n",
      "Epoch 214/3000\n",
      "184/184 [==============================] - 0s 131us/step - loss: 3.7742e-05 - val_loss: 0.0047\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 0.00470\n",
      "Epoch 215/3000\n",
      "184/184 [==============================] - 0s 141us/step - loss: 3.3547e-05 - val_loss: 0.0048\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 0.00470\n",
      "Epoch 216/3000\n",
      "184/184 [==============================] - 0s 147us/step - loss: 3.8059e-05 - val_loss: 0.0049\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 0.00470\n",
      "Epoch 217/3000\n",
      "184/184 [==============================] - 0s 119us/step - loss: 3.7741e-05 - val_loss: 0.0049\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 0.00470\n",
      "Epoch 218/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 3.4029e-05 - val_loss: 0.0047\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 0.00470\n",
      "Epoch 219/3000\n",
      "184/184 [==============================] - 0s 130us/step - loss: 3.5659e-05 - val_loss: 0.0046\n",
      "\n",
      "Epoch 00219: val_loss improved from 0.00470 to 0.00461, saving model to ./model_epoch_219.hdf5\n",
      "Epoch 220/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 3.0197e-05 - val_loss: 0.0045\n",
      "\n",
      "Epoch 00220: val_loss improved from 0.00461 to 0.00454, saving model to ./model_epoch_220.hdf5\n",
      "Epoch 221/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 3.6898e-05 - val_loss: 0.0045\n",
      "\n",
      "Epoch 00221: val_loss improved from 0.00454 to 0.00452, saving model to ./model_epoch_221.hdf5\n",
      "Epoch 222/3000\n",
      "184/184 [==============================] - 0s 163us/step - loss: 3.1219e-05 - val_loss: 0.0045\n",
      "\n",
      "Epoch 00222: val_loss improved from 0.00452 to 0.00450, saving model to ./model_epoch_222.hdf5\n",
      "Epoch 223/3000\n",
      "184/184 [==============================] - 0s 141us/step - loss: 3.7227e-05 - val_loss: 0.0045\n",
      "\n",
      "Epoch 00223: val_loss improved from 0.00450 to 0.00447, saving model to ./model_epoch_223.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 224/3000\n",
      "184/184 [==============================] - 0s 179us/step - loss: 3.3984e-05 - val_loss: 0.0044\n",
      "\n",
      "Epoch 00224: val_loss improved from 0.00447 to 0.00444, saving model to ./model_epoch_224.hdf5\n",
      "Epoch 225/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 3.9168e-05 - val_loss: 0.0045\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 0.00444\n",
      "Epoch 226/3000\n",
      "184/184 [==============================] - 0s 152us/step - loss: 3.5562e-05 - val_loss: 0.0045\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 0.00444\n",
      "Epoch 227/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 3.1829e-05 - val_loss: 0.0044\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 0.00444\n",
      "Epoch 228/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 3.7624e-05 - val_loss: 0.0045\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 0.00444\n",
      "Epoch 229/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.9319e-05 - val_loss: 0.0046\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 0.00444\n",
      "Epoch 230/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 3.6144e-05 - val_loss: 0.0046\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 0.00444\n",
      "Epoch 231/3000\n",
      "184/184 [==============================] - 0s 90us/step - loss: 3.2073e-05 - val_loss: 0.0046\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 0.00444\n",
      "Epoch 232/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 4.3945e-05 - val_loss: 0.0045\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 0.00444\n",
      "Epoch 233/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 3.4218e-05 - val_loss: 0.0044\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 0.00444\n",
      "Epoch 234/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 3.5869e-05 - val_loss: 0.0045\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 0.00444\n",
      "Epoch 235/3000\n",
      "184/184 [==============================] - 0s 82us/step - loss: 3.4171e-05 - val_loss: 0.0045\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 0.00444\n",
      "Epoch 236/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 3.0789e-05 - val_loss: 0.0044\n",
      "\n",
      "Epoch 00236: val_loss improved from 0.00444 to 0.00444, saving model to ./model_epoch_236.hdf5\n",
      "Epoch 237/3000\n",
      "184/184 [==============================] - 0s 282us/step - loss: 2.9227e-05 - val_loss: 0.0044\n",
      "\n",
      "Epoch 00237: val_loss improved from 0.00444 to 0.00440, saving model to ./model_epoch_237.hdf5\n",
      "Epoch 238/3000\n",
      "184/184 [==============================] - 0s 141us/step - loss: 3.1674e-05 - val_loss: 0.0045\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 0.00440\n",
      "Epoch 239/3000\n",
      "184/184 [==============================] - 0s 141us/step - loss: 3.9300e-05 - val_loss: 0.0046\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 0.00440\n",
      "Epoch 240/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 3.4136e-05 - val_loss: 0.0046\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 0.00440\n",
      "Epoch 241/3000\n",
      "184/184 [==============================] - 0s 120us/step - loss: 3.8226e-05 - val_loss: 0.0045\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 0.00440\n",
      "Epoch 242/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 3.7537e-05 - val_loss: 0.0044\n",
      "\n",
      "Epoch 00242: val_loss improved from 0.00440 to 0.00438, saving model to ./model_epoch_242.hdf5\n",
      "Epoch 243/3000\n",
      "184/184 [==============================] - 0s 201us/step - loss: 3.6757e-05 - val_loss: 0.0043\n",
      "\n",
      "Epoch 00243: val_loss improved from 0.00438 to 0.00434, saving model to ./model_epoch_243.hdf5\n",
      "Epoch 244/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 3.0559e-05 - val_loss: 0.0044\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 0.00434\n",
      "Epoch 245/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 3.2192e-05 - val_loss: 0.0045\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 0.00434\n",
      "Epoch 246/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 3.8836e-05 - val_loss: 0.0044\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 0.00434\n",
      "Epoch 247/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 3.2251e-05 - val_loss: 0.0044\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 0.00434\n",
      "Epoch 248/3000\n",
      "184/184 [==============================] - 0s 120us/step - loss: 3.5688e-05 - val_loss: 0.0044\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 0.00434\n",
      "Epoch 249/3000\n",
      "184/184 [==============================] - 0s 326us/step - loss: 3.0103e-05 - val_loss: 0.0044\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 0.00434\n",
      "Epoch 250/3000\n",
      "184/184 [==============================] - 0s 166us/step - loss: 3.7041e-05 - val_loss: 0.0044\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 0.00434\n",
      "Epoch 251/3000\n",
      "184/184 [==============================] - 0s 147us/step - loss: 3.0294e-05 - val_loss: 0.0043\n",
      "\n",
      "Epoch 00251: val_loss improved from 0.00434 to 0.00433, saving model to ./model_epoch_251.hdf5\n",
      "Epoch 252/3000\n",
      "184/184 [==============================] - 0s 130us/step - loss: 3.1649e-05 - val_loss: 0.0042\n",
      "\n",
      "Epoch 00252: val_loss improved from 0.00433 to 0.00422, saving model to ./model_epoch_252.hdf5\n",
      "Epoch 253/3000\n",
      "184/184 [==============================] - 0s 130us/step - loss: 3.5755e-05 - val_loss: 0.0042\n",
      "\n",
      "Epoch 00253: val_loss improved from 0.00422 to 0.00419, saving model to ./model_epoch_253.hdf5\n",
      "Epoch 254/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 3.3240e-05 - val_loss: 0.0042\n",
      "\n",
      "Epoch 00254: val_loss improved from 0.00419 to 0.00418, saving model to ./model_epoch_254.hdf5\n",
      "Epoch 255/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 3.3874e-05 - val_loss: 0.0042\n",
      "\n",
      "Epoch 00255: val_loss improved from 0.00418 to 0.00418, saving model to ./model_epoch_255.hdf5\n",
      "Epoch 256/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 3.1349e-05 - val_loss: 0.0042\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 0.00418\n",
      "Epoch 257/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 3.0351e-05 - val_loss: 0.0042\n",
      "\n",
      "Epoch 00257: val_loss improved from 0.00418 to 0.00416, saving model to ./model_epoch_257.hdf5\n",
      "Epoch 258/3000\n",
      "184/184 [==============================] - 0s 239us/step - loss: 2.8417e-05 - val_loss: 0.0042\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 0.00416\n",
      "Epoch 259/3000\n",
      "184/184 [==============================] - 0s 174us/step - loss: 3.2812e-05 - val_loss: 0.0042\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 0.00416\n",
      "Epoch 260/3000\n",
      "184/184 [==============================] - 0s 136us/step - loss: 3.2526e-05 - val_loss: 0.0041\n",
      "\n",
      "Epoch 00260: val_loss improved from 0.00416 to 0.00411, saving model to ./model_epoch_260.hdf5\n",
      "Epoch 261/3000\n",
      "184/184 [==============================] - 0s 119us/step - loss: 3.2378e-05 - val_loss: 0.0040\n",
      "\n",
      "Epoch 00261: val_loss improved from 0.00411 to 0.00404, saving model to ./model_epoch_261.hdf5\n",
      "Epoch 262/3000\n",
      "184/184 [==============================] - 0s 131us/step - loss: 3.0426e-05 - val_loss: 0.0041\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 0.00404\n",
      "Epoch 263/3000\n",
      "184/184 [==============================] - 0s 130us/step - loss: 2.7666e-05 - val_loss: 0.0041\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 0.00404\n",
      "Epoch 264/3000\n",
      "184/184 [==============================] - 0s 141us/step - loss: 3.1367e-05 - val_loss: 0.0041\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 0.00404\n",
      "Epoch 265/3000\n",
      "184/184 [==============================] - 0s 136us/step - loss: 3.0594e-05 - val_loss: 0.0041\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 0.00404\n",
      "Epoch 266/3000\n",
      "184/184 [==============================] - 0s 152us/step - loss: 3.2108e-05 - val_loss: 0.0040\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 0.00404\n",
      "Epoch 267/3000\n",
      "184/184 [==============================] - 0s 100us/step - loss: 3.3033e-05 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00267: val_loss improved from 0.00404 to 0.00395, saving model to ./model_epoch_267.hdf5\n",
      "Epoch 268/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.6407e-05 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00268: val_loss improved from 0.00395 to 0.00390, saving model to ./model_epoch_268.hdf5\n",
      "Epoch 269/3000\n",
      "184/184 [==============================] - 0s 234us/step - loss: 3.3835e-05 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 0.00390\n",
      "Epoch 270/3000\n",
      "184/184 [==============================] - 0s 282us/step - loss: 3.0216e-05 - val_loss: 0.0039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00270: val_loss improved from 0.00390 to 0.00389, saving model to ./model_epoch_270.hdf5\n",
      "Epoch 271/3000\n",
      "184/184 [==============================] - 0s 163us/step - loss: 2.9493e-05 - val_loss: 0.0040\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 0.00389\n",
      "Epoch 272/3000\n",
      "184/184 [==============================] - 0s 168us/step - loss: 3.0144e-05 - val_loss: 0.0041\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 0.00389\n",
      "Epoch 273/3000\n",
      "184/184 [==============================] - 0s 158us/step - loss: 2.6694e-05 - val_loss: 0.0041\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 0.00389\n",
      "Epoch 274/3000\n",
      "184/184 [==============================] - 0s 136us/step - loss: 2.7507e-05 - val_loss: 0.0040\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 0.00389\n",
      "Epoch 275/3000\n",
      "184/184 [==============================] - 0s 158us/step - loss: 2.9200e-05 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 0.00389\n",
      "Epoch 276/3000\n",
      "184/184 [==============================] - 0s 179us/step - loss: 3.5215e-05 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 0.00389\n",
      "Epoch 277/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 3.1477e-05 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 0.00389\n",
      "Epoch 278/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.6573e-05 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 0.00389\n",
      "Epoch 279/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 3.2983e-05 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 0.00389\n",
      "Epoch 280/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.8881e-05 - val_loss: 0.0040\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 0.00389\n",
      "Epoch 281/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.6067e-05 - val_loss: 0.0042\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 0.00389\n",
      "Epoch 282/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.7613e-05 - val_loss: 0.0042\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 0.00389\n",
      "Epoch 283/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.5121e-05 - val_loss: 0.0041\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 0.00389\n",
      "Epoch 284/3000\n",
      "184/184 [==============================] - 0s 119us/step - loss: 3.0427e-05 - val_loss: 0.0041\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 0.00389\n",
      "Epoch 285/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 2.9840e-05 - val_loss: 0.0041\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 0.00389\n",
      "Epoch 286/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 3.0800e-05 - val_loss: 0.0040\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 0.00389\n",
      "Epoch 287/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.7998e-05 - val_loss: 0.0040\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 0.00389\n",
      "Epoch 288/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 3.3614e-05 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 0.00389\n",
      "Epoch 289/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.7224e-05 - val_loss: 0.0038\n",
      "\n",
      "Epoch 00289: val_loss improved from 0.00389 to 0.00380, saving model to ./model_epoch_289.hdf5\n",
      "Epoch 290/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 3.5120e-05 - val_loss: 0.0038\n",
      "\n",
      "Epoch 00290: val_loss improved from 0.00380 to 0.00377, saving model to ./model_epoch_290.hdf5\n",
      "Epoch 291/3000\n",
      "184/184 [==============================] - 0s 131us/step - loss: 3.2813e-05 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 0.00377\n",
      "Epoch 292/3000\n",
      "184/184 [==============================] - 0s 179us/step - loss: 2.9134e-05 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 0.00377\n",
      "Epoch 293/3000\n",
      "184/184 [==============================] - 0s 228us/step - loss: 2.9079e-05 - val_loss: 0.0038\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 0.00377\n",
      "Epoch 294/3000\n",
      "184/184 [==============================] - 0s 315us/step - loss: 2.7828e-05 - val_loss: 0.0037\n",
      "\n",
      "Epoch 00294: val_loss improved from 0.00377 to 0.00374, saving model to ./model_epoch_294.hdf5\n",
      "Epoch 295/3000\n",
      "184/184 [==============================] - 0s 152us/step - loss: 3.1496e-05 - val_loss: 0.0038\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 0.00374\n",
      "Epoch 296/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 3.1642e-05 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 0.00374\n",
      "Epoch 297/3000\n",
      "184/184 [==============================] - 0s 147us/step - loss: 3.0448e-05 - val_loss: 0.0040\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 0.00374\n",
      "Epoch 298/3000\n",
      "184/184 [==============================] - 0s 131us/step - loss: 2.6669e-05 - val_loss: 0.0041\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 0.00374\n",
      "Epoch 299/3000\n",
      "184/184 [==============================] - 0s 158us/step - loss: 3.1158e-05 - val_loss: 0.0040\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 0.00374\n",
      "Epoch 300/3000\n",
      "184/184 [==============================] - 0s 223us/step - loss: 3.1591e-05 - val_loss: 0.0038\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 0.00374\n",
      "Epoch 301/3000\n",
      "184/184 [==============================] - 0s 119us/step - loss: 3.8093e-05 - val_loss: 0.0036\n",
      "\n",
      "Epoch 00301: val_loss improved from 0.00374 to 0.00360, saving model to ./model_epoch_301.hdf5\n",
      "Epoch 302/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 3.5043e-05 - val_loss: 0.0036\n",
      "\n",
      "Epoch 00302: val_loss did not improve from 0.00360\n",
      "Epoch 303/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 3.4354e-05 - val_loss: 0.0038\n",
      "\n",
      "Epoch 00303: val_loss did not improve from 0.00360\n",
      "Epoch 304/3000\n",
      "184/184 [==============================] - 0s 95us/step - loss: 3.0950e-05 - val_loss: 0.0041\n",
      "\n",
      "Epoch 00304: val_loss did not improve from 0.00360\n",
      "Epoch 305/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 2.1810e-05 - val_loss: 0.0041\n",
      "\n",
      "Epoch 00305: val_loss did not improve from 0.00360\n",
      "Epoch 306/3000\n",
      "184/184 [==============================] - 0s 288us/step - loss: 3.3636e-05 - val_loss: 0.0040\n",
      "\n",
      "Epoch 00306: val_loss did not improve from 0.00360\n",
      "Epoch 307/3000\n",
      "184/184 [==============================] - 0s 174us/step - loss: 2.8515e-05 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00307: val_loss did not improve from 0.00360\n",
      "Epoch 308/3000\n",
      "184/184 [==============================] - 0s 130us/step - loss: 2.9828e-05 - val_loss: 0.0037\n",
      "\n",
      "Epoch 00308: val_loss did not improve from 0.00360\n",
      "Epoch 309/3000\n",
      "184/184 [==============================] - 0s 136us/step - loss: 2.5638e-05 - val_loss: 0.0038\n",
      "\n",
      "Epoch 00309: val_loss did not improve from 0.00360\n",
      "Epoch 310/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 3.3210e-05 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00310: val_loss did not improve from 0.00360\n",
      "Epoch 311/3000\n",
      "184/184 [==============================] - 0s 147us/step - loss: 2.6503e-05 - val_loss: 0.0040\n",
      "\n",
      "Epoch 00311: val_loss did not improve from 0.00360\n",
      "Epoch 312/3000\n",
      "184/184 [==============================] - 0s 174us/step - loss: 2.9565e-05 - val_loss: 0.0040\n",
      "\n",
      "Epoch 00312: val_loss did not improve from 0.00360\n",
      "Epoch 313/3000\n",
      "184/184 [==============================] - 0s 163us/step - loss: 2.9134e-05 - val_loss: 0.0038\n",
      "\n",
      "Epoch 00313: val_loss did not improve from 0.00360\n",
      "Epoch 314/3000\n",
      "184/184 [==============================] - 0s 147us/step - loss: 3.4045e-05 - val_loss: 0.0037\n",
      "\n",
      "Epoch 00314: val_loss did not improve from 0.00360\n",
      "Epoch 315/3000\n",
      "184/184 [==============================] - 0s 158us/step - loss: 3.3267e-05 - val_loss: 0.0037\n",
      "\n",
      "Epoch 00315: val_loss did not improve from 0.00360\n",
      "Epoch 316/3000\n",
      "184/184 [==============================] - 0s 147us/step - loss: 3.1168e-05 - val_loss: 0.0037\n",
      "\n",
      "Epoch 00316: val_loss did not improve from 0.00360\n",
      "Epoch 317/3000\n",
      "184/184 [==============================] - 0s 136us/step - loss: 2.9494e-05 - val_loss: 0.0037\n",
      "\n",
      "Epoch 00317: val_loss did not improve from 0.00360\n",
      "Epoch 318/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.7944e-05 - val_loss: 0.0037\n",
      "\n",
      "Epoch 00318: val_loss did not improve from 0.00360\n",
      "Epoch 319/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 3.0132e-05 - val_loss: 0.0036\n",
      "\n",
      "Epoch 00319: val_loss did not improve from 0.00360\n",
      "Epoch 320/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 103us/step - loss: 2.4368e-05 - val_loss: 0.0037\n",
      "\n",
      "Epoch 00320: val_loss did not improve from 0.00360\n",
      "Epoch 321/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 3.0001e-05 - val_loss: 0.0037\n",
      "\n",
      "Epoch 00321: val_loss did not improve from 0.00360\n",
      "Epoch 322/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 3.2576e-05 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00322: val_loss did not improve from 0.00360\n",
      "Epoch 323/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 3.1849e-05 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00323: val_loss did not improve from 0.00360\n",
      "Epoch 324/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 3.2971e-05 - val_loss: 0.0038\n",
      "\n",
      "Epoch 00324: val_loss did not improve from 0.00360\n",
      "Epoch 325/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 3.2069e-05 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00325: val_loss did not improve from 0.00360\n",
      "Epoch 326/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.4525e-05 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00326: val_loss did not improve from 0.00360\n",
      "Epoch 327/3000\n",
      "184/184 [==============================] - 0s 119us/step - loss: 2.6481e-05 - val_loss: 0.0040\n",
      "\n",
      "Epoch 00327: val_loss did not improve from 0.00360\n",
      "Epoch 328/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 3.4169e-05 - val_loss: 0.0041\n",
      "\n",
      "Epoch 00328: val_loss did not improve from 0.00360\n",
      "Epoch 329/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 3.1382e-05 - val_loss: 0.0040\n",
      "\n",
      "Epoch 00329: val_loss did not improve from 0.00360\n",
      "Epoch 330/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.6592e-05 - val_loss: 0.0038\n",
      "\n",
      "Epoch 00330: val_loss did not improve from 0.00360\n",
      "Epoch 331/3000\n",
      "184/184 [==============================] - 0s 93us/step - loss: 2.6028e-05 - val_loss: 0.0036\n",
      "\n",
      "Epoch 00331: val_loss did not improve from 0.00360\n",
      "Epoch 332/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 3.2307e-05 - val_loss: 0.0036\n",
      "\n",
      "Epoch 00332: val_loss did not improve from 0.00360\n",
      "Epoch 333/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.5893e-05 - val_loss: 0.0038\n",
      "\n",
      "Epoch 00333: val_loss did not improve from 0.00360\n",
      "Epoch 334/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 3.1498e-05 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00334: val_loss did not improve from 0.00360\n",
      "Epoch 335/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 3.0980e-05 - val_loss: 0.0038\n",
      "\n",
      "Epoch 00335: val_loss did not improve from 0.00360\n",
      "Epoch 336/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 3.6359e-05 - val_loss: 0.0037\n",
      "\n",
      "Epoch 00336: val_loss did not improve from 0.00360\n",
      "Epoch 337/3000\n",
      "184/184 [==============================] - 0s 158us/step - loss: 2.7688e-05 - val_loss: 0.0036\n",
      "\n",
      "Epoch 00337: val_loss did not improve from 0.00360\n",
      "Epoch 338/3000\n",
      "184/184 [==============================] - 0s 93us/step - loss: 2.9069e-05 - val_loss: 0.0038\n",
      "\n",
      "Epoch 00338: val_loss did not improve from 0.00360\n",
      "Epoch 339/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.8058e-05 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00339: val_loss did not improve from 0.00360\n",
      "Epoch 340/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 3.1131e-05 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00340: val_loss did not improve from 0.00360\n",
      "Epoch 341/3000\n",
      "184/184 [==============================] - 0s 93us/step - loss: 2.4951e-05 - val_loss: 0.0038\n",
      "\n",
      "Epoch 00341: val_loss did not improve from 0.00360\n",
      "Epoch 342/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.8992e-05 - val_loss: 0.0038\n",
      "\n",
      "Epoch 00342: val_loss did not improve from 0.00360\n",
      "Epoch 343/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.8650e-05 - val_loss: 0.0037\n",
      "\n",
      "Epoch 00343: val_loss did not improve from 0.00360\n",
      "Epoch 344/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.9169e-05 - val_loss: 0.0037\n",
      "\n",
      "Epoch 00344: val_loss did not improve from 0.00360\n",
      "Epoch 345/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.9349e-05 - val_loss: 0.0038\n",
      "\n",
      "Epoch 00345: val_loss did not improve from 0.00360\n",
      "Epoch 346/3000\n",
      "184/184 [==============================] - ETA: 0s - loss: 1.4073e-0 - 0s 93us/step - loss: 2.9899e-05 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00346: val_loss did not improve from 0.00360\n",
      "Epoch 347/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.7399e-05 - val_loss: 0.0038\n",
      "\n",
      "Epoch 00347: val_loss did not improve from 0.00360\n",
      "Epoch 348/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.9775e-05 - val_loss: 0.0037\n",
      "\n",
      "Epoch 00348: val_loss did not improve from 0.00360\n",
      "Epoch 349/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 3.1725e-05 - val_loss: 0.0037\n",
      "\n",
      "Epoch 00349: val_loss did not improve from 0.00360\n",
      "Epoch 350/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.9733e-05 - val_loss: 0.0038\n",
      "\n",
      "Epoch 00350: val_loss did not improve from 0.00360\n",
      "Epoch 351/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.8891e-05 - val_loss: 0.0037\n",
      "\n",
      "Epoch 00351: val_loss did not improve from 0.00360\n",
      "Epoch 352/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.6698e-05 - val_loss: 0.0037\n",
      "\n",
      "Epoch 00352: val_loss did not improve from 0.00360\n",
      "Epoch 353/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 3.4941e-05 - val_loss: 0.0037\n",
      "\n",
      "Epoch 00353: val_loss did not improve from 0.00360\n",
      "Epoch 354/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.5945e-05 - val_loss: 0.0038\n",
      "\n",
      "Epoch 00354: val_loss did not improve from 0.00360\n",
      "Epoch 355/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.4836e-05 - val_loss: 0.0037\n",
      "\n",
      "Epoch 00355: val_loss did not improve from 0.00360\n",
      "Epoch 356/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 3.3028e-05 - val_loss: 0.0035\n",
      "\n",
      "Epoch 00356: val_loss improved from 0.00360 to 0.00355, saving model to ./model_epoch_356.hdf5\n",
      "Epoch 357/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.9509e-05 - val_loss: 0.0035\n",
      "\n",
      "Epoch 00357: val_loss improved from 0.00355 to 0.00351, saving model to ./model_epoch_357.hdf5\n",
      "Epoch 358/3000\n",
      "184/184 [==============================] - 0s 81us/step - loss: 2.6638e-05 - val_loss: 0.0036\n",
      "\n",
      "Epoch 00358: val_loss did not improve from 0.00351\n",
      "Epoch 359/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.6973e-05 - val_loss: 0.0036\n",
      "\n",
      "Epoch 00359: val_loss did not improve from 0.00351\n",
      "Epoch 360/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.6308e-05 - val_loss: 0.0035\n",
      "\n",
      "Epoch 00360: val_loss improved from 0.00351 to 0.00349, saving model to ./model_epoch_360.hdf5\n",
      "Epoch 361/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.6755e-05 - val_loss: 0.0034\n",
      "\n",
      "Epoch 00361: val_loss improved from 0.00349 to 0.00343, saving model to ./model_epoch_361.hdf5\n",
      "Epoch 362/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 3.6069e-05 - val_loss: 0.0035\n",
      "\n",
      "Epoch 00362: val_loss did not improve from 0.00343\n",
      "Epoch 363/3000\n",
      "184/184 [==============================] - ETA: 0s - loss: 1.4208e-0 - 0s 109us/step - loss: 2.7727e-05 - val_loss: 0.0037\n",
      "\n",
      "Epoch 00363: val_loss did not improve from 0.00343\n",
      "Epoch 364/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.8459e-05 - val_loss: 0.0037\n",
      "\n",
      "Epoch 00364: val_loss did not improve from 0.00343\n",
      "Epoch 365/3000\n",
      "184/184 [==============================] - 0s 104us/step - loss: 2.9100e-05 - val_loss: 0.0036\n",
      "\n",
      "Epoch 00365: val_loss did not improve from 0.00343\n",
      "Epoch 366/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.5230e-05 - val_loss: 0.0036\n",
      "\n",
      "Epoch 00366: val_loss did not improve from 0.00343\n",
      "Epoch 367/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.6148e-05 - val_loss: 0.0036\n",
      "\n",
      "Epoch 00367: val_loss did not improve from 0.00343\n",
      "Epoch 368/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.6193e-05 - val_loss: 0.0038\n",
      "\n",
      "Epoch 00368: val_loss did not improve from 0.00343\n",
      "Epoch 369/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 130us/step - loss: 3.2920e-05 - val_loss: 0.0038\n",
      "\n",
      "Epoch 00369: val_loss did not improve from 0.00343\n",
      "Epoch 370/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 2.6313e-05 - val_loss: 0.0038\n",
      "\n",
      "Epoch 00370: val_loss did not improve from 0.00343\n",
      "Epoch 371/3000\n",
      "184/184 [==============================] - 0s 272us/step - loss: 3.1174e-05 - val_loss: 0.0037\n",
      "\n",
      "Epoch 00371: val_loss did not improve from 0.00343\n",
      "Epoch 372/3000\n",
      "184/184 [==============================] - 0s 206us/step - loss: 2.3770e-05 - val_loss: 0.0036\n",
      "\n",
      "Epoch 00372: val_loss did not improve from 0.00343\n",
      "Epoch 373/3000\n",
      "184/184 [==============================] - 0s 255us/step - loss: 2.7018e-05 - val_loss: 0.0036\n",
      "\n",
      "Epoch 00373: val_loss did not improve from 0.00343\n",
      "Epoch 374/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.5713e-05 - val_loss: 0.0037\n",
      "\n",
      "Epoch 00374: val_loss did not improve from 0.00343\n",
      "Epoch 375/3000\n",
      "184/184 [==============================] - 0s 131us/step - loss: 2.3208e-05 - val_loss: 0.0037\n",
      "\n",
      "Epoch 00375: val_loss did not improve from 0.00343\n",
      "Epoch 376/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 2.5679e-05 - val_loss: 0.0035\n",
      "\n",
      "Epoch 00376: val_loss did not improve from 0.00343\n",
      "Epoch 377/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 2.7094e-05 - val_loss: 0.0034\n",
      "\n",
      "Epoch 00377: val_loss improved from 0.00343 to 0.00342, saving model to ./model_epoch_377.hdf5\n",
      "Epoch 378/3000\n",
      "184/184 [==============================] - 0s 174us/step - loss: 2.8500e-05 - val_loss: 0.0034\n",
      "\n",
      "Epoch 00378: val_loss did not improve from 0.00342\n",
      "Epoch 379/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 3.0499e-05 - val_loss: 0.0036\n",
      "\n",
      "Epoch 00379: val_loss did not improve from 0.00342\n",
      "Epoch 380/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.2790e-05 - val_loss: 0.0038\n",
      "\n",
      "Epoch 00380: val_loss did not improve from 0.00342\n",
      "Epoch 381/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.9197e-05 - val_loss: 0.0038\n",
      "\n",
      "Epoch 00381: val_loss did not improve from 0.00342\n",
      "Epoch 382/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 3.0576e-05 - val_loss: 0.0037\n",
      "\n",
      "Epoch 00382: val_loss did not improve from 0.00342\n",
      "Epoch 383/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.8689e-05 - val_loss: 0.0035\n",
      "\n",
      "Epoch 00383: val_loss did not improve from 0.00342\n",
      "Epoch 384/3000\n",
      "184/184 [==============================] - 0s 101us/step - loss: 3.0728e-05 - val_loss: 0.0035\n",
      "\n",
      "Epoch 00384: val_loss did not improve from 0.00342\n",
      "Epoch 385/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 3.1178e-05 - val_loss: 0.0038\n",
      "\n",
      "Epoch 00385: val_loss did not improve from 0.00342\n",
      "Epoch 386/3000\n",
      "184/184 [==============================] - 0s 185us/step - loss: 2.7730e-05 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00386: val_loss did not improve from 0.00342\n",
      "Epoch 387/3000\n",
      "184/184 [==============================] - 0s 342us/step - loss: 3.2826e-05 - val_loss: 0.0037\n",
      "\n",
      "Epoch 00387: val_loss did not improve from 0.00342\n",
      "Epoch 388/3000\n",
      "184/184 [==============================] - 0s 201us/step - loss: 2.5913e-05 - val_loss: 0.0035\n",
      "\n",
      "Epoch 00388: val_loss did not improve from 0.00342\n",
      "Epoch 389/3000\n",
      "184/184 [==============================] - 0s 119us/step - loss: 3.2704e-05 - val_loss: 0.0034\n",
      "\n",
      "Epoch 00389: val_loss improved from 0.00342 to 0.00341, saving model to ./model_epoch_389.hdf5\n",
      "Epoch 390/3000\n",
      "184/184 [==============================] - 0s 120us/step - loss: 2.8832e-05 - val_loss: 0.0036\n",
      "\n",
      "Epoch 00390: val_loss did not improve from 0.00341\n",
      "Epoch 391/3000\n",
      "184/184 [==============================] - 0s 141us/step - loss: 2.6767e-05 - val_loss: 0.0037\n",
      "\n",
      "Epoch 00391: val_loss did not improve from 0.00341\n",
      "Epoch 392/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.4640e-05 - val_loss: 0.0036\n",
      "\n",
      "Epoch 00392: val_loss did not improve from 0.00341\n",
      "Epoch 393/3000\n",
      "184/184 [==============================] - 0s 136us/step - loss: 2.2137e-05 - val_loss: 0.0036\n",
      "\n",
      "Epoch 00393: val_loss did not improve from 0.00341\n",
      "Epoch 394/3000\n",
      "184/184 [==============================] - 0s 141us/step - loss: 2.7171e-05 - val_loss: 0.0036\n",
      "\n",
      "Epoch 00394: val_loss did not improve from 0.00341\n",
      "Epoch 395/3000\n",
      "184/184 [==============================] - 0s 136us/step - loss: 2.4246e-05 - val_loss: 0.0036\n",
      "\n",
      "Epoch 00395: val_loss did not improve from 0.00341\n",
      "Epoch 396/3000\n",
      "184/184 [==============================] - 0s 119us/step - loss: 2.5550e-05 - val_loss: 0.0036\n",
      "\n",
      "Epoch 00396: val_loss did not improve from 0.00341\n",
      "Epoch 397/3000\n",
      "184/184 [==============================] - 0s 147us/step - loss: 2.4710e-05 - val_loss: 0.0036\n",
      "\n",
      "Epoch 00397: val_loss did not improve from 0.00341\n",
      "Epoch 398/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 3.0383e-05 - val_loss: 0.0037\n",
      "\n",
      "Epoch 00398: val_loss did not improve from 0.00341\n",
      "Epoch 399/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 2.9355e-05 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00399: val_loss did not improve from 0.00341\n",
      "Epoch 400/3000\n",
      "184/184 [==============================] - 0s 168us/step - loss: 2.6327e-05 - val_loss: 0.0038\n",
      "\n",
      "Epoch 00400: val_loss did not improve from 0.00341\n",
      "Epoch 401/3000\n",
      "184/184 [==============================] - ETA: 0s - loss: 1.2658e-0 - 0s 272us/step - loss: 2.6088e-05 - val_loss: 0.0037\n",
      "\n",
      "Epoch 00401: val_loss did not improve from 0.00341\n",
      "Epoch 402/3000\n",
      "184/184 [==============================] - 0s 223us/step - loss: 3.5030e-05 - val_loss: 0.0036\n",
      "\n",
      "Epoch 00402: val_loss did not improve from 0.00341\n",
      "Epoch 403/3000\n",
      "184/184 [==============================] - 0s 206us/step - loss: 2.5858e-05 - val_loss: 0.0037\n",
      "\n",
      "Epoch 00403: val_loss did not improve from 0.00341\n",
      "Epoch 404/3000\n",
      "184/184 [==============================] - 0s 174us/step - loss: 2.4052e-05 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00404: val_loss did not improve from 0.00341\n",
      "Epoch 405/3000\n",
      "184/184 [==============================] - 0s 141us/step - loss: 2.5889e-05 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00405: val_loss did not improve from 0.00341\n",
      "Epoch 406/3000\n",
      "184/184 [==============================] - 0s 136us/step - loss: 2.7580e-05 - val_loss: 0.0037\n",
      "\n",
      "Epoch 00406: val_loss did not improve from 0.00341\n",
      "Epoch 407/3000\n",
      "184/184 [==============================] - 0s 147us/step - loss: 2.2284e-05 - val_loss: 0.0036\n",
      "\n",
      "Epoch 00407: val_loss did not improve from 0.00341\n",
      "Epoch 408/3000\n",
      "184/184 [==============================] - 0s 139us/step - loss: 2.5387e-05 - val_loss: 0.0035\n",
      "\n",
      "Epoch 00408: val_loss did not improve from 0.00341\n",
      "Epoch 409/3000\n",
      "184/184 [==============================] - 0s 130us/step - loss: 2.2496e-05 - val_loss: 0.0036\n",
      "\n",
      "Epoch 00409: val_loss did not improve from 0.00341\n",
      "Epoch 410/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 2.9409e-05 - val_loss: 0.0036\n",
      "\n",
      "Epoch 00410: val_loss did not improve from 0.00341\n",
      "Epoch 411/3000\n",
      "184/184 [==============================] - 0s 147us/step - loss: 2.3954e-05 - val_loss: 0.0035\n",
      "\n",
      "Epoch 00411: val_loss did not improve from 0.00341\n",
      "Epoch 412/3000\n",
      "184/184 [==============================] - 0s 152us/step - loss: 2.9549e-05 - val_loss: 0.0035\n",
      "\n",
      "Epoch 00412: val_loss did not improve from 0.00341\n",
      "Epoch 413/3000\n",
      "184/184 [==============================] - 0s 141us/step - loss: 3.3103e-05 - val_loss: 0.0035\n",
      "\n",
      "Epoch 00413: val_loss did not improve from 0.00341\n",
      "Epoch 414/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 3.3093e-05 - val_loss: 0.0034\n",
      "\n",
      "Epoch 00414: val_loss did not improve from 0.00341\n",
      "Epoch 415/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.4836e-05 - val_loss: 0.0035\n",
      "\n",
      "Epoch 00415: val_loss did not improve from 0.00341\n",
      "Epoch 416/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.3696e-05 - val_loss: 0.0035\n",
      "\n",
      "Epoch 00416: val_loss did not improve from 0.00341\n",
      "Epoch 417/3000\n",
      "184/184 [==============================] - 0s 120us/step - loss: 2.6858e-05 - val_loss: 0.0036\n",
      "\n",
      "Epoch 00417: val_loss did not improve from 0.00341\n",
      "Epoch 418/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 2.7224e-05 - val_loss: 0.0036\n",
      "\n",
      "Epoch 00418: val_loss did not improve from 0.00341\n",
      "Epoch 419/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 109us/step - loss: 2.2921e-05 - val_loss: 0.0036\n",
      "\n",
      "Epoch 00419: val_loss did not improve from 0.00341\n",
      "Epoch 420/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 3.0609e-05 - val_loss: 0.0034\n",
      "\n",
      "Epoch 00420: val_loss did not improve from 0.00341\n",
      "Epoch 421/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.9091e-05 - val_loss: 0.0035\n",
      "\n",
      "Epoch 00421: val_loss did not improve from 0.00341\n",
      "Epoch 422/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.4145e-05 - val_loss: 0.0037\n",
      "\n",
      "Epoch 00422: val_loss did not improve from 0.00341\n",
      "Epoch 423/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 3.1006e-05 - val_loss: 0.0038\n",
      "\n",
      "Epoch 00423: val_loss did not improve from 0.00341\n",
      "Epoch 424/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.4427e-05 - val_loss: 0.0036\n",
      "\n",
      "Epoch 00424: val_loss did not improve from 0.00341\n",
      "Epoch 425/3000\n",
      "184/184 [==============================] - 0s 99us/step - loss: 3.0014e-05 - val_loss: 0.0035\n",
      "\n",
      "Epoch 00425: val_loss did not improve from 0.00341\n",
      "Epoch 426/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.7841e-05 - val_loss: 0.0036\n",
      "\n",
      "Epoch 00426: val_loss did not improve from 0.00341\n",
      "Epoch 427/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.4142e-05 - val_loss: 0.0038\n",
      "\n",
      "Epoch 00427: val_loss did not improve from 0.00341\n",
      "Epoch 428/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.9358e-05 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00428: val_loss did not improve from 0.00341\n",
      "Epoch 429/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.3318e-05 - val_loss: 0.0038\n",
      "\n",
      "Epoch 00429: val_loss did not improve from 0.00341\n",
      "Epoch 430/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.2262e-05 - val_loss: 0.0037\n",
      "\n",
      "Epoch 00430: val_loss did not improve from 0.00341\n",
      "Epoch 431/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 3.0944e-05 - val_loss: 0.0036\n",
      "\n",
      "Epoch 00431: val_loss did not improve from 0.00341\n",
      "Epoch 432/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.6868e-05 - val_loss: 0.0035\n",
      "\n",
      "Epoch 00432: val_loss did not improve from 0.00341\n",
      "Epoch 433/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 3.4109e-05 - val_loss: 0.0036\n",
      "\n",
      "Epoch 00433: val_loss did not improve from 0.00341\n",
      "Epoch 434/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.7632e-05 - val_loss: 0.0037\n",
      "\n",
      "Epoch 00434: val_loss did not improve from 0.00341\n",
      "Epoch 435/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.6952e-05 - val_loss: 0.0037\n",
      "\n",
      "Epoch 00435: val_loss did not improve from 0.00341\n",
      "Epoch 436/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 2.4952e-05 - val_loss: 0.0036\n",
      "\n",
      "Epoch 00436: val_loss did not improve from 0.00341\n",
      "Epoch 437/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.6307e-05 - val_loss: 0.0034\n",
      "\n",
      "Epoch 00437: val_loss did not improve from 0.00341\n",
      "Epoch 438/3000\n",
      "184/184 [==============================] - 0s 119us/step - loss: 2.7579e-05 - val_loss: 0.0033\n",
      "\n",
      "Epoch 00438: val_loss improved from 0.00341 to 0.00328, saving model to ./model_epoch_438.hdf5\n",
      "Epoch 439/3000\n",
      "184/184 [==============================] - 0s 119us/step - loss: 2.6357e-05 - val_loss: 0.0034\n",
      "\n",
      "Epoch 00439: val_loss did not improve from 0.00328\n",
      "Epoch 440/3000\n",
      "184/184 [==============================] - 0s 141us/step - loss: 2.3297e-05 - val_loss: 0.0037\n",
      "\n",
      "Epoch 00440: val_loss did not improve from 0.00328\n",
      "Epoch 441/3000\n",
      "184/184 [==============================] - 0s 169us/step - loss: 2.6230e-05 - val_loss: 0.0037\n",
      "\n",
      "Epoch 00441: val_loss did not improve from 0.00328\n",
      "Epoch 442/3000\n",
      "184/184 [==============================] - 0s 119us/step - loss: 3.4405e-05 - val_loss: 0.0035\n",
      "\n",
      "Epoch 00442: val_loss did not improve from 0.00328\n",
      "Epoch 443/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.5465e-05 - val_loss: 0.0034\n",
      "\n",
      "Epoch 00443: val_loss did not improve from 0.00328\n",
      "Epoch 444/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.5575e-05 - val_loss: 0.0035\n",
      "\n",
      "Epoch 00444: val_loss did not improve from 0.00328\n",
      "Epoch 445/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.8305e-05 - val_loss: 0.0037\n",
      "\n",
      "Epoch 00445: val_loss did not improve from 0.00328\n",
      "Epoch 446/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.4900e-05 - val_loss: 0.0038\n",
      "\n",
      "Epoch 00446: val_loss did not improve from 0.00328\n",
      "Epoch 447/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.4659e-05 - val_loss: 0.0037\n",
      "\n",
      "Epoch 00447: val_loss did not improve from 0.00328\n",
      "Epoch 448/3000\n",
      "184/184 [==============================] - 0s 93us/step - loss: 2.4164e-05 - val_loss: 0.0036\n",
      "\n",
      "Epoch 00448: val_loss did not improve from 0.00328\n",
      "Epoch 449/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 3.2781e-05 - val_loss: 0.0035\n",
      "\n",
      "Epoch 00449: val_loss did not improve from 0.00328\n",
      "Epoch 450/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.9538e-05 - val_loss: 0.0036\n",
      "\n",
      "Epoch 00450: val_loss did not improve from 0.00328\n",
      "Epoch 451/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.1776e-05 - val_loss: 0.0038\n",
      "\n",
      "Epoch 00451: val_loss did not improve from 0.00328\n",
      "Epoch 452/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.7762e-05 - val_loss: 0.0038\n",
      "\n",
      "Epoch 00452: val_loss did not improve from 0.00328\n",
      "Epoch 453/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.3643e-05 - val_loss: 0.0037\n",
      "\n",
      "Epoch 00453: val_loss did not improve from 0.00328\n",
      "Epoch 454/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.1959e-05 - val_loss: 0.0036\n",
      "\n",
      "Epoch 00454: val_loss did not improve from 0.00328\n",
      "Epoch 455/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.4582e-05 - val_loss: 0.0037\n",
      "\n",
      "Epoch 00455: val_loss did not improve from 0.00328\n",
      "Epoch 456/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.8212e-05 - val_loss: 0.0036\n",
      "\n",
      "Epoch 00456: val_loss did not improve from 0.00328\n",
      "Epoch 457/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 3.0931e-05 - val_loss: 0.0035\n",
      "\n",
      "Epoch 00457: val_loss did not improve from 0.00328\n",
      "Epoch 458/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.6599e-05 - val_loss: 0.0037\n",
      "\n",
      "Epoch 00458: val_loss did not improve from 0.00328\n",
      "Epoch 459/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.3070e-05 - val_loss: 0.0038\n",
      "\n",
      "Epoch 00459: val_loss did not improve from 0.00328\n",
      "Epoch 460/3000\n",
      "184/184 [==============================] - 0s 93us/step - loss: 2.4502e-05 - val_loss: 0.0037\n",
      "\n",
      "Epoch 00460: val_loss did not improve from 0.00328\n",
      "Epoch 461/3000\n",
      "184/184 [==============================] - 0s 119us/step - loss: 2.1929e-05 - val_loss: 0.0035\n",
      "\n",
      "Epoch 00461: val_loss did not improve from 0.00328\n",
      "Epoch 462/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.4325e-05 - val_loss: 0.0034\n",
      "\n",
      "Epoch 00462: val_loss did not improve from 0.00328\n",
      "Epoch 463/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.7160e-05 - val_loss: 0.0036\n",
      "\n",
      "Epoch 00463: val_loss did not improve from 0.00328\n",
      "Epoch 464/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.5960e-05 - val_loss: 0.0037\n",
      "\n",
      "Epoch 00464: val_loss did not improve from 0.00328\n",
      "Epoch 465/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.2603e-05 - val_loss: 0.0038\n",
      "\n",
      "Epoch 00465: val_loss did not improve from 0.00328\n",
      "Epoch 466/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.1072e-05 - val_loss: 0.0038\n",
      "\n",
      "Epoch 00466: val_loss did not improve from 0.00328\n",
      "Epoch 467/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.6228e-05 - val_loss: 0.0037\n",
      "\n",
      "Epoch 00467: val_loss did not improve from 0.00328\n",
      "Epoch 468/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.5920e-05 - val_loss: 0.0036\n",
      "\n",
      "Epoch 00468: val_loss did not improve from 0.00328\n",
      "Epoch 469/3000\n",
      "184/184 [==============================] - 0s 81us/step - loss: 2.8438e-05 - val_loss: 0.0037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00469: val_loss did not improve from 0.00328\n",
      "Epoch 470/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.4528e-05 - val_loss: 0.0040\n",
      "\n",
      "Epoch 00470: val_loss did not improve from 0.00328\n",
      "Epoch 471/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.6449e-05 - val_loss: 0.0041\n",
      "\n",
      "Epoch 00471: val_loss did not improve from 0.00328\n",
      "Epoch 472/3000\n",
      "184/184 [==============================] - 0s 234us/step - loss: 2.7170e-05 - val_loss: 0.0040\n",
      "\n",
      "Epoch 00472: val_loss did not improve from 0.00328\n",
      "Epoch 473/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.5712e-05 - val_loss: 0.0038\n",
      "\n",
      "Epoch 00473: val_loss did not improve from 0.00328\n",
      "Epoch 474/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.6505e-05 - val_loss: 0.0038\n",
      "\n",
      "Epoch 00474: val_loss did not improve from 0.00328\n",
      "Epoch 475/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.5226e-05 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00475: val_loss did not improve from 0.00328\n",
      "Epoch 476/3000\n",
      "184/184 [==============================] - 0s 136us/step - loss: 2.4202e-05 - val_loss: 0.0038\n",
      "\n",
      "Epoch 00476: val_loss did not improve from 0.00328\n",
      "Epoch 477/3000\n",
      "184/184 [==============================] - 0s 120us/step - loss: 2.1970e-05 - val_loss: 0.0037\n",
      "\n",
      "Epoch 00477: val_loss did not improve from 0.00328\n",
      "Epoch 478/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.3455e-05 - val_loss: 0.0037\n",
      "\n",
      "Epoch 00478: val_loss did not improve from 0.00328\n",
      "Epoch 479/3000\n",
      "184/184 [==============================] - 0s 93us/step - loss: 2.5622e-05 - val_loss: 0.0037\n",
      "\n",
      "Epoch 00479: val_loss did not improve from 0.00328\n",
      "Epoch 480/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 2.2856e-05 - val_loss: 0.0037\n",
      "\n",
      "Epoch 00480: val_loss did not improve from 0.00328\n",
      "Epoch 481/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.2583e-05 - val_loss: 0.0035\n",
      "\n",
      "Epoch 00481: val_loss did not improve from 0.00328\n",
      "Epoch 482/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.8873e-05 - val_loss: 0.0035\n",
      "\n",
      "Epoch 00482: val_loss did not improve from 0.00328\n",
      "Epoch 483/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.0351e-05 - val_loss: 0.0037\n",
      "\n",
      "Epoch 00483: val_loss did not improve from 0.00328\n",
      "Epoch 484/3000\n",
      "184/184 [==============================] - 0s 120us/step - loss: 2.5658e-05 - val_loss: 0.0038\n",
      "\n",
      "Epoch 00484: val_loss did not improve from 0.00328\n",
      "Epoch 485/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 2.9145e-05 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00485: val_loss did not improve from 0.00328\n",
      "Epoch 486/3000\n",
      "184/184 [==============================] - 0s 93us/step - loss: 2.7545e-05 - val_loss: 0.0037\n",
      "\n",
      "Epoch 00486: val_loss did not improve from 0.00328\n",
      "Epoch 487/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 3.3583e-05 - val_loss: 0.0036\n",
      "\n",
      "Epoch 00487: val_loss did not improve from 0.00328\n",
      "Epoch 488/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.5932e-05 - val_loss: 0.0037\n",
      "\n",
      "Epoch 00488: val_loss did not improve from 0.00328\n",
      "Epoch 489/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.7803e-05 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00489: val_loss did not improve from 0.00328\n",
      "Epoch 490/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.0740e-05 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00490: val_loss did not improve from 0.00328\n",
      "Epoch 491/3000\n",
      "184/184 [==============================] - ETA: 0s - loss: 1.1783e-0 - 0s 103us/step - loss: 2.4300e-05 - val_loss: 0.0037\n",
      "\n",
      "Epoch 00491: val_loss did not improve from 0.00328\n",
      "Epoch 492/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.3342e-05 - val_loss: 0.0036\n",
      "\n",
      "Epoch 00492: val_loss did not improve from 0.00328\n",
      "Epoch 493/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.2566e-05 - val_loss: 0.0038\n",
      "\n",
      "Epoch 00493: val_loss did not improve from 0.00328\n",
      "Epoch 494/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.5286e-05 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00494: val_loss did not improve from 0.00328\n",
      "Epoch 495/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.2582e-05 - val_loss: 0.0037\n",
      "\n",
      "Epoch 00495: val_loss did not improve from 0.00328\n",
      "Epoch 496/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.7769e-05 - val_loss: 0.0036\n",
      "\n",
      "Epoch 00496: val_loss did not improve from 0.00328\n",
      "Epoch 497/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.5994e-05 - val_loss: 0.0037\n",
      "\n",
      "Epoch 00497: val_loss did not improve from 0.00328\n",
      "Epoch 498/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.1242e-05 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00498: val_loss did not improve from 0.00328\n",
      "Epoch 499/3000\n",
      "184/184 [==============================] - 0s 131us/step - loss: 2.8360e-05 - val_loss: 0.0040\n",
      "\n",
      "Epoch 00499: val_loss did not improve from 0.00328\n",
      "Epoch 500/3000\n",
      "184/184 [==============================] - 0s 288us/step - loss: 2.0471e-05 - val_loss: 0.0037\n",
      "\n",
      "Epoch 00500: val_loss did not improve from 0.00328\n",
      "Epoch 501/3000\n",
      "184/184 [==============================] - 0s 190us/step - loss: 2.3583e-05 - val_loss: 0.0036\n",
      "\n",
      "Epoch 00501: val_loss did not improve from 0.00328\n",
      "Epoch 502/3000\n",
      "184/184 [==============================] - 0s 169us/step - loss: 2.7920e-05 - val_loss: 0.0038\n",
      "\n",
      "Epoch 00502: val_loss did not improve from 0.00328\n",
      "Epoch 503/3000\n",
      "184/184 [==============================] - 0s 141us/step - loss: 3.0038e-05 - val_loss: 0.0041\n",
      "\n",
      "Epoch 00503: val_loss did not improve from 0.00328\n",
      "Epoch 504/3000\n",
      "184/184 [==============================] - 0s 142us/step - loss: 2.4298e-05 - val_loss: 0.0041\n",
      "\n",
      "Epoch 00504: val_loss did not improve from 0.00328\n",
      "Epoch 505/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 2.1177e-05 - val_loss: 0.0038\n",
      "\n",
      "Epoch 00505: val_loss did not improve from 0.00328\n",
      "Epoch 506/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 2.6802e-05 - val_loss: 0.0037\n",
      "\n",
      "Epoch 00506: val_loss did not improve from 0.00328\n",
      "Epoch 507/3000\n",
      "184/184 [==============================] - 0s 131us/step - loss: 2.6725e-05 - val_loss: 0.0038\n",
      "\n",
      "Epoch 00507: val_loss did not improve from 0.00328\n",
      "Epoch 508/3000\n",
      "184/184 [==============================] - 0s 136us/step - loss: 3.0783e-05 - val_loss: 0.0042\n",
      "\n",
      "Epoch 00508: val_loss did not improve from 0.00328\n",
      "Epoch 509/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 3.2604e-05 - val_loss: 0.0043\n",
      "\n",
      "Epoch 00509: val_loss did not improve from 0.00328\n",
      "Epoch 510/3000\n",
      "184/184 [==============================] - 0s 136us/step - loss: 3.0468e-05 - val_loss: 0.0041\n",
      "\n",
      "Epoch 00510: val_loss did not improve from 0.00328\n",
      "Epoch 511/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 2.3148e-05 - val_loss: 0.0038\n",
      "\n",
      "Epoch 00511: val_loss did not improve from 0.00328\n",
      "Epoch 512/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 2.8980e-05 - val_loss: 0.0037\n",
      "\n",
      "Epoch 00512: val_loss did not improve from 0.00328\n",
      "Epoch 513/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 3.2623e-05 - val_loss: 0.0037\n",
      "\n",
      "Epoch 00513: val_loss did not improve from 0.00328\n",
      "Epoch 514/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.4592e-05 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00514: val_loss did not improve from 0.00328\n",
      "Epoch 515/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.7692e-05 - val_loss: 0.0040\n",
      "\n",
      "Epoch 00515: val_loss did not improve from 0.00328\n",
      "Epoch 516/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.2881e-05 - val_loss: 0.0038\n",
      "\n",
      "Epoch 00516: val_loss did not improve from 0.00328\n",
      "Epoch 517/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.4327e-05 - val_loss: 0.0036\n",
      "\n",
      "Epoch 00517: val_loss did not improve from 0.00328\n",
      "Epoch 518/3000\n",
      "184/184 [==============================] - 0s 81us/step - loss: 2.2873e-05 - val_loss: 0.0036\n",
      "\n",
      "Epoch 00518: val_loss did not improve from 0.00328\n",
      "Epoch 519/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.6274e-05 - val_loss: 0.0038\n",
      "\n",
      "Epoch 00519: val_loss did not improve from 0.00328\n",
      "Epoch 520/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 103us/step - loss: 2.7007e-05 - val_loss: 0.0038\n",
      "\n",
      "Epoch 00520: val_loss did not improve from 0.00328\n",
      "Epoch 521/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.1873e-05 - val_loss: 0.0036\n",
      "\n",
      "Epoch 00521: val_loss did not improve from 0.00328\n",
      "Epoch 522/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 3.1898e-05 - val_loss: 0.0036\n",
      "\n",
      "Epoch 00522: val_loss did not improve from 0.00328\n",
      "Epoch 523/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.3801e-05 - val_loss: 0.0038\n",
      "\n",
      "Epoch 00523: val_loss did not improve from 0.00328\n",
      "Epoch 524/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.6560e-05 - val_loss: 0.0038\n",
      "\n",
      "Epoch 00524: val_loss did not improve from 0.00328\n",
      "Epoch 525/3000\n",
      "184/184 [==============================] - 0s 152us/step - loss: 2.4759e-05 - val_loss: 0.0036\n",
      "\n",
      "Epoch 00525: val_loss did not improve from 0.00328\n",
      "Epoch 526/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.6330e-05 - val_loss: 0.0035\n",
      "\n",
      "Epoch 00526: val_loss did not improve from 0.00328\n",
      "Epoch 527/3000\n",
      "184/184 [==============================] - 0s 93us/step - loss: 2.3803e-05 - val_loss: 0.0036\n",
      "\n",
      "Epoch 00527: val_loss did not improve from 0.00328\n",
      "Epoch 528/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.7654e-05 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00528: val_loss did not improve from 0.00328\n",
      "Epoch 529/3000\n",
      "184/184 [==============================] - ETA: 0s - loss: 1.2031e-0 - 0s 109us/step - loss: 2.9652e-05 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00529: val_loss did not improve from 0.00328\n",
      "Epoch 530/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.4675e-05 - val_loss: 0.0038\n",
      "\n",
      "Epoch 00530: val_loss did not improve from 0.00328\n",
      "Epoch 531/3000\n",
      "184/184 [==============================] - 0s 130us/step - loss: 2.3126e-05 - val_loss: 0.0037\n",
      "\n",
      "Epoch 00531: val_loss did not improve from 0.00328\n",
      "Epoch 532/3000\n",
      "184/184 [==============================] - 0s 120us/step - loss: 2.4880e-05 - val_loss: 0.0038\n",
      "\n",
      "Epoch 00532: val_loss did not improve from 0.00328\n",
      "Epoch 533/3000\n",
      "184/184 [==============================] - 0s 119us/step - loss: 2.2229e-05 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00533: val_loss did not improve from 0.00328\n",
      "Epoch 534/3000\n",
      "184/184 [==============================] - 0s 304us/step - loss: 2.2058e-05 - val_loss: 0.0038\n",
      "\n",
      "Epoch 00534: val_loss did not improve from 0.00328\n",
      "Epoch 535/3000\n",
      "184/184 [==============================] - 0s 277us/step - loss: 2.7058e-05 - val_loss: 0.0036\n",
      "\n",
      "Epoch 00535: val_loss did not improve from 0.00328\n",
      "Epoch 536/3000\n",
      "184/184 [==============================] - 0s 179us/step - loss: 2.8527e-05 - val_loss: 0.0037\n",
      "\n",
      "Epoch 00536: val_loss did not improve from 0.00328\n",
      "Epoch 537/3000\n",
      "184/184 [==============================] - 0s 179us/step - loss: 2.1377e-05 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00537: val_loss did not improve from 0.00328\n",
      "Epoch 538/3000\n",
      "184/184 [==============================] - 0s 142us/step - loss: 2.4357e-05 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00538: val_loss did not improve from 0.00328\n",
      "Epoch 539/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 2.6263e-05 - val_loss: 0.0038\n",
      "\n",
      "Epoch 00539: val_loss did not improve from 0.00328\n",
      "Epoch 540/3000\n",
      "184/184 [==============================] - 0s 152us/step - loss: 2.3112e-05 - val_loss: 0.0036\n",
      "\n",
      "Epoch 00540: val_loss did not improve from 0.00328\n",
      "Epoch 541/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.1648e-05 - val_loss: 0.0035\n",
      "\n",
      "Epoch 00541: val_loss did not improve from 0.00328\n",
      "Epoch 542/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.4346e-05 - val_loss: 0.0035\n",
      "\n",
      "Epoch 00542: val_loss did not improve from 0.00328\n",
      "Epoch 543/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.3430e-05 - val_loss: 0.0037\n",
      "\n",
      "Epoch 00543: val_loss did not improve from 0.00328\n",
      "Epoch 544/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.7310e-05 - val_loss: 0.0038\n",
      "\n",
      "Epoch 00544: val_loss did not improve from 0.00328\n",
      "Epoch 545/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.4543e-05 - val_loss: 0.0038\n",
      "\n",
      "Epoch 00545: val_loss did not improve from 0.00328\n",
      "Epoch 546/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.8443e-05 - val_loss: 0.0037\n",
      "\n",
      "Epoch 00546: val_loss did not improve from 0.00328\n",
      "Epoch 547/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.3671e-05 - val_loss: 0.0036\n",
      "\n",
      "Epoch 00547: val_loss did not improve from 0.00328\n",
      "Epoch 548/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.8179e-05 - val_loss: 0.0036\n",
      "\n",
      "Epoch 00548: val_loss did not improve from 0.00328\n",
      "Epoch 549/3000\n",
      "184/184 [==============================] - 0s 130us/step - loss: 2.1578e-05 - val_loss: 0.0038\n",
      "\n",
      "Epoch 00549: val_loss did not improve from 0.00328\n",
      "Epoch 550/3000\n",
      "184/184 [==============================] - 0s 152us/step - loss: 2.8808e-05 - val_loss: 0.0041\n",
      "\n",
      "Epoch 00550: val_loss did not improve from 0.00328\n",
      "Epoch 551/3000\n",
      "184/184 [==============================] - 0s 190us/step - loss: 2.6668e-05 - val_loss: 0.0041\n",
      "\n",
      "Epoch 00551: val_loss did not improve from 0.00328\n",
      "Epoch 552/3000\n",
      "184/184 [==============================] - 0s 147us/step - loss: 2.6845e-05 - val_loss: 0.0038\n",
      "\n",
      "Epoch 00552: val_loss did not improve from 0.00328\n",
      "Epoch 553/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.1885e-05 - val_loss: 0.0036\n",
      "\n",
      "Epoch 00553: val_loss did not improve from 0.00328\n",
      "Epoch 554/3000\n",
      "184/184 [==============================] - 0s 119us/step - loss: 3.0234e-05 - val_loss: 0.0035\n",
      "\n",
      "Epoch 00554: val_loss did not improve from 0.00328\n",
      "Epoch 555/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.9636e-05 - val_loss: 0.0036\n",
      "\n",
      "Epoch 00555: val_loss did not improve from 0.00328\n",
      "Epoch 556/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.3747e-05 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00556: val_loss did not improve from 0.00328\n",
      "Epoch 557/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 3.0882e-05 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00557: val_loss did not improve from 0.00328\n",
      "Epoch 558/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.4471e-05 - val_loss: 0.0036\n",
      "\n",
      "Epoch 00558: val_loss did not improve from 0.00328\n",
      "Epoch 559/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 2.3835e-05 - val_loss: 0.0034\n",
      "\n",
      "Epoch 00559: val_loss did not improve from 0.00328\n",
      "Epoch 560/3000\n",
      "184/184 [==============================] - 0s 147us/step - loss: 2.5494e-05 - val_loss: 0.0036\n",
      "\n",
      "Epoch 00560: val_loss did not improve from 0.00328\n",
      "Epoch 561/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.3488e-05 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00561: val_loss did not improve from 0.00328\n",
      "Epoch 562/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 3.0151e-05 - val_loss: 0.0041\n",
      "\n",
      "Epoch 00562: val_loss did not improve from 0.00328\n",
      "Epoch 563/3000\n",
      "184/184 [==============================] - 0s 119us/step - loss: 2.8511e-05 - val_loss: 0.0038\n",
      "\n",
      "Epoch 00563: val_loss did not improve from 0.00328\n",
      "Epoch 564/3000\n",
      "184/184 [==============================] - 0s 130us/step - loss: 2.4196e-05 - val_loss: 0.0037\n",
      "\n",
      "Epoch 00564: val_loss did not improve from 0.00328\n",
      "Epoch 565/3000\n",
      "184/184 [==============================] - 0s 136us/step - loss: 3.0118e-05 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00565: val_loss did not improve from 0.00328\n",
      "Epoch 566/3000\n",
      "184/184 [==============================] - 0s 147us/step - loss: 1.9130e-05 - val_loss: 0.0041\n",
      "\n",
      "Epoch 00566: val_loss did not improve from 0.00328\n",
      "Epoch 567/3000\n",
      "184/184 [==============================] - 0s 152us/step - loss: 2.6688e-05 - val_loss: 0.0043\n",
      "\n",
      "Epoch 00567: val_loss did not improve from 0.00328\n",
      "Epoch 568/3000\n",
      "184/184 [==============================] - 0s 163us/step - loss: 2.9796e-05 - val_loss: 0.0040\n",
      "\n",
      "Epoch 00568: val_loss did not improve from 0.00328\n",
      "Epoch 569/3000\n",
      "184/184 [==============================] - 0s 169us/step - loss: 2.1252e-05 - val_loss: 0.0038\n",
      "\n",
      "Epoch 00569: val_loss did not improve from 0.00328\n",
      "Epoch 570/3000\n",
      "184/184 [==============================] - 0s 130us/step - loss: 2.8528e-05 - val_loss: 0.0038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00570: val_loss did not improve from 0.00328\n",
      "Epoch 571/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.4081e-05 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00571: val_loss did not improve from 0.00328\n",
      "Epoch 572/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 1.8707e-05 - val_loss: 0.0040\n",
      "\n",
      "Epoch 00572: val_loss did not improve from 0.00328\n",
      "Epoch 573/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.6522e-05 - val_loss: 0.0041\n",
      "\n",
      "Epoch 00573: val_loss did not improve from 0.00328\n",
      "Epoch 574/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.6326e-05 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00574: val_loss did not improve from 0.00328\n",
      "Epoch 575/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.7733e-05 - val_loss: 0.0037\n",
      "\n",
      "Epoch 00575: val_loss did not improve from 0.00328\n",
      "Epoch 576/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.4634e-05 - val_loss: 0.0037\n",
      "\n",
      "Epoch 00576: val_loss did not improve from 0.00328\n",
      "Epoch 577/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 2.7757e-05 - val_loss: 0.0038\n",
      "\n",
      "Epoch 00577: val_loss did not improve from 0.00328\n",
      "Epoch 578/3000\n",
      "184/184 [==============================] - 0s 130us/step - loss: 2.7621e-05 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00578: val_loss did not improve from 0.00328\n",
      "Epoch 579/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.6353e-05 - val_loss: 0.0040\n",
      "\n",
      "Epoch 00579: val_loss did not improve from 0.00328\n",
      "Epoch 580/3000\n",
      "184/184 [==============================] - 0s 119us/step - loss: 2.8762e-05 - val_loss: 0.0040\n",
      "\n",
      "Epoch 00580: val_loss did not improve from 0.00328\n",
      "Epoch 581/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.1877e-05 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00581: val_loss did not improve from 0.00328\n",
      "Epoch 582/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.1661e-05 - val_loss: 0.0040\n",
      "\n",
      "Epoch 00582: val_loss did not improve from 0.00328\n",
      "Epoch 583/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.5263e-05 - val_loss: 0.0041\n",
      "\n",
      "Epoch 00583: val_loss did not improve from 0.00328\n",
      "Epoch 584/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.6053e-05 - val_loss: 0.0040\n",
      "\n",
      "Epoch 00584: val_loss did not improve from 0.00328\n",
      "Epoch 585/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.5074e-05 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00585: val_loss did not improve from 0.00328\n",
      "Epoch 586/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 2.2995e-05 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00586: val_loss did not improve from 0.00328\n",
      "Epoch 587/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.9136e-05 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00587: val_loss did not improve from 0.00328\n",
      "Epoch 588/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.0185e-05 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00588: val_loss did not improve from 0.00328\n",
      "Epoch 589/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.1799e-05 - val_loss: 0.0040\n",
      "\n",
      "Epoch 00589: val_loss did not improve from 0.00328\n",
      "Epoch 590/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.7218e-05 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00590: val_loss did not improve from 0.00328\n",
      "Epoch 591/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 2.4951e-05 - val_loss: 0.0038\n",
      "\n",
      "Epoch 00591: val_loss did not improve from 0.00328\n",
      "Epoch 592/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.4850e-05 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00592: val_loss did not improve from 0.00328\n",
      "Epoch 593/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.6758e-05 - val_loss: 0.0041\n",
      "\n",
      "Epoch 00593: val_loss did not improve from 0.00328\n",
      "Epoch 594/3000\n",
      "184/184 [==============================] - 0s 99us/step - loss: 2.6283e-05 - val_loss: 0.0041\n",
      "\n",
      "Epoch 00594: val_loss did not improve from 0.00328\n",
      "Epoch 595/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.7143e-05 - val_loss: 0.0040\n",
      "\n",
      "Epoch 00595: val_loss did not improve from 0.00328\n",
      "Epoch 596/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.0461e-05 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00596: val_loss did not improve from 0.00328\n",
      "Epoch 597/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.4189e-05 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00597: val_loss did not improve from 0.00328\n",
      "Epoch 598/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.0218e-05 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00598: val_loss did not improve from 0.00328\n",
      "Epoch 599/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.1516e-05 - val_loss: 0.0041\n",
      "\n",
      "Epoch 00599: val_loss did not improve from 0.00328\n",
      "Epoch 600/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.4130e-05 - val_loss: 0.0041\n",
      "\n",
      "Epoch 00600: val_loss did not improve from 0.00328\n",
      "Epoch 601/3000\n",
      "184/184 [==============================] - 0s 163us/step - loss: 2.4132e-05 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00601: val_loss did not improve from 0.00328\n",
      "Epoch 602/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.0596e-05 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00602: val_loss did not improve from 0.00328\n",
      "Epoch 603/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.2209e-05 - val_loss: 0.0040\n",
      "\n",
      "Epoch 00603: val_loss did not improve from 0.00328\n",
      "Epoch 604/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.8853e-05 - val_loss: 0.0040\n",
      "\n",
      "Epoch 00604: val_loss did not improve from 0.00328\n",
      "Epoch 605/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.3872e-05 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00605: val_loss did not improve from 0.00328\n",
      "Epoch 606/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.2921e-05 - val_loss: 0.0040\n",
      "\n",
      "Epoch 00606: val_loss did not improve from 0.00328\n",
      "Epoch 607/3000\n",
      "184/184 [==============================] - ETA: 0s - loss: 1.2277e-0 - 0s 93us/step - loss: 2.0939e-05 - val_loss: 0.0040\n",
      "\n",
      "Epoch 00607: val_loss did not improve from 0.00328\n",
      "Epoch 608/3000\n",
      "184/184 [==============================] - 0s 136us/step - loss: 2.6424e-05 - val_loss: 0.0040\n",
      "\n",
      "Epoch 00608: val_loss did not improve from 0.00328\n",
      "Epoch 609/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 2.3377e-05 - val_loss: 0.0041\n",
      "\n",
      "Epoch 00609: val_loss did not improve from 0.00328\n",
      "Epoch 610/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 2.9375e-05 - val_loss: 0.0042\n",
      "\n",
      "Epoch 00610: val_loss did not improve from 0.00328\n",
      "Epoch 611/3000\n",
      "184/184 [==============================] - 0s 182us/step - loss: 2.0016e-05 - val_loss: 0.0040\n",
      "\n",
      "Epoch 00611: val_loss did not improve from 0.00328\n",
      "Epoch 612/3000\n",
      "184/184 [==============================] - 0s 141us/step - loss: 2.4187e-05 - val_loss: 0.0038\n",
      "\n",
      "Epoch 00612: val_loss did not improve from 0.00328\n",
      "Epoch 613/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.5115e-05 - val_loss: 0.0038\n",
      "\n",
      "Epoch 00613: val_loss did not improve from 0.00328\n",
      "Epoch 614/3000\n",
      "184/184 [==============================] - 0s 152us/step - loss: 2.4750e-05 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00614: val_loss did not improve from 0.00328\n",
      "Epoch 615/3000\n",
      "184/184 [==============================] - 0s 119us/step - loss: 2.5321e-05 - val_loss: 0.0040\n",
      "\n",
      "Epoch 00615: val_loss did not improve from 0.00328\n",
      "Epoch 616/3000\n",
      "184/184 [==============================] - 0s 408us/step - loss: 2.2175e-05 - val_loss: 0.0038\n",
      "\n",
      "Epoch 00616: val_loss did not improve from 0.00328\n",
      "Epoch 617/3000\n",
      "184/184 [==============================] - 0s 244us/step - loss: 2.2465e-05 - val_loss: 0.0037\n",
      "\n",
      "Epoch 00617: val_loss did not improve from 0.00328\n",
      "Epoch 618/3000\n",
      "184/184 [==============================] - 0s 174us/step - loss: 2.2506e-05 - val_loss: 0.0038\n",
      "\n",
      "Epoch 00618: val_loss did not improve from 0.00328\n",
      "Epoch 619/3000\n",
      "184/184 [==============================] - 0s 201us/step - loss: 2.1830e-05 - val_loss: 0.0040\n",
      "\n",
      "Epoch 00619: val_loss did not improve from 0.00328\n",
      "Epoch 620/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.6464e-05 - val_loss: 0.0041\n",
      "\n",
      "Epoch 00620: val_loss did not improve from 0.00328\n",
      "Epoch 621/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 109us/step - loss: 2.0710e-05 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00621: val_loss did not improve from 0.00328\n",
      "Epoch 622/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.0816e-05 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00622: val_loss did not improve from 0.00328\n",
      "Epoch 623/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.4175e-05 - val_loss: 0.0038\n",
      "\n",
      "Epoch 00623: val_loss did not improve from 0.00328\n",
      "Epoch 624/3000\n",
      "184/184 [==============================] - 0s 119us/step - loss: 2.4563e-05 - val_loss: 0.0038\n",
      "\n",
      "Epoch 00624: val_loss did not improve from 0.00328\n",
      "Epoch 625/3000\n",
      "184/184 [==============================] - 0s 136us/step - loss: 2.7278e-05 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00625: val_loss did not improve from 0.00328\n",
      "Epoch 626/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.2493e-05 - val_loss: 0.0040\n",
      "\n",
      "Epoch 00626: val_loss did not improve from 0.00328\n",
      "Epoch 627/3000\n",
      "184/184 [==============================] - ETA: 0s - loss: 1.0958e-0 - 0s 92us/step - loss: 2.7857e-05 - val_loss: 0.0040\n",
      "\n",
      "Epoch 00627: val_loss did not improve from 0.00328\n",
      "Epoch 628/3000\n",
      "184/184 [==============================] - 0s 120us/step - loss: 2.1302e-05 - val_loss: 0.0038\n",
      "\n",
      "Epoch 00628: val_loss did not improve from 0.00328\n",
      "Epoch 629/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.6277e-05 - val_loss: 0.0038\n",
      "\n",
      "Epoch 00629: val_loss did not improve from 0.00328\n",
      "Epoch 630/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.6167e-05 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00630: val_loss did not improve from 0.00328\n",
      "Epoch 631/3000\n",
      "184/184 [==============================] - 0s 147us/step - loss: 2.0082e-05 - val_loss: 0.0040\n",
      "\n",
      "Epoch 00631: val_loss did not improve from 0.00328\n",
      "Epoch 632/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 2.0190e-05 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00632: val_loss did not improve from 0.00328\n",
      "Epoch 633/3000\n",
      "184/184 [==============================] - 0s 244us/step - loss: 2.7640e-05 - val_loss: 0.0038\n",
      "\n",
      "Epoch 00633: val_loss did not improve from 0.00328\n",
      "Epoch 634/3000\n",
      "184/184 [==============================] - 0s 380us/step - loss: 2.1285e-05 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00634: val_loss did not improve from 0.00328\n",
      "Epoch 635/3000\n",
      "184/184 [==============================] - 0s 131us/step - loss: 2.3465e-05 - val_loss: 0.0040\n",
      "\n",
      "Epoch 00635: val_loss did not improve from 0.00328\n",
      "Epoch 636/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.5308e-05 - val_loss: 0.0040\n",
      "\n",
      "Epoch 00636: val_loss did not improve from 0.00328\n",
      "Epoch 637/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.2740e-05 - val_loss: 0.0042\n",
      "\n",
      "Epoch 00637: val_loss did not improve from 0.00328\n",
      "Epoch 638/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 1.8631e-05 - val_loss: 0.0043\n",
      "\n",
      "Epoch 00638: val_loss did not improve from 0.00328\n",
      "Epoch 639/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.6880e-05 - val_loss: 0.0041\n",
      "\n",
      "Epoch 00639: val_loss did not improve from 0.00328\n",
      "Epoch 640/3000\n",
      "184/184 [==============================] - 0s 120us/step - loss: 2.3805e-05 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00640: val_loss did not improve from 0.00328\n",
      "Epoch 641/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.6382e-05 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00641: val_loss did not improve from 0.00328\n",
      "Epoch 642/3000\n",
      "184/184 [==============================] - 0s 120us/step - loss: 2.3502e-05 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00642: val_loss did not improve from 0.00328\n",
      "Epoch 643/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.7635e-05 - val_loss: 0.0038\n",
      "\n",
      "Epoch 00643: val_loss did not improve from 0.00328\n",
      "Epoch 644/3000\n",
      "184/184 [==============================] - 0s 136us/step - loss: 2.3931e-05 - val_loss: 0.0037\n",
      "\n",
      "Epoch 00644: val_loss did not improve from 0.00328\n",
      "Epoch 645/3000\n",
      "184/184 [==============================] - 0s 120us/step - loss: 2.3612e-05 - val_loss: 0.0038\n",
      "\n",
      "Epoch 00645: val_loss did not improve from 0.00328\n",
      "Epoch 646/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.6074e-05 - val_loss: 0.0038\n",
      "\n",
      "Epoch 00646: val_loss did not improve from 0.00328\n",
      "Epoch 647/3000\n",
      "184/184 [==============================] - 0s 206us/step - loss: 2.4665e-05 - val_loss: 0.0038\n",
      "\n",
      "Epoch 00647: val_loss did not improve from 0.00328\n",
      "Epoch 648/3000\n",
      "184/184 [==============================] - 0s 245us/step - loss: 2.4667e-05 - val_loss: 0.0038\n",
      "\n",
      "Epoch 00648: val_loss did not improve from 0.00328\n",
      "Epoch 649/3000\n",
      "184/184 [==============================] - 0s 190us/step - loss: 2.6257e-05 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00649: val_loss did not improve from 0.00328\n",
      "Epoch 650/3000\n",
      "184/184 [==============================] - 0s 119us/step - loss: 2.2411e-05 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00650: val_loss did not improve from 0.00328\n",
      "Epoch 651/3000\n",
      "184/184 [==============================] - 0s 136us/step - loss: 2.1938e-05 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00651: val_loss did not improve from 0.00328\n",
      "Epoch 652/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.4801e-05 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00652: val_loss did not improve from 0.00328\n",
      "Epoch 653/3000\n",
      "184/184 [==============================] - 0s 106us/step - loss: 1.9324e-05 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00653: val_loss did not improve from 0.00328\n",
      "Epoch 654/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 1.9217e-05 - val_loss: 0.0040\n",
      "\n",
      "Epoch 00654: val_loss did not improve from 0.00328\n",
      "Epoch 655/3000\n",
      "184/184 [==============================] - ETA: 0s - loss: 1.1141e-0 - 0s 125us/step - loss: 2.5315e-05 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00655: val_loss did not improve from 0.00328\n",
      "Epoch 656/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 1.8864e-05 - val_loss: 0.0037\n",
      "\n",
      "Epoch 00656: val_loss did not improve from 0.00328\n",
      "Epoch 657/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.4639e-05 - val_loss: 0.0036\n",
      "\n",
      "Epoch 00657: val_loss did not improve from 0.00328\n",
      "Epoch 658/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.4259e-05 - val_loss: 0.0037\n",
      "\n",
      "Epoch 00658: val_loss did not improve from 0.00328\n",
      "Epoch 659/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.3022e-05 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00659: val_loss did not improve from 0.00328\n",
      "Epoch 660/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.4157e-05 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00660: val_loss did not improve from 0.00328\n",
      "Epoch 661/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.5380e-05 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00661: val_loss did not improve from 0.00328\n",
      "Epoch 662/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.2156e-05 - val_loss: 0.0038\n",
      "\n",
      "Epoch 00662: val_loss did not improve from 0.00328\n",
      "Epoch 663/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.4996e-05 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00663: val_loss did not improve from 0.00328\n",
      "Epoch 664/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.4899e-05 - val_loss: 0.0041\n",
      "\n",
      "Epoch 00664: val_loss did not improve from 0.00328\n",
      "Epoch 665/3000\n",
      "184/184 [==============================] - 0s 93us/step - loss: 2.9048e-05 - val_loss: 0.0042\n",
      "\n",
      "Epoch 00665: val_loss did not improve from 0.00328\n",
      "Epoch 666/3000\n",
      "184/184 [==============================] - 0s 152us/step - loss: 2.5980e-05 - val_loss: 0.0043\n",
      "\n",
      "Epoch 00666: val_loss did not improve from 0.00328\n",
      "Epoch 667/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.5021e-05 - val_loss: 0.0042\n",
      "\n",
      "Epoch 00667: val_loss did not improve from 0.00328\n",
      "Epoch 668/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 3.1237e-05 - val_loss: 0.0041\n",
      "\n",
      "Epoch 00668: val_loss did not improve from 0.00328\n",
      "Epoch 669/3000\n",
      "184/184 [==============================] - 0s 128us/step - loss: 2.4390e-05 - val_loss: 0.0042\n",
      "\n",
      "Epoch 00669: val_loss did not improve from 0.00328\n",
      "Epoch 670/3000\n",
      "184/184 [==============================] - 0s 179us/step - loss: 2.9493e-05 - val_loss: 0.0041\n",
      "\n",
      "Epoch 00670: val_loss did not improve from 0.00328\n",
      "Epoch 671/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 109us/step - loss: 2.5070e-05 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00671: val_loss did not improve from 0.00328\n",
      "Epoch 672/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.4574e-05 - val_loss: 0.0038\n",
      "\n",
      "Epoch 00672: val_loss did not improve from 0.00328\n",
      "Epoch 673/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.3419e-05 - val_loss: 0.0040\n",
      "\n",
      "Epoch 00673: val_loss did not improve from 0.00328\n",
      "Epoch 674/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.2553e-05 - val_loss: 0.0041\n",
      "\n",
      "Epoch 00674: val_loss did not improve from 0.00328\n",
      "Epoch 675/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.6276e-05 - val_loss: 0.0042\n",
      "\n",
      "Epoch 00675: val_loss did not improve from 0.00328\n",
      "Epoch 676/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.1378e-05 - val_loss: 0.0041\n",
      "\n",
      "Epoch 00676: val_loss did not improve from 0.00328\n",
      "Epoch 677/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.1704e-05 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00677: val_loss did not improve from 0.00328\n",
      "Epoch 678/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.1345e-05 - val_loss: 0.0040\n",
      "\n",
      "Epoch 00678: val_loss did not improve from 0.00328\n",
      "Epoch 679/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.7288e-05 - val_loss: 0.0042\n",
      "\n",
      "Epoch 00679: val_loss did not improve from 0.00328\n",
      "Epoch 680/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.4738e-05 - val_loss: 0.0042\n",
      "\n",
      "Epoch 00680: val_loss did not improve from 0.00328\n",
      "Epoch 681/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.6149e-05 - val_loss: 0.0040\n",
      "\n",
      "Epoch 00681: val_loss did not improve from 0.00328\n",
      "Epoch 682/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.0955e-05 - val_loss: 0.0040\n",
      "\n",
      "Epoch 00682: val_loss did not improve from 0.00328\n",
      "Epoch 683/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.2583e-05 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00683: val_loss did not improve from 0.00328\n",
      "Epoch 684/3000\n",
      "184/184 [==============================] - 0s 81us/step - loss: 2.6301e-05 - val_loss: 0.0040\n",
      "\n",
      "Epoch 00684: val_loss did not improve from 0.00328\n",
      "Epoch 685/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.7190e-05 - val_loss: 0.0041\n",
      "\n",
      "Epoch 00685: val_loss did not improve from 0.00328\n",
      "Epoch 686/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.5183e-05 - val_loss: 0.0042\n",
      "\n",
      "Epoch 00686: val_loss did not improve from 0.00328\n",
      "Epoch 687/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.4857e-05 - val_loss: 0.0040\n",
      "\n",
      "Epoch 00687: val_loss did not improve from 0.00328\n",
      "Epoch 688/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.1618e-05 - val_loss: 0.0038\n",
      "\n",
      "Epoch 00688: val_loss did not improve from 0.00328\n",
      "Epoch 689/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.9819e-05 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00689: val_loss did not improve from 0.00328\n",
      "Epoch 690/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.2687e-05 - val_loss: 0.0043\n",
      "\n",
      "Epoch 00690: val_loss did not improve from 0.00328\n",
      "Epoch 691/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.6119e-05 - val_loss: 0.0043\n",
      "\n",
      "Epoch 00691: val_loss did not improve from 0.00328\n",
      "Epoch 692/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.2642e-05 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00692: val_loss did not improve from 0.00328\n",
      "Epoch 693/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.2604e-05 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00693: val_loss did not improve from 0.00328\n",
      "Epoch 694/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.4897e-05 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00694: val_loss did not improve from 0.00328\n",
      "Epoch 695/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.6630e-05 - val_loss: 0.0040\n",
      "\n",
      "Epoch 00695: val_loss did not improve from 0.00328\n",
      "Epoch 696/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.7335e-05 - val_loss: 0.0041\n",
      "\n",
      "Epoch 00696: val_loss did not improve from 0.00328\n",
      "Epoch 697/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.3184e-05 - val_loss: 0.0042\n",
      "\n",
      "Epoch 00697: val_loss did not improve from 0.00328\n",
      "Epoch 698/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.4691e-05 - val_loss: 0.0041\n",
      "\n",
      "Epoch 00698: val_loss did not improve from 0.00328\n",
      "Epoch 699/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.2471e-05 - val_loss: 0.0040\n",
      "\n",
      "Epoch 00699: val_loss did not improve from 0.00328\n",
      "Epoch 700/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.5873e-05 - val_loss: 0.0041\n",
      "\n",
      "Epoch 00700: val_loss did not improve from 0.00328\n",
      "Epoch 701/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.4083e-05 - val_loss: 0.0044\n",
      "\n",
      "Epoch 00701: val_loss did not improve from 0.00328\n",
      "Epoch 702/3000\n",
      "184/184 [==============================] - 0s 93us/step - loss: 2.3341e-05 - val_loss: 0.0042\n",
      "\n",
      "Epoch 00702: val_loss did not improve from 0.00328\n",
      "Epoch 703/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.0035e-05 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00703: val_loss did not improve from 0.00328\n",
      "Epoch 704/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 3.0858e-05 - val_loss: 0.0038\n",
      "\n",
      "Epoch 00704: val_loss did not improve from 0.00328\n",
      "Epoch 705/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.4709e-05 - val_loss: 0.0042\n",
      "\n",
      "Epoch 00705: val_loss did not improve from 0.00328\n",
      "Epoch 706/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.7331e-05 - val_loss: 0.0043\n",
      "\n",
      "Epoch 00706: val_loss did not improve from 0.00328\n",
      "Epoch 707/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.4489e-05 - val_loss: 0.0041\n",
      "\n",
      "Epoch 00707: val_loss did not improve from 0.00328\n",
      "Epoch 708/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.4653e-05 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00708: val_loss did not improve from 0.00328\n",
      "Epoch 709/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.7652e-05 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00709: val_loss did not improve from 0.00328\n",
      "Epoch 710/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.1376e-05 - val_loss: 0.0043\n",
      "\n",
      "Epoch 00710: val_loss did not improve from 0.00328\n",
      "Epoch 711/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.4679e-05 - val_loss: 0.0045\n",
      "\n",
      "Epoch 00711: val_loss did not improve from 0.00328\n",
      "Epoch 712/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.4892e-05 - val_loss: 0.0041\n",
      "\n",
      "Epoch 00712: val_loss did not improve from 0.00328\n",
      "Epoch 713/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.5461e-05 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00713: val_loss did not improve from 0.00328\n",
      "Epoch 714/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.5290e-05 - val_loss: 0.0042\n",
      "\n",
      "Epoch 00714: val_loss did not improve from 0.00328\n",
      "Epoch 715/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.4150e-05 - val_loss: 0.0045\n",
      "\n",
      "Epoch 00715: val_loss did not improve from 0.00328\n",
      "Epoch 716/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 3.2506e-05 - val_loss: 0.0044\n",
      "\n",
      "Epoch 00716: val_loss did not improve from 0.00328\n",
      "Epoch 717/3000\n",
      "184/184 [==============================] - 0s 163us/step - loss: 1.8263e-05 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00717: val_loss did not improve from 0.00328\n",
      "Epoch 718/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.8870e-05 - val_loss: 0.0040\n",
      "\n",
      "Epoch 00718: val_loss did not improve from 0.00328\n",
      "Epoch 719/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.6629e-05 - val_loss: 0.0045\n",
      "\n",
      "Epoch 00719: val_loss did not improve from 0.00328\n",
      "Epoch 720/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 3.1035e-05 - val_loss: 0.0048\n",
      "\n",
      "Epoch 00720: val_loss did not improve from 0.00328\n",
      "Epoch 721/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.4916e-05 - val_loss: 0.0044\n",
      "\n",
      "Epoch 00721: val_loss did not improve from 0.00328\n",
      "Epoch 722/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 87us/step - loss: 2.1441e-05 - val_loss: 0.0040\n",
      "\n",
      "Epoch 00722: val_loss did not improve from 0.00328\n",
      "Epoch 723/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 3.0749e-05 - val_loss: 0.0040\n",
      "\n",
      "Epoch 00723: val_loss did not improve from 0.00328\n",
      "Epoch 724/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.9144e-05 - val_loss: 0.0042\n",
      "\n",
      "Epoch 00724: val_loss did not improve from 0.00328\n",
      "Epoch 725/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 1.8735e-05 - val_loss: 0.0043\n",
      "\n",
      "Epoch 00725: val_loss did not improve from 0.00328\n",
      "Epoch 726/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.5379e-05 - val_loss: 0.0042\n",
      "\n",
      "Epoch 00726: val_loss did not improve from 0.00328\n",
      "Epoch 727/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.0523e-05 - val_loss: 0.0039\n",
      "\n",
      "Epoch 00727: val_loss did not improve from 0.00328\n",
      "Epoch 728/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.4782e-05 - val_loss: 0.0037\n",
      "\n",
      "Epoch 00728: val_loss did not improve from 0.00328\n",
      "Epoch 729/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.6742e-05 - val_loss: 0.0040\n",
      "\n",
      "Epoch 00729: val_loss did not improve from 0.00328\n",
      "Epoch 730/3000\n",
      "184/184 [==============================] - ETA: 0s - loss: 1.1703e-0 - 0s 98us/step - loss: 2.6671e-05 - val_loss: 0.0045\n",
      "\n",
      "Epoch 00730: val_loss did not improve from 0.00328\n",
      "Epoch 731/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.5524e-05 - val_loss: 0.0044\n",
      "\n",
      "Epoch 00731: val_loss did not improve from 0.00328\n",
      "Epoch 732/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.3512e-05 - val_loss: 0.0041\n",
      "\n",
      "Epoch 00732: val_loss did not improve from 0.00328\n",
      "Epoch 733/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.5845e-05 - val_loss: 0.0042\n",
      "\n",
      "Epoch 00733: val_loss did not improve from 0.00328\n",
      "Epoch 734/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.6190e-05 - val_loss: 0.0043\n",
      "\n",
      "Epoch 00734: val_loss did not improve from 0.00328\n",
      "Epoch 735/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.5653e-05 - val_loss: 0.0044\n",
      "\n",
      "Epoch 00735: val_loss did not improve from 0.00328\n",
      "Epoch 736/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.0953e-05 - val_loss: 0.0044\n",
      "\n",
      "Epoch 00736: val_loss did not improve from 0.00328\n",
      "Epoch 737/3000\n",
      "184/184 [==============================] - 0s 81us/step - loss: 2.5477e-05 - val_loss: 0.0044\n",
      "\n",
      "Epoch 00737: val_loss did not improve from 0.00328\n",
      "Epoch 738/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.4772e-05 - val_loss: 0.0044\n",
      "\n",
      "Epoch 00738: val_loss did not improve from 0.00328\n",
      "Epoch 739/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 2.1875e-05 - val_loss: 0.0044\n",
      "\n",
      "Epoch 00739: val_loss did not improve from 0.00328\n",
      "Epoch 740/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.6640e-05 - val_loss: 0.0043\n",
      "\n",
      "Epoch 00740: val_loss did not improve from 0.00328\n",
      "Epoch 741/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.2100e-05 - val_loss: 0.0043\n",
      "\n",
      "Epoch 00741: val_loss did not improve from 0.00328\n",
      "Epoch 742/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.2716e-05 - val_loss: 0.0043\n",
      "\n",
      "Epoch 00742: val_loss did not improve from 0.00328\n",
      "Epoch 743/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.2235e-05 - val_loss: 0.0044\n",
      "\n",
      "Epoch 00743: val_loss did not improve from 0.00328\n",
      "Epoch 744/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.8755e-05 - val_loss: 0.0044\n",
      "\n",
      "Epoch 00744: val_loss did not improve from 0.00328\n",
      "Epoch 745/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.1799e-05 - val_loss: 0.0043\n",
      "\n",
      "Epoch 00745: val_loss did not improve from 0.00328\n",
      "Epoch 746/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.6404e-05 - val_loss: 0.0045\n",
      "\n",
      "Epoch 00746: val_loss did not improve from 0.00328\n",
      "Epoch 747/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.3923e-05 - val_loss: 0.0046\n",
      "\n",
      "Epoch 00747: val_loss did not improve from 0.00328\n",
      "Epoch 748/3000\n",
      "184/184 [==============================] - 0s 119us/step - loss: 2.0396e-05 - val_loss: 0.0045\n",
      "\n",
      "Epoch 00748: val_loss did not improve from 0.00328\n",
      "Epoch 749/3000\n",
      "184/184 [==============================] - ETA: 0s - loss: 1.3159e-0 - 0s 87us/step - loss: 1.9902e-05 - val_loss: 0.0045\n",
      "\n",
      "Epoch 00749: val_loss did not improve from 0.00328\n",
      "Epoch 750/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.2410e-05 - val_loss: 0.0044\n",
      "\n",
      "Epoch 00750: val_loss did not improve from 0.00328\n",
      "Epoch 751/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.0422e-05 - val_loss: 0.0045\n",
      "\n",
      "Epoch 00751: val_loss did not improve from 0.00328\n",
      "Epoch 752/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.1101e-05 - val_loss: 0.0046\n",
      "\n",
      "Epoch 00752: val_loss did not improve from 0.00328\n",
      "Epoch 753/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.0975e-05 - val_loss: 0.0044\n",
      "\n",
      "Epoch 00753: val_loss did not improve from 0.00328\n",
      "Epoch 754/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 1.9877e-05 - val_loss: 0.0043\n",
      "\n",
      "Epoch 00754: val_loss did not improve from 0.00328\n",
      "Epoch 755/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.4732e-05 - val_loss: 0.0043\n",
      "\n",
      "Epoch 00755: val_loss did not improve from 0.00328\n",
      "Epoch 756/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 1.8922e-05 - val_loss: 0.0045\n",
      "\n",
      "Epoch 00756: val_loss did not improve from 0.00328\n",
      "Epoch 757/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.4371e-05 - val_loss: 0.0046\n",
      "\n",
      "Epoch 00757: val_loss did not improve from 0.00328\n",
      "Epoch 758/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.4594e-05 - val_loss: 0.0045\n",
      "\n",
      "Epoch 00758: val_loss did not improve from 0.00328\n",
      "Epoch 759/3000\n",
      "184/184 [==============================] - ETA: 0s - loss: 1.1680e-0 - 0s 103us/step - loss: 2.1394e-05 - val_loss: 0.0041\n",
      "\n",
      "Epoch 00759: val_loss did not improve from 0.00328\n",
      "Epoch 760/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.6392e-05 - val_loss: 0.0040\n",
      "\n",
      "Epoch 00760: val_loss did not improve from 0.00328\n",
      "Epoch 761/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.3903e-05 - val_loss: 0.0043\n",
      "\n",
      "Epoch 00761: val_loss did not improve from 0.00328\n",
      "Epoch 762/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.3414e-05 - val_loss: 0.0046\n",
      "\n",
      "Epoch 00762: val_loss did not improve from 0.00328\n",
      "Epoch 763/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 3.2375e-05 - val_loss: 0.0045\n",
      "\n",
      "Epoch 00763: val_loss did not improve from 0.00328\n",
      "Epoch 764/3000\n",
      "184/184 [==============================] - 0s 130us/step - loss: 2.6038e-05 - val_loss: 0.0041\n",
      "\n",
      "Epoch 00764: val_loss did not improve from 0.00328\n",
      "Epoch 765/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 3.2621e-05 - val_loss: 0.0040\n",
      "\n",
      "Epoch 00765: val_loss did not improve from 0.00328\n",
      "Epoch 766/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.7538e-05 - val_loss: 0.0044\n",
      "\n",
      "Epoch 00766: val_loss did not improve from 0.00328\n",
      "Epoch 767/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.7520e-05 - val_loss: 0.0045\n",
      "\n",
      "Epoch 00767: val_loss did not improve from 0.00328\n",
      "Epoch 768/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.1639e-05 - val_loss: 0.0043\n",
      "\n",
      "Epoch 00768: val_loss did not improve from 0.00328\n",
      "Epoch 769/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.6822e-05 - val_loss: 0.0042\n",
      "\n",
      "Epoch 00769: val_loss did not improve from 0.00328\n",
      "Epoch 770/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.5107e-05 - val_loss: 0.0044\n",
      "\n",
      "Epoch 00770: val_loss did not improve from 0.00328\n",
      "Epoch 771/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.4021e-05 - val_loss: 0.0044\n",
      "\n",
      "Epoch 00771: val_loss did not improve from 0.00328\n",
      "Epoch 772/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 87us/step - loss: 2.2954e-05 - val_loss: 0.0043\n",
      "\n",
      "Epoch 00772: val_loss did not improve from 0.00328\n",
      "Epoch 773/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 3.0502e-05 - val_loss: 0.0042\n",
      "\n",
      "Epoch 00773: val_loss did not improve from 0.00328\n",
      "Epoch 774/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.3204e-05 - val_loss: 0.0045\n",
      "\n",
      "Epoch 00774: val_loss did not improve from 0.00328\n",
      "Epoch 775/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.3699e-05 - val_loss: 0.0047\n",
      "\n",
      "Epoch 00775: val_loss did not improve from 0.00328\n",
      "Epoch 776/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.9040e-05 - val_loss: 0.0045\n",
      "\n",
      "Epoch 00776: val_loss did not improve from 0.00328\n",
      "Epoch 777/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 3.0198e-05 - val_loss: 0.0043\n",
      "\n",
      "Epoch 00777: val_loss did not improve from 0.00328\n",
      "Epoch 778/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.3682e-05 - val_loss: 0.0044\n",
      "\n",
      "Epoch 00778: val_loss did not improve from 0.00328\n",
      "Epoch 779/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.9990e-05 - val_loss: 0.0046\n",
      "\n",
      "Epoch 00779: val_loss did not improve from 0.00328\n",
      "Epoch 780/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.1233e-05 - val_loss: 0.0046\n",
      "\n",
      "Epoch 00780: val_loss did not improve from 0.00328\n",
      "Epoch 781/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.4986e-05 - val_loss: 0.0045\n",
      "\n",
      "Epoch 00781: val_loss did not improve from 0.00328\n",
      "Epoch 782/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.9872e-05 - val_loss: 0.0043\n",
      "\n",
      "Epoch 00782: val_loss did not improve from 0.00328\n",
      "Epoch 783/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.0553e-05 - val_loss: 0.0040\n",
      "\n",
      "Epoch 00783: val_loss did not improve from 0.00328\n",
      "Epoch 784/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.5540e-05 - val_loss: 0.0041\n",
      "\n",
      "Epoch 00784: val_loss did not improve from 0.00328\n",
      "Epoch 785/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.6321e-05 - val_loss: 0.0043\n",
      "\n",
      "Epoch 00785: val_loss did not improve from 0.00328\n",
      "Epoch 786/3000\n",
      "184/184 [==============================] - 0s 119us/step - loss: 2.4145e-05 - val_loss: 0.0044\n",
      "\n",
      "Epoch 00786: val_loss did not improve from 0.00328\n",
      "Epoch 787/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.1814e-05 - val_loss: 0.0042\n",
      "\n",
      "Epoch 00787: val_loss did not improve from 0.00328\n",
      "Epoch 788/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.3358e-05 - val_loss: 0.0040\n",
      "\n",
      "Epoch 00788: val_loss did not improve from 0.00328\n",
      "Epoch 789/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.4923e-05 - val_loss: 0.0041\n",
      "\n",
      "Epoch 00789: val_loss did not improve from 0.00328\n",
      "Epoch 790/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.3922e-05 - val_loss: 0.0043\n",
      "\n",
      "Epoch 00790: val_loss did not improve from 0.00328\n",
      "Epoch 791/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.2395e-05 - val_loss: 0.0046\n",
      "\n",
      "Epoch 00791: val_loss did not improve from 0.00328\n",
      "Epoch 792/3000\n",
      "184/184 [==============================] - 0s 152us/step - loss: 2.5847e-05 - val_loss: 0.0045\n",
      "\n",
      "Epoch 00792: val_loss did not improve from 0.00328\n",
      "Epoch 793/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.1536e-05 - val_loss: 0.0042\n",
      "\n",
      "Epoch 00793: val_loss did not improve from 0.00328\n",
      "Epoch 794/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.5999e-05 - val_loss: 0.0043\n",
      "\n",
      "Epoch 00794: val_loss did not improve from 0.00328\n",
      "Epoch 795/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.3175e-05 - val_loss: 0.0044\n",
      "\n",
      "Epoch 00795: val_loss did not improve from 0.00328\n",
      "Epoch 796/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.2446e-05 - val_loss: 0.0045\n",
      "\n",
      "Epoch 00796: val_loss did not improve from 0.00328\n",
      "Epoch 797/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.1812e-05 - val_loss: 0.0048\n",
      "\n",
      "Epoch 00797: val_loss did not improve from 0.00328\n",
      "Epoch 798/3000\n",
      "184/184 [==============================] - 0s 136us/step - loss: 3.1496e-05 - val_loss: 0.0046\n",
      "\n",
      "Epoch 00798: val_loss did not improve from 0.00328\n",
      "Epoch 799/3000\n",
      "184/184 [==============================] - 0s 147us/step - loss: 2.4583e-05 - val_loss: 0.0044\n",
      "\n",
      "Epoch 00799: val_loss did not improve from 0.00328\n",
      "Epoch 800/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.5846e-05 - val_loss: 0.0042\n",
      "\n",
      "Epoch 00800: val_loss did not improve from 0.00328\n",
      "Epoch 801/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 2.8004e-05 - val_loss: 0.0043\n",
      "\n",
      "Epoch 00801: val_loss did not improve from 0.00328\n",
      "Epoch 802/3000\n",
      "184/184 [==============================] - 0s 119us/step - loss: 1.9302e-05 - val_loss: 0.0045\n",
      "\n",
      "Epoch 00802: val_loss did not improve from 0.00328\n",
      "Epoch 803/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.7984e-05 - val_loss: 0.0046\n",
      "\n",
      "Epoch 00803: val_loss did not improve from 0.00328\n",
      "Epoch 804/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.6013e-05 - val_loss: 0.0045\n",
      "\n",
      "Epoch 00804: val_loss did not improve from 0.00328\n",
      "Epoch 805/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.1616e-05 - val_loss: 0.0043\n",
      "\n",
      "Epoch 00805: val_loss did not improve from 0.00328\n",
      "Epoch 806/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 1.9899e-05 - val_loss: 0.0043\n",
      "\n",
      "Epoch 00806: val_loss did not improve from 0.00328\n",
      "Epoch 807/3000\n",
      "184/184 [==============================] - 0s 120us/step - loss: 3.1470e-05 - val_loss: 0.0045\n",
      "\n",
      "Epoch 00807: val_loss did not improve from 0.00328\n",
      "Epoch 808/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.4038e-05 - val_loss: 0.0045\n",
      "\n",
      "Epoch 00808: val_loss did not improve from 0.00328\n",
      "Epoch 809/3000\n",
      "184/184 [==============================] - 0s 299us/step - loss: 2.6597e-05 - val_loss: 0.0045\n",
      "\n",
      "Epoch 00809: val_loss did not improve from 0.00328\n",
      "Epoch 810/3000\n",
      "184/184 [==============================] - 0s 163us/step - loss: 2.6257e-05 - val_loss: 0.0044\n",
      "\n",
      "Epoch 00810: val_loss did not improve from 0.00328\n",
      "Epoch 811/3000\n",
      "184/184 [==============================] - 0s 212us/step - loss: 2.5575e-05 - val_loss: 0.0043\n",
      "\n",
      "Epoch 00811: val_loss did not improve from 0.00328\n",
      "Epoch 812/3000\n",
      "184/184 [==============================] - 0s 196us/step - loss: 2.7534e-05 - val_loss: 0.0043\n",
      "\n",
      "Epoch 00812: val_loss did not improve from 0.00328\n",
      "Epoch 813/3000\n",
      "184/184 [==============================] - 0s 179us/step - loss: 2.3681e-05 - val_loss: 0.0043\n",
      "\n",
      "Epoch 00813: val_loss did not improve from 0.00328\n",
      "Epoch 814/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.6191e-05 - val_loss: 0.0043\n",
      "\n",
      "Epoch 00814: val_loss did not improve from 0.00328\n",
      "Epoch 815/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.3036e-05 - val_loss: 0.0045\n",
      "\n",
      "Epoch 00815: val_loss did not improve from 0.00328\n",
      "Epoch 816/3000\n",
      "184/184 [==============================] - 0s 126us/step - loss: 2.2681e-05 - val_loss: 0.0048\n",
      "\n",
      "Epoch 00816: val_loss did not improve from 0.00328\n",
      "Epoch 817/3000\n",
      "184/184 [==============================] - 0s 158us/step - loss: 2.2048e-05 - val_loss: 0.0047\n",
      "\n",
      "Epoch 00817: val_loss did not improve from 0.00328\n",
      "Epoch 818/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.0975e-05 - val_loss: 0.0044\n",
      "\n",
      "Epoch 00818: val_loss did not improve from 0.00328\n",
      "Epoch 819/3000\n",
      "184/184 [==============================] - 0s 190us/step - loss: 2.4975e-05 - val_loss: 0.0044\n",
      "\n",
      "Epoch 00819: val_loss did not improve from 0.00328\n",
      "Epoch 820/3000\n",
      "184/184 [==============================] - 0s 201us/step - loss: 2.7403e-05 - val_loss: 0.0044\n",
      "\n",
      "Epoch 00820: val_loss did not improve from 0.00328\n",
      "Epoch 821/3000\n",
      "184/184 [==============================] - 0s 190us/step - loss: 2.1029e-05 - val_loss: 0.0046\n",
      "\n",
      "Epoch 00821: val_loss did not improve from 0.00328\n",
      "Epoch 822/3000\n",
      "184/184 [==============================] - 0s 163us/step - loss: 2.9744e-05 - val_loss: 0.0048\n",
      "\n",
      "Epoch 00822: val_loss did not improve from 0.00328\n",
      "Epoch 823/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 141us/step - loss: 2.2309e-05 - val_loss: 0.0046\n",
      "\n",
      "Epoch 00823: val_loss did not improve from 0.00328\n",
      "Epoch 824/3000\n",
      "184/184 [==============================] - 0s 163us/step - loss: 2.3341e-05 - val_loss: 0.0044\n",
      "\n",
      "Epoch 00824: val_loss did not improve from 0.00328\n",
      "Epoch 825/3000\n",
      "184/184 [==============================] - 0s 130us/step - loss: 2.7026e-05 - val_loss: 0.0046\n",
      "\n",
      "Epoch 00825: val_loss did not improve from 0.00328\n",
      "Epoch 826/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.2026e-05 - val_loss: 0.0047\n",
      "\n",
      "Epoch 00826: val_loss did not improve from 0.00328\n",
      "Epoch 827/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.9568e-05 - val_loss: 0.0046\n",
      "\n",
      "Epoch 00827: val_loss did not improve from 0.00328\n",
      "Epoch 828/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.4357e-05 - val_loss: 0.0047\n",
      "\n",
      "Epoch 00828: val_loss did not improve from 0.00328\n",
      "Epoch 829/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.6746e-05 - val_loss: 0.0046\n",
      "\n",
      "Epoch 00829: val_loss did not improve from 0.00328\n",
      "Epoch 830/3000\n",
      "184/184 [==============================] - 0s 120us/step - loss: 2.1049e-05 - val_loss: 0.0045\n",
      "\n",
      "Epoch 00830: val_loss did not improve from 0.00328\n",
      "Epoch 831/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.5828e-05 - val_loss: 0.0043\n",
      "\n",
      "Epoch 00831: val_loss did not improve from 0.00328\n",
      "Epoch 832/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 2.8207e-05 - val_loss: 0.0043\n",
      "\n",
      "Epoch 00832: val_loss did not improve from 0.00328\n",
      "Epoch 833/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.5978e-05 - val_loss: 0.0047\n",
      "\n",
      "Epoch 00833: val_loss did not improve from 0.00328\n",
      "Epoch 834/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.9102e-05 - val_loss: 0.0049\n",
      "\n",
      "Epoch 00834: val_loss did not improve from 0.00328\n",
      "Epoch 835/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.6271e-05 - val_loss: 0.0046\n",
      "\n",
      "Epoch 00835: val_loss did not improve from 0.00328\n",
      "Epoch 836/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.2128e-05 - val_loss: 0.0043\n",
      "\n",
      "Epoch 00836: val_loss did not improve from 0.00328\n",
      "Epoch 837/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.4301e-05 - val_loss: 0.0044\n",
      "\n",
      "Epoch 00837: val_loss did not improve from 0.00328\n",
      "Epoch 838/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.6935e-05 - val_loss: 0.0045\n",
      "\n",
      "Epoch 00838: val_loss did not improve from 0.00328\n",
      "Epoch 839/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.6270e-05 - val_loss: 0.0046\n",
      "\n",
      "Epoch 00839: val_loss did not improve from 0.00328\n",
      "Epoch 840/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 3.0263e-05 - val_loss: 0.0047\n",
      "\n",
      "Epoch 00840: val_loss did not improve from 0.00328\n",
      "Epoch 841/3000\n",
      "184/184 [==============================] - 0s 152us/step - loss: 2.4947e-05 - val_loss: 0.0046\n",
      "\n",
      "Epoch 00841: val_loss did not improve from 0.00328\n",
      "Epoch 842/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.2988e-05 - val_loss: 0.0044\n",
      "\n",
      "Epoch 00842: val_loss did not improve from 0.00328\n",
      "Epoch 843/3000\n",
      "184/184 [==============================] - 0s 93us/step - loss: 2.5106e-05 - val_loss: 0.0045\n",
      "\n",
      "Epoch 00843: val_loss did not improve from 0.00328\n",
      "Epoch 844/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.0796e-05 - val_loss: 0.0046\n",
      "\n",
      "Epoch 00844: val_loss did not improve from 0.00328\n",
      "Epoch 845/3000\n",
      "184/184 [==============================] - ETA: 0s - loss: 1.2694e-0 - 0s 87us/step - loss: 2.1906e-05 - val_loss: 0.0045\n",
      "\n",
      "Epoch 00845: val_loss did not improve from 0.00328\n",
      "Epoch 846/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.4574e-05 - val_loss: 0.0044\n",
      "\n",
      "Epoch 00846: val_loss did not improve from 0.00328\n",
      "Epoch 847/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.1132e-05 - val_loss: 0.0043\n",
      "\n",
      "Epoch 00847: val_loss did not improve from 0.00328\n",
      "Epoch 848/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.5800e-05 - val_loss: 0.0045\n",
      "\n",
      "Epoch 00848: val_loss did not improve from 0.00328\n",
      "Epoch 849/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.0097e-05 - val_loss: 0.0047\n",
      "\n",
      "Epoch 00849: val_loss did not improve from 0.00328\n",
      "Epoch 850/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.7950e-05 - val_loss: 0.0046\n",
      "\n",
      "Epoch 00850: val_loss did not improve from 0.00328\n",
      "Epoch 851/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.5064e-05 - val_loss: 0.0044\n",
      "\n",
      "Epoch 00851: val_loss did not improve from 0.00328\n",
      "Epoch 852/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.2427e-05 - val_loss: 0.0045\n",
      "\n",
      "Epoch 00852: val_loss did not improve from 0.00328\n",
      "Epoch 853/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.1968e-05 - val_loss: 0.0047\n",
      "\n",
      "Epoch 00853: val_loss did not improve from 0.00328\n",
      "Epoch 854/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 1.9218e-05 - val_loss: 0.0046\n",
      "\n",
      "Epoch 00854: val_loss did not improve from 0.00328\n",
      "Epoch 855/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.1796e-05 - val_loss: 0.0046\n",
      "\n",
      "Epoch 00855: val_loss did not improve from 0.00328\n",
      "Epoch 856/3000\n",
      "184/184 [==============================] - 0s 104us/step - loss: 2.0919e-05 - val_loss: 0.0047\n",
      "\n",
      "Epoch 00856: val_loss did not improve from 0.00328\n",
      "Epoch 857/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.7988e-05 - val_loss: 0.0046\n",
      "\n",
      "Epoch 00857: val_loss did not improve from 0.00328\n",
      "Epoch 858/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.4950e-05 - val_loss: 0.0043\n",
      "\n",
      "Epoch 00858: val_loss did not improve from 0.00328\n",
      "Epoch 859/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.6176e-05 - val_loss: 0.0042\n",
      "\n",
      "Epoch 00859: val_loss did not improve from 0.00328\n",
      "Epoch 860/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.6259e-05 - val_loss: 0.0046\n",
      "\n",
      "Epoch 00860: val_loss did not improve from 0.00328\n",
      "Epoch 861/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.1563e-05 - val_loss: 0.0047\n",
      "\n",
      "Epoch 00861: val_loss did not improve from 0.00328\n",
      "Epoch 862/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.2179e-05 - val_loss: 0.0045\n",
      "\n",
      "Epoch 00862: val_loss did not improve from 0.00328\n",
      "Epoch 863/3000\n",
      "184/184 [==============================] - 0s 120us/step - loss: 2.3073e-05 - val_loss: 0.0043\n",
      "\n",
      "Epoch 00863: val_loss did not improve from 0.00328\n",
      "Epoch 864/3000\n",
      "184/184 [==============================] - ETA: 0s - loss: 1.4095e-0 - 0s 109us/step - loss: 2.9446e-05 - val_loss: 0.0043\n",
      "\n",
      "Epoch 00864: val_loss did not improve from 0.00328\n",
      "Epoch 865/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.0578e-05 - val_loss: 0.0046\n",
      "\n",
      "Epoch 00865: val_loss did not improve from 0.00328\n",
      "Epoch 866/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 1.9255e-05 - val_loss: 0.0046\n",
      "\n",
      "Epoch 00866: val_loss did not improve from 0.00328\n",
      "Epoch 867/3000\n",
      "184/184 [==============================] - ETA: 0s - loss: 1.1888e-0 - 0s 103us/step - loss: 2.3712e-05 - val_loss: 0.0045\n",
      "\n",
      "Epoch 00867: val_loss did not improve from 0.00328\n",
      "Epoch 868/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.8538e-05 - val_loss: 0.0044\n",
      "\n",
      "Epoch 00868: val_loss did not improve from 0.00328\n",
      "Epoch 869/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.1872e-05 - val_loss: 0.0045\n",
      "\n",
      "Epoch 00869: val_loss did not improve from 0.00328\n",
      "Epoch 870/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.4948e-05 - val_loss: 0.0046\n",
      "\n",
      "Epoch 00870: val_loss did not improve from 0.00328\n",
      "Epoch 871/3000\n",
      "184/184 [==============================] - 0s 81us/step - loss: 2.5955e-05 - val_loss: 0.0048\n",
      "\n",
      "Epoch 00871: val_loss did not improve from 0.00328\n",
      "Epoch 872/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.3498e-05 - val_loss: 0.0048\n",
      "\n",
      "Epoch 00872: val_loss did not improve from 0.00328\n",
      "Epoch 873/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 98us/step - loss: 2.4856e-05 - val_loss: 0.0047\n",
      "\n",
      "Epoch 00873: val_loss did not improve from 0.00328\n",
      "Epoch 874/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.7442e-05 - val_loss: 0.0046\n",
      "\n",
      "Epoch 00874: val_loss did not improve from 0.00328\n",
      "Epoch 875/3000\n",
      "184/184 [==============================] - 0s 93us/step - loss: 2.1903e-05 - val_loss: 0.0045\n",
      "\n",
      "Epoch 00875: val_loss did not improve from 0.00328\n",
      "Epoch 876/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.2319e-05 - val_loss: 0.0048\n",
      "\n",
      "Epoch 00876: val_loss did not improve from 0.00328\n",
      "Epoch 877/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.3780e-05 - val_loss: 0.0050\n",
      "\n",
      "Epoch 00877: val_loss did not improve from 0.00328\n",
      "Epoch 878/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.2638e-05 - val_loss: 0.0047\n",
      "\n",
      "Epoch 00878: val_loss did not improve from 0.00328\n",
      "Epoch 879/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.3667e-05 - val_loss: 0.0044\n",
      "\n",
      "Epoch 00879: val_loss did not improve from 0.00328\n",
      "Epoch 880/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.3877e-05 - val_loss: 0.0043\n",
      "\n",
      "Epoch 00880: val_loss did not improve from 0.00328\n",
      "Epoch 881/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 3.0143e-05 - val_loss: 0.0046\n",
      "\n",
      "Epoch 00881: val_loss did not improve from 0.00328\n",
      "Epoch 882/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 1.9714e-05 - val_loss: 0.0047\n",
      "\n",
      "Epoch 00882: val_loss did not improve from 0.00328\n",
      "Epoch 883/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.7343e-05 - val_loss: 0.0046\n",
      "\n",
      "Epoch 00883: val_loss did not improve from 0.00328\n",
      "Epoch 884/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.7002e-05 - val_loss: 0.0044\n",
      "\n",
      "Epoch 00884: val_loss did not improve from 0.00328\n",
      "Epoch 885/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.5471e-05 - val_loss: 0.0043\n",
      "\n",
      "Epoch 00885: val_loss did not improve from 0.00328\n",
      "Epoch 886/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.3543e-05 - val_loss: 0.0045\n",
      "\n",
      "Epoch 00886: val_loss did not improve from 0.00328\n",
      "Epoch 887/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.0499e-05 - val_loss: 0.0047\n",
      "\n",
      "Epoch 00887: val_loss did not improve from 0.00328\n",
      "Epoch 888/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.1425e-05 - val_loss: 0.0047\n",
      "\n",
      "Epoch 00888: val_loss did not improve from 0.00328\n",
      "Epoch 889/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 2.3523e-05 - val_loss: 0.0046\n",
      "\n",
      "Epoch 00889: val_loss did not improve from 0.00328\n",
      "Epoch 890/3000\n",
      "184/184 [==============================] - 0s 93us/step - loss: 2.1695e-05 - val_loss: 0.0046\n",
      "\n",
      "Epoch 00890: val_loss did not improve from 0.00328\n",
      "Epoch 891/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.0872e-05 - val_loss: 0.0048\n",
      "\n",
      "Epoch 00891: val_loss did not improve from 0.00328\n",
      "Epoch 892/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 3.0279e-05 - val_loss: 0.0049\n",
      "\n",
      "Epoch 00892: val_loss did not improve from 0.00328\n",
      "Epoch 893/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 1.7313e-05 - val_loss: 0.0047\n",
      "\n",
      "Epoch 00893: val_loss did not improve from 0.00328\n",
      "Epoch 894/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.6288e-05 - val_loss: 0.0047\n",
      "\n",
      "Epoch 00894: val_loss did not improve from 0.00328\n",
      "Epoch 895/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.5074e-05 - val_loss: 0.0048\n",
      "\n",
      "Epoch 00895: val_loss did not improve from 0.00328\n",
      "Epoch 896/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.5171e-05 - val_loss: 0.0048\n",
      "\n",
      "Epoch 00896: val_loss did not improve from 0.00328\n",
      "Epoch 897/3000\n",
      "184/184 [==============================] - 0s 120us/step - loss: 2.1707e-05 - val_loss: 0.0048\n",
      "\n",
      "Epoch 00897: val_loss did not improve from 0.00328\n",
      "Epoch 898/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.2702e-05 - val_loss: 0.0047\n",
      "\n",
      "Epoch 00898: val_loss did not improve from 0.00328\n",
      "Epoch 899/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 2.3370e-05 - val_loss: 0.0047\n",
      "\n",
      "Epoch 00899: val_loss did not improve from 0.00328\n",
      "Epoch 900/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.0729e-05 - val_loss: 0.0046\n",
      "\n",
      "Epoch 00900: val_loss did not improve from 0.00328\n",
      "Epoch 901/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.0999e-05 - val_loss: 0.0048\n",
      "\n",
      "Epoch 00901: val_loss did not improve from 0.00328\n",
      "Epoch 902/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.7332e-05 - val_loss: 0.0049\n",
      "\n",
      "Epoch 00902: val_loss did not improve from 0.00328\n",
      "Epoch 903/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.5760e-05 - val_loss: 0.0047\n",
      "\n",
      "Epoch 00903: val_loss did not improve from 0.00328\n",
      "Epoch 904/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.9160e-05 - val_loss: 0.0044\n",
      "\n",
      "Epoch 00904: val_loss did not improve from 0.00328\n",
      "Epoch 905/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.7217e-05 - val_loss: 0.0045\n",
      "\n",
      "Epoch 00905: val_loss did not improve from 0.00328\n",
      "Epoch 906/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.1703e-05 - val_loss: 0.0046\n",
      "\n",
      "Epoch 00906: val_loss did not improve from 0.00328\n",
      "Epoch 907/3000\n",
      "184/184 [==============================] - 0s 93us/step - loss: 2.2928e-05 - val_loss: 0.0045\n",
      "\n",
      "Epoch 00907: val_loss did not improve from 0.00328\n",
      "Epoch 908/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.6483e-05 - val_loss: 0.0045\n",
      "\n",
      "Epoch 00908: val_loss did not improve from 0.00328\n",
      "Epoch 909/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.5378e-05 - val_loss: 0.0045\n",
      "\n",
      "Epoch 00909: val_loss did not improve from 0.00328\n",
      "Epoch 910/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.0111e-05 - val_loss: 0.0044\n",
      "\n",
      "Epoch 00910: val_loss did not improve from 0.00328\n",
      "Epoch 911/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.7941e-05 - val_loss: 0.0044\n",
      "\n",
      "Epoch 00911: val_loss did not improve from 0.00328\n",
      "Epoch 912/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.3390e-05 - val_loss: 0.0045\n",
      "\n",
      "Epoch 00912: val_loss did not improve from 0.00328\n",
      "Epoch 913/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.8116e-05 - val_loss: 0.0046\n",
      "\n",
      "Epoch 00913: val_loss did not improve from 0.00328\n",
      "Epoch 914/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.4920e-05 - val_loss: 0.0047\n",
      "\n",
      "Epoch 00914: val_loss did not improve from 0.00328\n",
      "Epoch 915/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.4333e-05 - val_loss: 0.0048\n",
      "\n",
      "Epoch 00915: val_loss did not improve from 0.00328\n",
      "Epoch 916/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.0062e-05 - val_loss: 0.0048\n",
      "\n",
      "Epoch 00916: val_loss did not improve from 0.00328\n",
      "Epoch 917/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 1.8681e-05 - val_loss: 0.0047\n",
      "\n",
      "Epoch 00917: val_loss did not improve from 0.00328\n",
      "Epoch 918/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.1485e-05 - val_loss: 0.0049\n",
      "\n",
      "Epoch 00918: val_loss did not improve from 0.00328\n",
      "Epoch 919/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.4989e-05 - val_loss: 0.0050\n",
      "\n",
      "Epoch 00919: val_loss did not improve from 0.00328\n",
      "Epoch 920/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 1.8115e-05 - val_loss: 0.0050\n",
      "\n",
      "Epoch 00920: val_loss did not improve from 0.00328\n",
      "Epoch 921/3000\n",
      "184/184 [==============================] - 0s 93us/step - loss: 1.9848e-05 - val_loss: 0.0049\n",
      "\n",
      "Epoch 00921: val_loss did not improve from 0.00328\n",
      "Epoch 922/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.3312e-05 - val_loss: 0.0047\n",
      "\n",
      "Epoch 00922: val_loss did not improve from 0.00328\n",
      "Epoch 923/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.0056e-05 - val_loss: 0.0046\n",
      "\n",
      "Epoch 00923: val_loss did not improve from 0.00328\n",
      "Epoch 924/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 99us/step - loss: 2.0603e-05 - val_loss: 0.0048\n",
      "\n",
      "Epoch 00924: val_loss did not improve from 0.00328\n",
      "Epoch 925/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.5209e-05 - val_loss: 0.0050\n",
      "\n",
      "Epoch 00925: val_loss did not improve from 0.00328\n",
      "Epoch 926/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 3.3165e-05 - val_loss: 0.0051\n",
      "\n",
      "Epoch 00926: val_loss did not improve from 0.00328\n",
      "Epoch 927/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.4687e-05 - val_loss: 0.0048\n",
      "\n",
      "Epoch 00927: val_loss did not improve from 0.00328\n",
      "Epoch 928/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.4258e-05 - val_loss: 0.0046\n",
      "\n",
      "Epoch 00928: val_loss did not improve from 0.00328\n",
      "Epoch 929/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.2567e-05 - val_loss: 0.0048\n",
      "\n",
      "Epoch 00929: val_loss did not improve from 0.00328\n",
      "Epoch 930/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.5721e-05 - val_loss: 0.0048\n",
      "\n",
      "Epoch 00930: val_loss did not improve from 0.00328\n",
      "Epoch 931/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 1.8137e-05 - val_loss: 0.0048\n",
      "\n",
      "Epoch 00931: val_loss did not improve from 0.00328\n",
      "Epoch 932/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.1970e-05 - val_loss: 0.0049\n",
      "\n",
      "Epoch 00932: val_loss did not improve from 0.00328\n",
      "Epoch 933/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.6735e-05 - val_loss: 0.0050\n",
      "\n",
      "Epoch 00933: val_loss did not improve from 0.00328\n",
      "Epoch 934/3000\n",
      "184/184 [==============================] - 0s 130us/step - loss: 2.4647e-05 - val_loss: 0.0051\n",
      "\n",
      "Epoch 00934: val_loss did not improve from 0.00328\n",
      "Epoch 935/3000\n",
      "184/184 [==============================] - 0s 130us/step - loss: 2.6330e-05 - val_loss: 0.0052\n",
      "\n",
      "Epoch 00935: val_loss did not improve from 0.00328\n",
      "Epoch 936/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.3267e-05 - val_loss: 0.0051\n",
      "\n",
      "Epoch 00936: val_loss did not improve from 0.00328\n",
      "Epoch 937/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.0965e-05 - val_loss: 0.0051\n",
      "\n",
      "Epoch 00937: val_loss did not improve from 0.00328\n",
      "Epoch 938/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.1137e-05 - val_loss: 0.0051\n",
      "\n",
      "Epoch 00938: val_loss did not improve from 0.00328\n",
      "Epoch 939/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.2026e-05 - val_loss: 0.0051\n",
      "\n",
      "Epoch 00939: val_loss did not improve from 0.00328\n",
      "Epoch 940/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.6684e-05 - val_loss: 0.0050\n",
      "\n",
      "Epoch 00940: val_loss did not improve from 0.00328\n",
      "Epoch 941/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.1998e-05 - val_loss: 0.0047\n",
      "\n",
      "Epoch 00941: val_loss did not improve from 0.00328\n",
      "Epoch 942/3000\n",
      "184/184 [==============================] - ETA: 0s - loss: 1.2971e-0 - 0s 87us/step - loss: 2.3503e-05 - val_loss: 0.0046\n",
      "\n",
      "Epoch 00942: val_loss did not improve from 0.00328\n",
      "Epoch 943/3000\n",
      "184/184 [==============================] - 0s 93us/step - loss: 2.4618e-05 - val_loss: 0.0048\n",
      "\n",
      "Epoch 00943: val_loss did not improve from 0.00328\n",
      "Epoch 944/3000\n",
      "184/184 [==============================] - 0s 93us/step - loss: 2.6118e-05 - val_loss: 0.0048\n",
      "\n",
      "Epoch 00944: val_loss did not improve from 0.00328\n",
      "Epoch 945/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.3135e-05 - val_loss: 0.0047\n",
      "\n",
      "Epoch 00945: val_loss did not improve from 0.00328\n",
      "Epoch 946/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.1352e-05 - val_loss: 0.0048\n",
      "\n",
      "Epoch 00946: val_loss did not improve from 0.00328\n",
      "Epoch 947/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.0963e-05 - val_loss: 0.0048\n",
      "\n",
      "Epoch 00947: val_loss did not improve from 0.00328\n",
      "Epoch 948/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.1851e-05 - val_loss: 0.0047\n",
      "\n",
      "Epoch 00948: val_loss did not improve from 0.00328\n",
      "Epoch 949/3000\n",
      "184/184 [==============================] - 0s 93us/step - loss: 2.2050e-05 - val_loss: 0.0046\n",
      "\n",
      "Epoch 00949: val_loss did not improve from 0.00328\n",
      "Epoch 950/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 1.9479e-05 - val_loss: 0.0045\n",
      "\n",
      "Epoch 00950: val_loss did not improve from 0.00328\n",
      "Epoch 951/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.2473e-05 - val_loss: 0.0045\n",
      "\n",
      "Epoch 00951: val_loss did not improve from 0.00328\n",
      "Epoch 952/3000\n",
      "184/184 [==============================] - 0s 82us/step - loss: 2.2603e-05 - val_loss: 0.0047\n",
      "\n",
      "Epoch 00952: val_loss did not improve from 0.00328\n",
      "Epoch 953/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.1753e-05 - val_loss: 0.0045\n",
      "\n",
      "Epoch 00953: val_loss did not improve from 0.00328\n",
      "Epoch 954/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.2824e-05 - val_loss: 0.0045\n",
      "\n",
      "Epoch 00954: val_loss did not improve from 0.00328\n",
      "Epoch 955/3000\n",
      "184/184 [==============================] - 0s 93us/step - loss: 2.8600e-05 - val_loss: 0.0048\n",
      "\n",
      "Epoch 00955: val_loss did not improve from 0.00328\n",
      "Epoch 956/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.3934e-05 - val_loss: 0.0050\n",
      "\n",
      "Epoch 00956: val_loss did not improve from 0.00328\n",
      "Epoch 957/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.2712e-05 - val_loss: 0.0046\n",
      "\n",
      "Epoch 00957: val_loss did not improve from 0.00328\n",
      "Epoch 958/3000\n",
      "184/184 [==============================] - 0s 93us/step - loss: 2.6475e-05 - val_loss: 0.0044\n",
      "\n",
      "Epoch 00958: val_loss did not improve from 0.00328\n",
      "Epoch 959/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.1280e-05 - val_loss: 0.0048\n",
      "\n",
      "Epoch 00959: val_loss did not improve from 0.00328\n",
      "Epoch 960/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.1636e-05 - val_loss: 0.0051\n",
      "\n",
      "Epoch 00960: val_loss did not improve from 0.00328\n",
      "Epoch 961/3000\n",
      "184/184 [==============================] - 0s 81us/step - loss: 1.9513e-05 - val_loss: 0.0049\n",
      "\n",
      "Epoch 00961: val_loss did not improve from 0.00328\n",
      "Epoch 962/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 1.8342e-05 - val_loss: 0.0046\n",
      "\n",
      "Epoch 00962: val_loss did not improve from 0.00328\n",
      "Epoch 963/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 3.0312e-05 - val_loss: 0.0047\n",
      "\n",
      "Epoch 00963: val_loss did not improve from 0.00328\n",
      "Epoch 964/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.1924e-05 - val_loss: 0.0050\n",
      "\n",
      "Epoch 00964: val_loss did not improve from 0.00328\n",
      "Epoch 965/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 1.9863e-05 - val_loss: 0.0052\n",
      "\n",
      "Epoch 00965: val_loss did not improve from 0.00328\n",
      "Epoch 966/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.5214e-05 - val_loss: 0.0049\n",
      "\n",
      "Epoch 00966: val_loss did not improve from 0.00328\n",
      "Epoch 967/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.1494e-05 - val_loss: 0.0048\n",
      "\n",
      "Epoch 00967: val_loss did not improve from 0.00328\n",
      "Epoch 968/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.4096e-05 - val_loss: 0.0048\n",
      "\n",
      "Epoch 00968: val_loss did not improve from 0.00328\n",
      "Epoch 969/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.2587e-05 - val_loss: 0.0049\n",
      "\n",
      "Epoch 00969: val_loss did not improve from 0.00328\n",
      "Epoch 970/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.1916e-05 - val_loss: 0.0047\n",
      "\n",
      "Epoch 00970: val_loss did not improve from 0.00328\n",
      "Epoch 971/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.2080e-05 - val_loss: 0.0048\n",
      "\n",
      "Epoch 00971: val_loss did not improve from 0.00328\n",
      "Epoch 972/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.7655e-05 - val_loss: 0.0050\n",
      "\n",
      "Epoch 00972: val_loss did not improve from 0.00328\n",
      "Epoch 973/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.7600e-05 - val_loss: 0.0050\n",
      "\n",
      "Epoch 00973: val_loss did not improve from 0.00328\n",
      "Epoch 974/3000\n",
      "184/184 [==============================] - 0s 95us/step - loss: 2.1298e-05 - val_loss: 0.0049\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00974: val_loss did not improve from 0.00328\n",
      "Epoch 975/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.2336e-05 - val_loss: 0.0050\n",
      "\n",
      "Epoch 00975: val_loss did not improve from 0.00328\n",
      "Epoch 976/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.4019e-05 - val_loss: 0.0052\n",
      "\n",
      "Epoch 00976: val_loss did not improve from 0.00328\n",
      "Epoch 977/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.3312e-05 - val_loss: 0.0052\n",
      "\n",
      "Epoch 00977: val_loss did not improve from 0.00328\n",
      "Epoch 978/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.9437e-05 - val_loss: 0.0051\n",
      "\n",
      "Epoch 00978: val_loss did not improve from 0.00328\n",
      "Epoch 979/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.2406e-05 - val_loss: 0.0051\n",
      "\n",
      "Epoch 00979: val_loss did not improve from 0.00328\n",
      "Epoch 980/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.5634e-05 - val_loss: 0.0051\n",
      "\n",
      "Epoch 00980: val_loss did not improve from 0.00328\n",
      "Epoch 981/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 1.8237e-05 - val_loss: 0.0049\n",
      "\n",
      "Epoch 00981: val_loss did not improve from 0.00328\n",
      "Epoch 982/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.1705e-05 - val_loss: 0.0049\n",
      "\n",
      "Epoch 00982: val_loss did not improve from 0.00328\n",
      "Epoch 983/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.3290e-05 - val_loss: 0.0052\n",
      "\n",
      "Epoch 00983: val_loss did not improve from 0.00328\n",
      "Epoch 984/3000\n",
      "184/184 [==============================] - 0s 119us/step - loss: 2.1091e-05 - val_loss: 0.0052\n",
      "\n",
      "Epoch 00984: val_loss did not improve from 0.00328\n",
      "Epoch 985/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 1.8832e-05 - val_loss: 0.0050\n",
      "\n",
      "Epoch 00985: val_loss did not improve from 0.00328\n",
      "Epoch 986/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.4912e-05 - val_loss: 0.0048\n",
      "\n",
      "Epoch 00986: val_loss did not improve from 0.00328\n",
      "Epoch 987/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.3991e-05 - val_loss: 0.0049\n",
      "\n",
      "Epoch 00987: val_loss did not improve from 0.00328\n",
      "Epoch 988/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.4464e-05 - val_loss: 0.0051\n",
      "\n",
      "Epoch 00988: val_loss did not improve from 0.00328\n",
      "Epoch 989/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.3264e-05 - val_loss: 0.0052\n",
      "\n",
      "Epoch 00989: val_loss did not improve from 0.00328\n",
      "Epoch 990/3000\n",
      "184/184 [==============================] - 0s 93us/step - loss: 2.3293e-05 - val_loss: 0.0049\n",
      "\n",
      "Epoch 00990: val_loss did not improve from 0.00328\n",
      "Epoch 991/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.4725e-05 - val_loss: 0.0047\n",
      "\n",
      "Epoch 00991: val_loss did not improve from 0.00328\n",
      "Epoch 992/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.3860e-05 - val_loss: 0.0050\n",
      "\n",
      "Epoch 00992: val_loss did not improve from 0.00328\n",
      "Epoch 993/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.1440e-05 - val_loss: 0.0052\n",
      "\n",
      "Epoch 00993: val_loss did not improve from 0.00328\n",
      "Epoch 994/3000\n",
      "184/184 [==============================] - 0s 93us/step - loss: 2.7451e-05 - val_loss: 0.0049\n",
      "\n",
      "Epoch 00994: val_loss did not improve from 0.00328\n",
      "Epoch 995/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.1024e-05 - val_loss: 0.0047\n",
      "\n",
      "Epoch 00995: val_loss did not improve from 0.00328\n",
      "Epoch 996/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.2979e-05 - val_loss: 0.0049\n",
      "\n",
      "Epoch 00996: val_loss did not improve from 0.00328\n",
      "Epoch 997/3000\n",
      "184/184 [==============================] - 0s 104us/step - loss: 2.2708e-05 - val_loss: 0.0052\n",
      "\n",
      "Epoch 00997: val_loss did not improve from 0.00328\n",
      "Epoch 998/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 1.8249e-05 - val_loss: 0.0053\n",
      "\n",
      "Epoch 00998: val_loss did not improve from 0.00328\n",
      "Epoch 999/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.7745e-05 - val_loss: 0.0052\n",
      "\n",
      "Epoch 00999: val_loss did not improve from 0.00328\n",
      "Epoch 1000/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.4451e-05 - val_loss: 0.0050\n",
      "\n",
      "Epoch 01000: val_loss did not improve from 0.00328\n",
      "Epoch 1001/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.6764e-05 - val_loss: 0.0052\n",
      "\n",
      "Epoch 01001: val_loss did not improve from 0.00328\n",
      "Epoch 1002/3000\n",
      "184/184 [==============================] - 0s 168us/step - loss: 2.6578e-05 - val_loss: 0.0056\n",
      "\n",
      "Epoch 01002: val_loss did not improve from 0.00328\n",
      "Epoch 1003/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 3.1339e-05 - val_loss: 0.0054\n",
      "\n",
      "Epoch 01003: val_loss did not improve from 0.00328\n",
      "Epoch 1004/3000\n",
      "184/184 [==============================] - 0s 93us/step - loss: 2.2420e-05 - val_loss: 0.0049\n",
      "\n",
      "Epoch 01004: val_loss did not improve from 0.00328\n",
      "Epoch 1005/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.9594e-05 - val_loss: 0.0049\n",
      "\n",
      "Epoch 01005: val_loss did not improve from 0.00328\n",
      "Epoch 1006/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.7041e-05 - val_loss: 0.0051\n",
      "\n",
      "Epoch 01006: val_loss did not improve from 0.00328\n",
      "Epoch 1007/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 1.9503e-05 - val_loss: 0.0050\n",
      "\n",
      "Epoch 01007: val_loss did not improve from 0.00328\n",
      "Epoch 1008/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.1404e-05 - val_loss: 0.0049\n",
      "\n",
      "Epoch 01008: val_loss did not improve from 0.00328\n",
      "Epoch 1009/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.0958e-05 - val_loss: 0.0049\n",
      "\n",
      "Epoch 01009: val_loss did not improve from 0.00328\n",
      "Epoch 1010/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.2995e-05 - val_loss: 0.0048\n",
      "\n",
      "Epoch 01010: val_loss did not improve from 0.00328\n",
      "Epoch 1011/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.9534e-05 - val_loss: 0.0048\n",
      "\n",
      "Epoch 01011: val_loss did not improve from 0.00328\n",
      "Epoch 1012/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.1310e-05 - val_loss: 0.0051\n",
      "\n",
      "Epoch 01012: val_loss did not improve from 0.00328\n",
      "Epoch 1013/3000\n",
      "184/184 [==============================] - 0s 119us/step - loss: 2.3169e-05 - val_loss: 0.0053\n",
      "\n",
      "Epoch 01013: val_loss did not improve from 0.00328\n",
      "Epoch 1014/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 2.6901e-05 - val_loss: 0.0052\n",
      "\n",
      "Epoch 01014: val_loss did not improve from 0.00328\n",
      "Epoch 1015/3000\n",
      "184/184 [==============================] - 0s 174us/step - loss: 2.5208e-05 - val_loss: 0.0049\n",
      "\n",
      "Epoch 01015: val_loss did not improve from 0.00328\n",
      "Epoch 1016/3000\n",
      "184/184 [==============================] - 0s 158us/step - loss: 2.3953e-05 - val_loss: 0.0050\n",
      "\n",
      "Epoch 01016: val_loss did not improve from 0.00328\n",
      "Epoch 1017/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 2.8521e-05 - val_loss: 0.0053\n",
      "\n",
      "Epoch 01017: val_loss did not improve from 0.00328\n",
      "Epoch 1018/3000\n",
      "184/184 [==============================] - 0s 169us/step - loss: 2.5566e-05 - val_loss: 0.0053\n",
      "\n",
      "Epoch 01018: val_loss did not improve from 0.00328\n",
      "Epoch 1019/3000\n",
      "184/184 [==============================] - 0s 179us/step - loss: 2.1548e-05 - val_loss: 0.0051\n",
      "\n",
      "Epoch 01019: val_loss did not improve from 0.00328\n",
      "Epoch 1020/3000\n",
      "184/184 [==============================] - 0s 130us/step - loss: 2.1189e-05 - val_loss: 0.0049\n",
      "\n",
      "Epoch 01020: val_loss did not improve from 0.00328\n",
      "Epoch 1021/3000\n",
      "184/184 [==============================] - 0s 190us/step - loss: 1.8757e-05 - val_loss: 0.0049\n",
      "\n",
      "Epoch 01021: val_loss did not improve from 0.00328\n",
      "Epoch 1022/3000\n",
      "184/184 [==============================] - 0s 120us/step - loss: 2.0772e-05 - val_loss: 0.0049\n",
      "\n",
      "Epoch 01022: val_loss did not improve from 0.00328\n",
      "Epoch 1023/3000\n",
      "184/184 [==============================] - 0s 196us/step - loss: 2.1930e-05 - val_loss: 0.0051\n",
      "\n",
      "Epoch 01023: val_loss did not improve from 0.00328\n",
      "Epoch 1024/3000\n",
      "184/184 [==============================] - 0s 217us/step - loss: 2.4898e-05 - val_loss: 0.0053\n",
      "\n",
      "Epoch 01024: val_loss did not improve from 0.00328\n",
      "Epoch 1025/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 103us/step - loss: 2.1298e-05 - val_loss: 0.0051\n",
      "\n",
      "Epoch 01025: val_loss did not improve from 0.00328\n",
      "Epoch 1026/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.2696e-05 - val_loss: 0.0051\n",
      "\n",
      "Epoch 01026: val_loss did not improve from 0.00328\n",
      "Epoch 1027/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 2.2535e-05 - val_loss: 0.0052\n",
      "\n",
      "Epoch 01027: val_loss did not improve from 0.00328\n",
      "Epoch 1028/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.9409e-05 - val_loss: 0.0053\n",
      "\n",
      "Epoch 01028: val_loss did not improve from 0.00328\n",
      "Epoch 1029/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.5876e-05 - val_loss: 0.0053\n",
      "\n",
      "Epoch 01029: val_loss did not improve from 0.00328\n",
      "Epoch 1030/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 1.9788e-05 - val_loss: 0.0051\n",
      "\n",
      "Epoch 01030: val_loss did not improve from 0.00328\n",
      "Epoch 1031/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.1633e-05 - val_loss: 0.0050\n",
      "\n",
      "Epoch 01031: val_loss did not improve from 0.00328\n",
      "Epoch 1032/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 1.8907e-05 - val_loss: 0.0052\n",
      "\n",
      "Epoch 01032: val_loss did not improve from 0.00328\n",
      "Epoch 1033/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.1980e-05 - val_loss: 0.0052\n",
      "\n",
      "Epoch 01033: val_loss did not improve from 0.00328\n",
      "Epoch 1034/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 1.8373e-05 - val_loss: 0.0050\n",
      "\n",
      "Epoch 01034: val_loss did not improve from 0.00328\n",
      "Epoch 1035/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.6302e-05 - val_loss: 0.0051\n",
      "\n",
      "Epoch 01035: val_loss did not improve from 0.00328\n",
      "Epoch 1036/3000\n",
      "184/184 [==============================] - 0s 95us/step - loss: 2.1499e-05 - val_loss: 0.0054\n",
      "\n",
      "Epoch 01036: val_loss did not improve from 0.00328\n",
      "Epoch 1037/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.3917e-05 - val_loss: 0.0052\n",
      "\n",
      "Epoch 01037: val_loss did not improve from 0.00328\n",
      "Epoch 1038/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 1.9928e-05 - val_loss: 0.0050\n",
      "\n",
      "Epoch 01038: val_loss did not improve from 0.00328\n",
      "Epoch 1039/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.4236e-05 - val_loss: 0.0050\n",
      "\n",
      "Epoch 01039: val_loss did not improve from 0.00328\n",
      "Epoch 1040/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.5422e-05 - val_loss: 0.0053\n",
      "\n",
      "Epoch 01040: val_loss did not improve from 0.00328\n",
      "Epoch 1041/3000\n",
      "184/184 [==============================] - 0s 158us/step - loss: 1.9197e-05 - val_loss: 0.0053\n",
      "\n",
      "Epoch 01041: val_loss did not improve from 0.00328\n",
      "Epoch 1042/3000\n",
      "184/184 [==============================] - 0s 196us/step - loss: 1.8432e-05 - val_loss: 0.0052\n",
      "\n",
      "Epoch 01042: val_loss did not improve from 0.00328\n",
      "Epoch 1043/3000\n",
      "184/184 [==============================] - 0s 245us/step - loss: 2.1952e-05 - val_loss: 0.0050\n",
      "\n",
      "Epoch 01043: val_loss did not improve from 0.00328\n",
      "Epoch 1044/3000\n",
      "184/184 [==============================] - 0s 190us/step - loss: 2.1577e-05 - val_loss: 0.0048\n",
      "\n",
      "Epoch 01044: val_loss did not improve from 0.00328\n",
      "Epoch 1045/3000\n",
      "184/184 [==============================] - 0s 163us/step - loss: 2.1690e-05 - val_loss: 0.0050\n",
      "\n",
      "Epoch 01045: val_loss did not improve from 0.00328\n",
      "Epoch 1046/3000\n",
      "184/184 [==============================] - 0s 185us/step - loss: 3.0442e-05 - val_loss: 0.0053\n",
      "\n",
      "Epoch 01046: val_loss did not improve from 0.00328\n",
      "Epoch 1047/3000\n",
      "184/184 [==============================] - 0s 174us/step - loss: 2.4405e-05 - val_loss: 0.0052\n",
      "\n",
      "Epoch 01047: val_loss did not improve from 0.00328\n",
      "Epoch 1048/3000\n",
      "184/184 [==============================] - 0s 158us/step - loss: 2.6606e-05 - val_loss: 0.0051\n",
      "\n",
      "Epoch 01048: val_loss did not improve from 0.00328\n",
      "Epoch 1049/3000\n",
      "184/184 [==============================] - 0s 158us/step - loss: 2.1427e-05 - val_loss: 0.0053\n",
      "\n",
      "Epoch 01049: val_loss did not improve from 0.00328\n",
      "Epoch 1050/3000\n",
      "184/184 [==============================] - 0s 163us/step - loss: 2.5496e-05 - val_loss: 0.0052\n",
      "\n",
      "Epoch 01050: val_loss did not improve from 0.00328\n",
      "Epoch 1051/3000\n",
      "184/184 [==============================] - 0s 206us/step - loss: 1.9162e-05 - val_loss: 0.0052\n",
      "\n",
      "Epoch 01051: val_loss did not improve from 0.00328\n",
      "Epoch 1052/3000\n",
      "184/184 [==============================] - 0s 141us/step - loss: 2.4138e-05 - val_loss: 0.0052\n",
      "\n",
      "Epoch 01052: val_loss did not improve from 0.00328\n",
      "Epoch 1053/3000\n",
      "184/184 [==============================] - 0s 174us/step - loss: 2.6918e-05 - val_loss: 0.0052\n",
      "\n",
      "Epoch 01053: val_loss did not improve from 0.00328\n",
      "Epoch 1054/3000\n",
      "184/184 [==============================] - 0s 141us/step - loss: 2.6346e-05 - val_loss: 0.0051\n",
      "\n",
      "Epoch 01054: val_loss did not improve from 0.00328\n",
      "Epoch 1055/3000\n",
      "184/184 [==============================] - 0s 250us/step - loss: 2.2856e-05 - val_loss: 0.0051\n",
      "\n",
      "Epoch 01055: val_loss did not improve from 0.00328\n",
      "Epoch 1056/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 2.4983e-05 - val_loss: 0.0053\n",
      "\n",
      "Epoch 01056: val_loss did not improve from 0.00328\n",
      "Epoch 1057/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.4279e-05 - val_loss: 0.0056\n",
      "\n",
      "Epoch 01057: val_loss did not improve from 0.00328\n",
      "Epoch 1058/3000\n",
      "184/184 [==============================] - 0s 136us/step - loss: 2.4898e-05 - val_loss: 0.0055\n",
      "\n",
      "Epoch 01058: val_loss did not improve from 0.00328\n",
      "Epoch 1059/3000\n",
      "184/184 [==============================] - 0s 141us/step - loss: 2.2182e-05 - val_loss: 0.0052\n",
      "\n",
      "Epoch 01059: val_loss did not improve from 0.00328\n",
      "Epoch 1060/3000\n",
      "184/184 [==============================] - ETA: 0s - loss: 1.5861e-0 - 0s 114us/step - loss: 2.6952e-05 - val_loss: 0.0052\n",
      "\n",
      "Epoch 01060: val_loss did not improve from 0.00328\n",
      "Epoch 1061/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.2326e-05 - val_loss: 0.0054\n",
      "\n",
      "Epoch 01061: val_loss did not improve from 0.00328\n",
      "Epoch 1062/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.8578e-05 - val_loss: 0.0055\n",
      "\n",
      "Epoch 01062: val_loss did not improve from 0.00328\n",
      "Epoch 1063/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.1543e-05 - val_loss: 0.0052\n",
      "\n",
      "Epoch 01063: val_loss did not improve from 0.00328\n",
      "Epoch 1064/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.0252e-05 - val_loss: 0.0048\n",
      "\n",
      "Epoch 01064: val_loss did not improve from 0.00328\n",
      "Epoch 1065/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 3.2884e-05 - val_loss: 0.0050\n",
      "\n",
      "Epoch 01065: val_loss did not improve from 0.00328\n",
      "Epoch 1066/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.2581e-05 - val_loss: 0.0056\n",
      "\n",
      "Epoch 01066: val_loss did not improve from 0.00328\n",
      "Epoch 1067/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.6045e-05 - val_loss: 0.0054\n",
      "\n",
      "Epoch 01067: val_loss did not improve from 0.00328\n",
      "Epoch 1068/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.2107e-05 - val_loss: 0.0050\n",
      "\n",
      "Epoch 01068: val_loss did not improve from 0.00328\n",
      "Epoch 1069/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.8887e-05 - val_loss: 0.0050\n",
      "\n",
      "Epoch 01069: val_loss did not improve from 0.00328\n",
      "Epoch 1070/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.0385e-05 - val_loss: 0.0053\n",
      "\n",
      "Epoch 01070: val_loss did not improve from 0.00328\n",
      "Epoch 1071/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.2982e-05 - val_loss: 0.0053\n",
      "\n",
      "Epoch 01071: val_loss did not improve from 0.00328\n",
      "Epoch 1072/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.3667e-05 - val_loss: 0.0051\n",
      "\n",
      "Epoch 01072: val_loss did not improve from 0.00328\n",
      "Epoch 1073/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.0000e-05 - val_loss: 0.0052\n",
      "\n",
      "Epoch 01073: val_loss did not improve from 0.00328\n",
      "Epoch 1074/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.2341e-05 - val_loss: 0.0052\n",
      "\n",
      "Epoch 01074: val_loss did not improve from 0.00328\n",
      "Epoch 1075/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 114us/step - loss: 2.2234e-05 - val_loss: 0.0051\n",
      "\n",
      "Epoch 01075: val_loss did not improve from 0.00328\n",
      "Epoch 1076/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.9017e-05 - val_loss: 0.0053\n",
      "\n",
      "Epoch 01076: val_loss did not improve from 0.00328\n",
      "Epoch 1077/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 1.8294e-05 - val_loss: 0.0053\n",
      "\n",
      "Epoch 01077: val_loss did not improve from 0.00328\n",
      "Epoch 1078/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.4018e-05 - val_loss: 0.0053\n",
      "\n",
      "Epoch 01078: val_loss did not improve from 0.00328\n",
      "Epoch 1079/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.1834e-05 - val_loss: 0.0055\n",
      "\n",
      "Epoch 01079: val_loss did not improve from 0.00328\n",
      "Epoch 1080/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.5578e-05 - val_loss: 0.0056\n",
      "\n",
      "Epoch 01080: val_loss did not improve from 0.00328\n",
      "Epoch 1081/3000\n",
      "184/184 [==============================] - 0s 120us/step - loss: 2.3928e-05 - val_loss: 0.0055\n",
      "\n",
      "Epoch 01081: val_loss did not improve from 0.00328\n",
      "Epoch 1082/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 1.9053e-05 - val_loss: 0.0054\n",
      "\n",
      "Epoch 01082: val_loss did not improve from 0.00328\n",
      "Epoch 1083/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.7120e-05 - val_loss: 0.0054\n",
      "\n",
      "Epoch 01083: val_loss did not improve from 0.00328\n",
      "Epoch 1084/3000\n",
      "184/184 [==============================] - 0s 94us/step - loss: 2.2054e-05 - val_loss: 0.0054\n",
      "\n",
      "Epoch 01084: val_loss did not improve from 0.00328\n",
      "Epoch 1085/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.3709e-05 - val_loss: 0.0055\n",
      "\n",
      "Epoch 01085: val_loss did not improve from 0.00328\n",
      "Epoch 1086/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.2125e-05 - val_loss: 0.0054\n",
      "\n",
      "Epoch 01086: val_loss did not improve from 0.00328\n",
      "Epoch 1087/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.2788e-05 - val_loss: 0.0051\n",
      "\n",
      "Epoch 01087: val_loss did not improve from 0.00328\n",
      "Epoch 1088/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.2216e-05 - val_loss: 0.0050\n",
      "\n",
      "Epoch 01088: val_loss did not improve from 0.00328\n",
      "Epoch 1089/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.8769e-05 - val_loss: 0.0050\n",
      "\n",
      "Epoch 01089: val_loss did not improve from 0.00328\n",
      "Epoch 1090/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.2114e-05 - val_loss: 0.0054\n",
      "\n",
      "Epoch 01090: val_loss did not improve from 0.00328\n",
      "Epoch 1091/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.4265e-05 - val_loss: 0.0057\n",
      "\n",
      "Epoch 01091: val_loss did not improve from 0.00328\n",
      "Epoch 1092/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.2601e-05 - val_loss: 0.0056\n",
      "\n",
      "Epoch 01092: val_loss did not improve from 0.00328\n",
      "Epoch 1093/3000\n",
      "184/184 [==============================] - 0s 97us/step - loss: 2.5709e-05 - val_loss: 0.0052\n",
      "\n",
      "Epoch 01093: val_loss did not improve from 0.00328\n",
      "Epoch 1094/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.7024e-05 - val_loss: 0.0049\n",
      "\n",
      "Epoch 01094: val_loss did not improve from 0.00328\n",
      "Epoch 1095/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.3785e-05 - val_loss: 0.0051\n",
      "\n",
      "Epoch 01095: val_loss did not improve from 0.00328\n",
      "Epoch 1096/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.5178e-05 - val_loss: 0.0053\n",
      "\n",
      "Epoch 01096: val_loss did not improve from 0.00328\n",
      "Epoch 1097/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.7783e-05 - val_loss: 0.0052\n",
      "\n",
      "Epoch 01097: val_loss did not improve from 0.00328\n",
      "Epoch 1098/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.1560e-05 - val_loss: 0.0049\n",
      "\n",
      "Epoch 01098: val_loss did not improve from 0.00328\n",
      "Epoch 1099/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.0799e-05 - val_loss: 0.0049\n",
      "\n",
      "Epoch 01099: val_loss did not improve from 0.00328\n",
      "Epoch 1100/3000\n",
      "184/184 [==============================] - 0s 152us/step - loss: 2.4805e-05 - val_loss: 0.0052\n",
      "\n",
      "Epoch 01100: val_loss did not improve from 0.00328\n",
      "Epoch 1101/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.4604e-05 - val_loss: 0.0055\n",
      "\n",
      "Epoch 01101: val_loss did not improve from 0.00328\n",
      "Epoch 1102/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 1.9837e-05 - val_loss: 0.0052\n",
      "\n",
      "Epoch 01102: val_loss did not improve from 0.00328\n",
      "Epoch 1103/3000\n",
      "184/184 [==============================] - ETA: 0s - loss: 1.2196e-0 - 0s 92us/step - loss: 2.1414e-05 - val_loss: 0.0051\n",
      "\n",
      "Epoch 01103: val_loss did not improve from 0.00328\n",
      "Epoch 1104/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.3435e-05 - val_loss: 0.0055\n",
      "\n",
      "Epoch 01104: val_loss did not improve from 0.00328\n",
      "Epoch 1105/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.5232e-05 - val_loss: 0.0058\n",
      "\n",
      "Epoch 01105: val_loss did not improve from 0.00328\n",
      "Epoch 1106/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.3476e-05 - val_loss: 0.0054\n",
      "\n",
      "Epoch 01106: val_loss did not improve from 0.00328\n",
      "Epoch 1107/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.3115e-05 - val_loss: 0.0051\n",
      "\n",
      "Epoch 01107: val_loss did not improve from 0.00328\n",
      "Epoch 1108/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 3.1444e-05 - val_loss: 0.0050\n",
      "\n",
      "Epoch 01108: val_loss did not improve from 0.00328\n",
      "Epoch 1109/3000\n",
      "184/184 [==============================] - 0s 81us/step - loss: 2.6675e-05 - val_loss: 0.0051\n",
      "\n",
      "Epoch 01109: val_loss did not improve from 0.00328\n",
      "Epoch 1110/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.0474e-05 - val_loss: 0.0056\n",
      "\n",
      "Epoch 01110: val_loss did not improve from 0.00328\n",
      "Epoch 1111/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 3.1931e-05 - val_loss: 0.0057\n",
      "\n",
      "Epoch 01111: val_loss did not improve from 0.00328\n",
      "Epoch 1112/3000\n",
      "184/184 [==============================] - ETA: 0s - loss: 1.2212e-0 - 0s 92us/step - loss: 2.7236e-05 - val_loss: 0.0052\n",
      "\n",
      "Epoch 01112: val_loss did not improve from 0.00328\n",
      "Epoch 1113/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.2040e-05 - val_loss: 0.0048\n",
      "\n",
      "Epoch 01113: val_loss did not improve from 0.00328\n",
      "Epoch 1114/3000\n",
      "184/184 [==============================] - 0s 81us/step - loss: 3.1557e-05 - val_loss: 0.0051\n",
      "\n",
      "Epoch 01114: val_loss did not improve from 0.00328\n",
      "Epoch 1115/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.8418e-05 - val_loss: 0.0055\n",
      "\n",
      "Epoch 01115: val_loss did not improve from 0.00328\n",
      "Epoch 1116/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.3442e-05 - val_loss: 0.0053\n",
      "\n",
      "Epoch 01116: val_loss did not improve from 0.00328\n",
      "Epoch 1117/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.0792e-05 - val_loss: 0.0050\n",
      "\n",
      "Epoch 01117: val_loss did not improve from 0.00328\n",
      "Epoch 1118/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.7415e-05 - val_loss: 0.0050\n",
      "\n",
      "Epoch 01118: val_loss did not improve from 0.00328\n",
      "Epoch 1119/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 3.1382e-05 - val_loss: 0.0053\n",
      "\n",
      "Epoch 01119: val_loss did not improve from 0.00328\n",
      "Epoch 1120/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.5168e-05 - val_loss: 0.0057\n",
      "\n",
      "Epoch 01120: val_loss did not improve from 0.00328\n",
      "Epoch 1121/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.3828e-05 - val_loss: 0.0055\n",
      "\n",
      "Epoch 01121: val_loss did not improve from 0.00328\n",
      "Epoch 1122/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.1714e-05 - val_loss: 0.0051\n",
      "\n",
      "Epoch 01122: val_loss did not improve from 0.00328\n",
      "Epoch 1123/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 3.2816e-05 - val_loss: 0.0050\n",
      "\n",
      "Epoch 01123: val_loss did not improve from 0.00328\n",
      "Epoch 1124/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.1777e-05 - val_loss: 0.0053\n",
      "\n",
      "Epoch 01124: val_loss did not improve from 0.00328\n",
      "Epoch 1125/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 82us/step - loss: 2.3146e-05 - val_loss: 0.0053\n",
      "\n",
      "Epoch 01125: val_loss did not improve from 0.00328\n",
      "Epoch 1126/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.4211e-05 - val_loss: 0.0050\n",
      "\n",
      "Epoch 01126: val_loss did not improve from 0.00328\n",
      "Epoch 1127/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.5063e-05 - val_loss: 0.0050\n",
      "\n",
      "Epoch 01127: val_loss did not improve from 0.00328\n",
      "Epoch 1128/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.4747e-05 - val_loss: 0.0052\n",
      "\n",
      "Epoch 01128: val_loss did not improve from 0.00328\n",
      "Epoch 1129/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.4402e-05 - val_loss: 0.0053\n",
      "\n",
      "Epoch 01129: val_loss did not improve from 0.00328\n",
      "Epoch 1130/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.3839e-05 - val_loss: 0.0053\n",
      "\n",
      "Epoch 01130: val_loss did not improve from 0.00328\n",
      "Epoch 1131/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.3321e-05 - val_loss: 0.0051\n",
      "\n",
      "Epoch 01131: val_loss did not improve from 0.00328\n",
      "Epoch 1132/3000\n",
      "184/184 [==============================] - 0s 104us/step - loss: 3.0085e-05 - val_loss: 0.0051\n",
      "\n",
      "Epoch 01132: val_loss did not improve from 0.00328\n",
      "Epoch 1133/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 3.1999e-05 - val_loss: 0.0056\n",
      "\n",
      "Epoch 01133: val_loss did not improve from 0.00328\n",
      "Epoch 1134/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.2022e-05 - val_loss: 0.0054\n",
      "\n",
      "Epoch 01134: val_loss did not improve from 0.00328\n",
      "Epoch 1135/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.0968e-05 - val_loss: 0.0055\n",
      "\n",
      "Epoch 01135: val_loss did not improve from 0.00328\n",
      "Epoch 1136/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.2965e-05 - val_loss: 0.0057\n",
      "\n",
      "Epoch 01136: val_loss did not improve from 0.00328\n",
      "Epoch 1137/3000\n",
      "184/184 [==============================] - 0s 136us/step - loss: 1.9827e-05 - val_loss: 0.0056\n",
      "\n",
      "Epoch 01137: val_loss did not improve from 0.00328\n",
      "Epoch 1138/3000\n",
      "184/184 [==============================] - 0s 158us/step - loss: 2.3525e-05 - val_loss: 0.0055\n",
      "\n",
      "Epoch 01138: val_loss did not improve from 0.00328\n",
      "Epoch 1139/3000\n",
      "184/184 [==============================] - 0s 168us/step - loss: 2.1033e-05 - val_loss: 0.0054\n",
      "\n",
      "Epoch 01139: val_loss did not improve from 0.00328\n",
      "Epoch 1140/3000\n",
      "184/184 [==============================] - 0s 201us/step - loss: 1.8870e-05 - val_loss: 0.0053\n",
      "\n",
      "Epoch 01140: val_loss did not improve from 0.00328\n",
      "Epoch 1141/3000\n",
      "184/184 [==============================] - 0s 185us/step - loss: 2.1209e-05 - val_loss: 0.0054\n",
      "\n",
      "Epoch 01141: val_loss did not improve from 0.00328\n",
      "Epoch 1142/3000\n",
      "184/184 [==============================] - 0s 185us/step - loss: 1.8255e-05 - val_loss: 0.0055\n",
      "\n",
      "Epoch 01142: val_loss did not improve from 0.00328\n",
      "Epoch 1143/3000\n",
      "184/184 [==============================] - 0s 538us/step - loss: 2.8462e-05 - val_loss: 0.0053\n",
      "\n",
      "Epoch 01143: val_loss did not improve from 0.00328\n",
      "Epoch 1144/3000\n",
      "184/184 [==============================] - 0s 467us/step - loss: 2.4740e-05 - val_loss: 0.0051\n",
      "\n",
      "Epoch 01144: val_loss did not improve from 0.00328\n",
      "Epoch 1145/3000\n",
      "184/184 [==============================] - 0s 250us/step - loss: 2.1381e-05 - val_loss: 0.0053\n",
      "\n",
      "Epoch 01145: val_loss did not improve from 0.00328\n",
      "Epoch 1146/3000\n",
      "184/184 [==============================] - 0s 245us/step - loss: 2.0653e-05 - val_loss: 0.0054\n",
      "\n",
      "Epoch 01146: val_loss did not improve from 0.00328\n",
      "Epoch 1147/3000\n",
      "184/184 [==============================] - 0s 179us/step - loss: 1.9395e-05 - val_loss: 0.0055\n",
      "\n",
      "Epoch 01147: val_loss did not improve from 0.00328\n",
      "Epoch 1148/3000\n",
      "184/184 [==============================] - 0s 136us/step - loss: 2.9444e-05 - val_loss: 0.0056\n",
      "\n",
      "Epoch 01148: val_loss did not improve from 0.00328\n",
      "Epoch 1149/3000\n",
      "184/184 [==============================] - 0s 141us/step - loss: 1.9375e-05 - val_loss: 0.0057\n",
      "\n",
      "Epoch 01149: val_loss did not improve from 0.00328\n",
      "Epoch 1150/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 1.6522e-05 - val_loss: 0.0058\n",
      "\n",
      "Epoch 01150: val_loss did not improve from 0.00328\n",
      "Epoch 1151/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.1045e-05 - val_loss: 0.0057\n",
      "\n",
      "Epoch 01151: val_loss did not improve from 0.00328\n",
      "Epoch 1152/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.4646e-05 - val_loss: 0.0055\n",
      "\n",
      "Epoch 01152: val_loss did not improve from 0.00328\n",
      "Epoch 1153/3000\n",
      "184/184 [==============================] - 0s 147us/step - loss: 2.5560e-05 - val_loss: 0.0056\n",
      "\n",
      "Epoch 01153: val_loss did not improve from 0.00328\n",
      "Epoch 1154/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.1627e-05 - val_loss: 0.0060\n",
      "\n",
      "Epoch 01154: val_loss did not improve from 0.00328\n",
      "Epoch 1155/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.4955e-05 - val_loss: 0.0059\n",
      "\n",
      "Epoch 01155: val_loss did not improve from 0.00328\n",
      "Epoch 1156/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 1.7703e-05 - val_loss: 0.0054\n",
      "\n",
      "Epoch 01156: val_loss did not improve from 0.00328\n",
      "Epoch 1157/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.3118e-05 - val_loss: 0.0054\n",
      "\n",
      "Epoch 01157: val_loss did not improve from 0.00328\n",
      "Epoch 1158/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.0906e-05 - val_loss: 0.0056\n",
      "\n",
      "Epoch 01158: val_loss did not improve from 0.00328\n",
      "Epoch 1159/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.2508e-05 - val_loss: 0.0056\n",
      "\n",
      "Epoch 01159: val_loss did not improve from 0.00328\n",
      "Epoch 1160/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 1.6915e-05 - val_loss: 0.0053\n",
      "\n",
      "Epoch 01160: val_loss did not improve from 0.00328\n",
      "Epoch 1161/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.1944e-05 - val_loss: 0.0054\n",
      "\n",
      "Epoch 01161: val_loss did not improve from 0.00328\n",
      "Epoch 1162/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.0136e-05 - val_loss: 0.0057\n",
      "\n",
      "Epoch 01162: val_loss did not improve from 0.00328\n",
      "Epoch 1163/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.5807e-05 - val_loss: 0.0057\n",
      "\n",
      "Epoch 01163: val_loss did not improve from 0.00328\n",
      "Epoch 1164/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.3765e-05 - val_loss: 0.0055\n",
      "\n",
      "Epoch 01164: val_loss did not improve from 0.00328\n",
      "Epoch 1165/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.2367e-05 - val_loss: 0.0055\n",
      "\n",
      "Epoch 01165: val_loss did not improve from 0.00328\n",
      "Epoch 1166/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.5152e-05 - val_loss: 0.0057\n",
      "\n",
      "Epoch 01166: val_loss did not improve from 0.00328\n",
      "Epoch 1167/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.6542e-05 - val_loss: 0.0058\n",
      "\n",
      "Epoch 01167: val_loss did not improve from 0.00328\n",
      "Epoch 1168/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.0636e-05 - val_loss: 0.0057\n",
      "\n",
      "Epoch 01168: val_loss did not improve from 0.00328\n",
      "Epoch 1169/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 2.0114e-05 - val_loss: 0.0056\n",
      "\n",
      "Epoch 01169: val_loss did not improve from 0.00328\n",
      "Epoch 1170/3000\n",
      "184/184 [==============================] - 0s 119us/step - loss: 2.9139e-05 - val_loss: 0.0056\n",
      "\n",
      "Epoch 01170: val_loss did not improve from 0.00328\n",
      "Epoch 1171/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.0841e-05 - val_loss: 0.0056\n",
      "\n",
      "Epoch 01171: val_loss did not improve from 0.00328\n",
      "Epoch 1172/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.1993e-05 - val_loss: 0.0057\n",
      "\n",
      "Epoch 01172: val_loss did not improve from 0.00328\n",
      "Epoch 1173/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.3315e-05 - val_loss: 0.0055\n",
      "\n",
      "Epoch 01173: val_loss did not improve from 0.00328\n",
      "Epoch 1174/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.3060e-05 - val_loss: 0.0054\n",
      "\n",
      "Epoch 01174: val_loss did not improve from 0.00328\n",
      "Epoch 1175/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 98us/step - loss: 1.8239e-05 - val_loss: 0.0054\n",
      "\n",
      "Epoch 01175: val_loss did not improve from 0.00328\n",
      "Epoch 1176/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 1.8403e-05 - val_loss: 0.0055\n",
      "\n",
      "Epoch 01176: val_loss did not improve from 0.00328\n",
      "Epoch 1177/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.0733e-05 - val_loss: 0.0055\n",
      "\n",
      "Epoch 01177: val_loss did not improve from 0.00328\n",
      "Epoch 1178/3000\n",
      "184/184 [==============================] - 0s 152us/step - loss: 2.0411e-05 - val_loss: 0.0056\n",
      "\n",
      "Epoch 01178: val_loss did not improve from 0.00328\n",
      "Epoch 1179/3000\n",
      "184/184 [==============================] - 0s 158us/step - loss: 3.2886e-05 - val_loss: 0.0056\n",
      "\n",
      "Epoch 01179: val_loss did not improve from 0.00328\n",
      "Epoch 1180/3000\n",
      "184/184 [==============================] - 0s 174us/step - loss: 2.2699e-05 - val_loss: 0.0054\n",
      "\n",
      "Epoch 01180: val_loss did not improve from 0.00328\n",
      "Epoch 1181/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.0972e-05 - val_loss: 0.0053\n",
      "\n",
      "Epoch 01181: val_loss did not improve from 0.00328\n",
      "Epoch 1182/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.6206e-05 - val_loss: 0.0054\n",
      "\n",
      "Epoch 01182: val_loss did not improve from 0.00328\n",
      "Epoch 1183/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.4003e-05 - val_loss: 0.0058\n",
      "\n",
      "Epoch 01183: val_loss did not improve from 0.00328\n",
      "Epoch 1184/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.2490e-05 - val_loss: 0.0059\n",
      "\n",
      "Epoch 01184: val_loss did not improve from 0.00328\n",
      "Epoch 1185/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 1.8370e-05 - val_loss: 0.0056\n",
      "\n",
      "Epoch 01185: val_loss did not improve from 0.00328\n",
      "Epoch 1186/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.6675e-05 - val_loss: 0.0055\n",
      "\n",
      "Epoch 01186: val_loss did not improve from 0.00328\n",
      "Epoch 1187/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.1231e-05 - val_loss: 0.0057\n",
      "\n",
      "Epoch 01187: val_loss did not improve from 0.00328\n",
      "Epoch 1188/3000\n",
      "184/184 [==============================] - 0s 169us/step - loss: 2.0978e-05 - val_loss: 0.0059\n",
      "\n",
      "Epoch 01188: val_loss did not improve from 0.00328\n",
      "Epoch 1189/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.3878e-05 - val_loss: 0.0057\n",
      "\n",
      "Epoch 01189: val_loss did not improve from 0.00328\n",
      "Epoch 1190/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.1987e-05 - val_loss: 0.0056\n",
      "\n",
      "Epoch 01190: val_loss did not improve from 0.00328\n",
      "Epoch 1191/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 1.9820e-05 - val_loss: 0.0057\n",
      "\n",
      "Epoch 01191: val_loss did not improve from 0.00328\n",
      "Epoch 1192/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.5648e-05 - val_loss: 0.0058\n",
      "\n",
      "Epoch 01192: val_loss did not improve from 0.00328\n",
      "Epoch 1193/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.4163e-05 - val_loss: 0.0057\n",
      "\n",
      "Epoch 01193: val_loss did not improve from 0.00328\n",
      "Epoch 1194/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.2388e-05 - val_loss: 0.0058\n",
      "\n",
      "Epoch 01194: val_loss did not improve from 0.00328\n",
      "Epoch 1195/3000\n",
      "184/184 [==============================] - 0s 81us/step - loss: 2.3630e-05 - val_loss: 0.0058\n",
      "\n",
      "Epoch 01195: val_loss did not improve from 0.00328\n",
      "Epoch 1196/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.3217e-05 - val_loss: 0.0057\n",
      "\n",
      "Epoch 01196: val_loss did not improve from 0.00328\n",
      "Epoch 1197/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 1.8060e-05 - val_loss: 0.0057\n",
      "\n",
      "Epoch 01197: val_loss did not improve from 0.00328\n",
      "Epoch 1198/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.2182e-05 - val_loss: 0.0059\n",
      "\n",
      "Epoch 01198: val_loss did not improve from 0.00328\n",
      "Epoch 1199/3000\n",
      "184/184 [==============================] - ETA: 0s - loss: 1.1994e-0 - 0s 103us/step - loss: 1.9993e-05 - val_loss: 0.0058\n",
      "\n",
      "Epoch 01199: val_loss did not improve from 0.00328\n",
      "Epoch 1200/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.6574e-05 - val_loss: 0.0058\n",
      "\n",
      "Epoch 01200: val_loss did not improve from 0.00328\n",
      "Epoch 1201/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 2.0272e-05 - val_loss: 0.0059\n",
      "\n",
      "Epoch 01201: val_loss did not improve from 0.00328\n",
      "Epoch 1202/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.1212e-05 - val_loss: 0.0059\n",
      "\n",
      "Epoch 01202: val_loss did not improve from 0.00328\n",
      "Epoch 1203/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.3921e-05 - val_loss: 0.0057\n",
      "\n",
      "Epoch 01203: val_loss did not improve from 0.00328\n",
      "Epoch 1204/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.1946e-05 - val_loss: 0.0057\n",
      "\n",
      "Epoch 01204: val_loss did not improve from 0.00328\n",
      "Epoch 1205/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.5435e-05 - val_loss: 0.0059\n",
      "\n",
      "Epoch 01205: val_loss did not improve from 0.00328\n",
      "Epoch 1206/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.2651e-05 - val_loss: 0.0059\n",
      "\n",
      "Epoch 01206: val_loss did not improve from 0.00328\n",
      "Epoch 1207/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.5904e-05 - val_loss: 0.0057\n",
      "\n",
      "Epoch 01207: val_loss did not improve from 0.00328\n",
      "Epoch 1208/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.1673e-05 - val_loss: 0.0056\n",
      "\n",
      "Epoch 01208: val_loss did not improve from 0.00328\n",
      "Epoch 1209/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.5907e-05 - val_loss: 0.0055\n",
      "\n",
      "Epoch 01209: val_loss did not improve from 0.00328\n",
      "Epoch 1210/3000\n",
      "184/184 [==============================] - 0s 81us/step - loss: 2.3614e-05 - val_loss: 0.0057\n",
      "\n",
      "Epoch 01210: val_loss did not improve from 0.00328\n",
      "Epoch 1211/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.2901e-05 - val_loss: 0.0060\n",
      "\n",
      "Epoch 01211: val_loss did not improve from 0.00328\n",
      "Epoch 1212/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.3034e-05 - val_loss: 0.0058\n",
      "\n",
      "Epoch 01212: val_loss did not improve from 0.00328\n",
      "Epoch 1213/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.1365e-05 - val_loss: 0.0055\n",
      "\n",
      "Epoch 01213: val_loss did not improve from 0.00328\n",
      "Epoch 1214/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.9505e-05 - val_loss: 0.0058\n",
      "\n",
      "Epoch 01214: val_loss did not improve from 0.00328\n",
      "Epoch 1215/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.2785e-05 - val_loss: 0.0061\n",
      "\n",
      "Epoch 01215: val_loss did not improve from 0.00328\n",
      "Epoch 1216/3000\n",
      "184/184 [==============================] - 0s 93us/step - loss: 2.4346e-05 - val_loss: 0.0061\n",
      "\n",
      "Epoch 01216: val_loss did not improve from 0.00328\n",
      "Epoch 1217/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.0308e-05 - val_loss: 0.0057\n",
      "\n",
      "Epoch 01217: val_loss did not improve from 0.00328\n",
      "Epoch 1218/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.7161e-05 - val_loss: 0.0056\n",
      "\n",
      "Epoch 01218: val_loss did not improve from 0.00328\n",
      "Epoch 1219/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.3000e-05 - val_loss: 0.0061\n",
      "\n",
      "Epoch 01219: val_loss did not improve from 0.00328\n",
      "Epoch 1220/3000\n",
      "184/184 [==============================] - 0s 131us/step - loss: 2.5182e-05 - val_loss: 0.0061\n",
      "\n",
      "Epoch 01220: val_loss did not improve from 0.00328\n",
      "Epoch 1221/3000\n",
      "184/184 [==============================] - 0s 136us/step - loss: 2.3405e-05 - val_loss: 0.0059\n",
      "\n",
      "Epoch 01221: val_loss did not improve from 0.00328\n",
      "Epoch 1222/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.0984e-05 - val_loss: 0.0056\n",
      "\n",
      "Epoch 01222: val_loss did not improve from 0.00328\n",
      "Epoch 1223/3000\n",
      "184/184 [==============================] - 0s 141us/step - loss: 2.2060e-05 - val_loss: 0.0054\n",
      "\n",
      "Epoch 01223: val_loss did not improve from 0.00328\n",
      "Epoch 1224/3000\n",
      "184/184 [==============================] - 0s 119us/step - loss: 2.2710e-05 - val_loss: 0.0058\n",
      "\n",
      "Epoch 01224: val_loss did not improve from 0.00328\n",
      "Epoch 1225/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 92us/step - loss: 2.6695e-05 - val_loss: 0.0063\n",
      "\n",
      "Epoch 01225: val_loss did not improve from 0.00328\n",
      "Epoch 1226/3000\n",
      "184/184 [==============================] - 0s 93us/step - loss: 2.3098e-05 - val_loss: 0.0061\n",
      "\n",
      "Epoch 01226: val_loss did not improve from 0.00328\n",
      "Epoch 1227/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.1630e-05 - val_loss: 0.0057\n",
      "\n",
      "Epoch 01227: val_loss did not improve from 0.00328\n",
      "Epoch 1228/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.8775e-05 - val_loss: 0.0058\n",
      "\n",
      "Epoch 01228: val_loss did not improve from 0.00328\n",
      "Epoch 1229/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.5814e-05 - val_loss: 0.0062\n",
      "\n",
      "Epoch 01229: val_loss did not improve from 0.00328\n",
      "Epoch 1230/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.2726e-05 - val_loss: 0.0059\n",
      "\n",
      "Epoch 01230: val_loss did not improve from 0.00328\n",
      "Epoch 1231/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.4358e-05 - val_loss: 0.0056\n",
      "\n",
      "Epoch 01231: val_loss did not improve from 0.00328\n",
      "Epoch 1232/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.9903e-05 - val_loss: 0.0057\n",
      "\n",
      "Epoch 01232: val_loss did not improve from 0.00328\n",
      "Epoch 1233/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.5603e-05 - val_loss: 0.0060\n",
      "\n",
      "Epoch 01233: val_loss did not improve from 0.00328\n",
      "Epoch 1234/3000\n",
      "184/184 [==============================] - 0s 130us/step - loss: 2.0117e-05 - val_loss: 0.0060\n",
      "\n",
      "Epoch 01234: val_loss did not improve from 0.00328\n",
      "Epoch 1235/3000\n",
      "184/184 [==============================] - 0s 147us/step - loss: 2.3069e-05 - val_loss: 0.0058\n",
      "\n",
      "Epoch 01235: val_loss did not improve from 0.00328\n",
      "Epoch 1236/3000\n",
      "184/184 [==============================] - 0s 120us/step - loss: 2.3917e-05 - val_loss: 0.0057\n",
      "\n",
      "Epoch 01236: val_loss did not improve from 0.00328\n",
      "Epoch 1237/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.3936e-05 - val_loss: 0.0058\n",
      "\n",
      "Epoch 01237: val_loss did not improve from 0.00328\n",
      "Epoch 1238/3000\n",
      "184/184 [==============================] - 0s 141us/step - loss: 2.2408e-05 - val_loss: 0.0059\n",
      "\n",
      "Epoch 01238: val_loss did not improve from 0.00328\n",
      "Epoch 1239/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 1.8414e-05 - val_loss: 0.0058\n",
      "\n",
      "Epoch 01239: val_loss did not improve from 0.00328\n",
      "Epoch 1240/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.4857e-05 - val_loss: 0.0058\n",
      "\n",
      "Epoch 01240: val_loss did not improve from 0.00328\n",
      "Epoch 1241/3000\n",
      "184/184 [==============================] - 0s 120us/step - loss: 2.3120e-05 - val_loss: 0.0061\n",
      "\n",
      "Epoch 01241: val_loss did not improve from 0.00328\n",
      "Epoch 1242/3000\n",
      "184/184 [==============================] - 0s 106us/step - loss: 2.3741e-05 - val_loss: 0.0060\n",
      "\n",
      "Epoch 01242: val_loss did not improve from 0.00328\n",
      "Epoch 1243/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.3045e-05 - val_loss: 0.0059\n",
      "\n",
      "Epoch 01243: val_loss did not improve from 0.00328\n",
      "Epoch 1244/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.3439e-05 - val_loss: 0.0060\n",
      "\n",
      "Epoch 01244: val_loss did not improve from 0.00328\n",
      "Epoch 1245/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 1.9762e-05 - val_loss: 0.0061\n",
      "\n",
      "Epoch 01245: val_loss did not improve from 0.00328\n",
      "Epoch 1246/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.0221e-05 - val_loss: 0.0061\n",
      "\n",
      "Epoch 01246: val_loss did not improve from 0.00328\n",
      "Epoch 1247/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 1.9449e-05 - val_loss: 0.0059\n",
      "\n",
      "Epoch 01247: val_loss did not improve from 0.00328\n",
      "Epoch 1248/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.4093e-05 - val_loss: 0.0059\n",
      "\n",
      "Epoch 01248: val_loss did not improve from 0.00328\n",
      "Epoch 1249/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.3760e-05 - val_loss: 0.0058\n",
      "\n",
      "Epoch 01249: val_loss did not improve from 0.00328\n",
      "Epoch 1250/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.0146e-05 - val_loss: 0.0059\n",
      "\n",
      "Epoch 01250: val_loss did not improve from 0.00328\n",
      "Epoch 1251/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.1560e-05 - val_loss: 0.0060\n",
      "\n",
      "Epoch 01251: val_loss did not improve from 0.00328\n",
      "Epoch 1252/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.3388e-05 - val_loss: 0.0058\n",
      "\n",
      "Epoch 01252: val_loss did not improve from 0.00328\n",
      "Epoch 1253/3000\n",
      "184/184 [==============================] - 0s 93us/step - loss: 2.3502e-05 - val_loss: 0.0056\n",
      "\n",
      "Epoch 01253: val_loss did not improve from 0.00328\n",
      "Epoch 1254/3000\n",
      "184/184 [==============================] - 0s 76us/step - loss: 2.5443e-05 - val_loss: 0.0057\n",
      "\n",
      "Epoch 01254: val_loss did not improve from 0.00328\n",
      "Epoch 1255/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.4695e-05 - val_loss: 0.0062\n",
      "\n",
      "Epoch 01255: val_loss did not improve from 0.00328\n",
      "Epoch 1256/3000\n",
      "184/184 [==============================] - 0s 93us/step - loss: 2.0097e-05 - val_loss: 0.0064\n",
      "\n",
      "Epoch 01256: val_loss did not improve from 0.00328\n",
      "Epoch 1257/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 1.6111e-05 - val_loss: 0.0061\n",
      "\n",
      "Epoch 01257: val_loss did not improve from 0.00328\n",
      "Epoch 1258/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.2785e-05 - val_loss: 0.0060\n",
      "\n",
      "Epoch 01258: val_loss did not improve from 0.00328\n",
      "Epoch 1259/3000\n",
      "184/184 [==============================] - 0s 93us/step - loss: 2.9248e-05 - val_loss: 0.0061\n",
      "\n",
      "Epoch 01259: val_loss did not improve from 0.00328\n",
      "Epoch 1260/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.3490e-05 - val_loss: 0.0062\n",
      "\n",
      "Epoch 01260: val_loss did not improve from 0.00328\n",
      "Epoch 1261/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.2078e-05 - val_loss: 0.0060\n",
      "\n",
      "Epoch 01261: val_loss did not improve from 0.00328\n",
      "Epoch 1262/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.6504e-05 - val_loss: 0.0060\n",
      "\n",
      "Epoch 01262: val_loss did not improve from 0.00328\n",
      "Epoch 1263/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 1.6888e-05 - val_loss: 0.0060\n",
      "\n",
      "Epoch 01263: val_loss did not improve from 0.00328\n",
      "Epoch 1264/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.1619e-05 - val_loss: 0.0058\n",
      "\n",
      "Epoch 01264: val_loss did not improve from 0.00328\n",
      "Epoch 1265/3000\n",
      "184/184 [==============================] - 0s 130us/step - loss: 2.3247e-05 - val_loss: 0.0057\n",
      "\n",
      "Epoch 01265: val_loss did not improve from 0.00328\n",
      "Epoch 1266/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.4353e-05 - val_loss: 0.0059\n",
      "\n",
      "Epoch 01266: val_loss did not improve from 0.00328\n",
      "Epoch 1267/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.4229e-05 - val_loss: 0.0062\n",
      "\n",
      "Epoch 01267: val_loss did not improve from 0.00328\n",
      "Epoch 1268/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.2161e-05 - val_loss: 0.0061\n",
      "\n",
      "Epoch 01268: val_loss did not improve from 0.00328\n",
      "Epoch 1269/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.3259e-05 - val_loss: 0.0060\n",
      "\n",
      "Epoch 01269: val_loss did not improve from 0.00328\n",
      "Epoch 1270/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.0944e-05 - val_loss: 0.0060\n",
      "\n",
      "Epoch 01270: val_loss did not improve from 0.00328\n",
      "Epoch 1271/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.1940e-05 - val_loss: 0.0063\n",
      "\n",
      "Epoch 01271: val_loss did not improve from 0.00328\n",
      "Epoch 1272/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.5390e-05 - val_loss: 0.0062\n",
      "\n",
      "Epoch 01272: val_loss did not improve from 0.00328\n",
      "Epoch 1273/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 1.9215e-05 - val_loss: 0.0060\n",
      "\n",
      "Epoch 01273: val_loss did not improve from 0.00328\n",
      "Epoch 1274/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.7474e-05 - val_loss: 0.0062\n",
      "\n",
      "Epoch 01274: val_loss did not improve from 0.00328\n",
      "Epoch 1275/3000\n",
      "184/184 [==============================] - 0s 93us/step - loss: 2.5484e-05 - val_loss: 0.0065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 01275: val_loss did not improve from 0.00328\n",
      "Epoch 1276/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 1.8388e-05 - val_loss: 0.0063\n",
      "\n",
      "Epoch 01276: val_loss did not improve from 0.00328\n",
      "Epoch 1277/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.2941e-05 - val_loss: 0.0058\n",
      "\n",
      "Epoch 01277: val_loss did not improve from 0.00328\n",
      "Epoch 1278/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.7447e-05 - val_loss: 0.0056\n",
      "\n",
      "Epoch 01278: val_loss did not improve from 0.00328\n",
      "Epoch 1279/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.4983e-05 - val_loss: 0.0058\n",
      "\n",
      "Epoch 01279: val_loss did not improve from 0.00328\n",
      "Epoch 1280/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.6497e-05 - val_loss: 0.0062\n",
      "\n",
      "Epoch 01280: val_loss did not improve from 0.00328\n",
      "Epoch 1281/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.2977e-05 - val_loss: 0.0060\n",
      "\n",
      "Epoch 01281: val_loss did not improve from 0.00328\n",
      "Epoch 1282/3000\n",
      "184/184 [==============================] - 0s 101us/step - loss: 2.0064e-05 - val_loss: 0.0056\n",
      "\n",
      "Epoch 01282: val_loss did not improve from 0.00328\n",
      "Epoch 1283/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.5639e-05 - val_loss: 0.0055\n",
      "\n",
      "Epoch 01283: val_loss did not improve from 0.00328\n",
      "Epoch 1284/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.1806e-05 - val_loss: 0.0059\n",
      "\n",
      "Epoch 01284: val_loss did not improve from 0.00328\n",
      "Epoch 1285/3000\n",
      "184/184 [==============================] - 0s 93us/step - loss: 1.9592e-05 - val_loss: 0.0062\n",
      "\n",
      "Epoch 01285: val_loss did not improve from 0.00328\n",
      "Epoch 1286/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.3215e-05 - val_loss: 0.0061\n",
      "\n",
      "Epoch 01286: val_loss did not improve from 0.00328\n",
      "Epoch 1287/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.1821e-05 - val_loss: 0.0059\n",
      "\n",
      "Epoch 01287: val_loss did not improve from 0.00328\n",
      "Epoch 1288/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 1.9787e-05 - val_loss: 0.0060\n",
      "\n",
      "Epoch 01288: val_loss did not improve from 0.00328\n",
      "Epoch 1289/3000\n",
      "184/184 [==============================] - ETA: 0s - loss: 1.2525e-0 - 0s 114us/step - loss: 2.2928e-05 - val_loss: 0.0060\n",
      "\n",
      "Epoch 01289: val_loss did not improve from 0.00328\n",
      "Epoch 1290/3000\n",
      "184/184 [==============================] - 0s 95us/step - loss: 1.9888e-05 - val_loss: 0.0061\n",
      "\n",
      "Epoch 01290: val_loss did not improve from 0.00328\n",
      "Epoch 1291/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.0200e-05 - val_loss: 0.0063\n",
      "\n",
      "Epoch 01291: val_loss did not improve from 0.00328\n",
      "Epoch 1292/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.8322e-05 - val_loss: 0.0064\n",
      "\n",
      "Epoch 01292: val_loss did not improve from 0.00328\n",
      "Epoch 1293/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.3053e-05 - val_loss: 0.0062\n",
      "\n",
      "Epoch 01293: val_loss did not improve from 0.00328\n",
      "Epoch 1294/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.1050e-05 - val_loss: 0.0061\n",
      "\n",
      "Epoch 01294: val_loss did not improve from 0.00328\n",
      "Epoch 1295/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.2325e-05 - val_loss: 0.0060\n",
      "\n",
      "Epoch 01295: val_loss did not improve from 0.00328\n",
      "Epoch 1296/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 2.0496e-05 - val_loss: 0.0061\n",
      "\n",
      "Epoch 01296: val_loss did not improve from 0.00328\n",
      "Epoch 1297/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.5342e-05 - val_loss: 0.0061\n",
      "\n",
      "Epoch 01297: val_loss did not improve from 0.00328\n",
      "Epoch 1298/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.1300e-05 - val_loss: 0.0058\n",
      "\n",
      "Epoch 01298: val_loss did not improve from 0.00328\n",
      "Epoch 1299/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.1701e-05 - val_loss: 0.0058\n",
      "\n",
      "Epoch 01299: val_loss did not improve from 0.00328\n",
      "Epoch 1300/3000\n",
      "184/184 [==============================] - 0s 93us/step - loss: 2.0370e-05 - val_loss: 0.0060\n",
      "\n",
      "Epoch 01300: val_loss did not improve from 0.00328\n",
      "Epoch 1301/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.3854e-05 - val_loss: 0.0061\n",
      "\n",
      "Epoch 01301: val_loss did not improve from 0.00328\n",
      "Epoch 1302/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.2397e-05 - val_loss: 0.0060\n",
      "\n",
      "Epoch 01302: val_loss did not improve from 0.00328\n",
      "Epoch 1303/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 1.7851e-05 - val_loss: 0.0061\n",
      "\n",
      "Epoch 01303: val_loss did not improve from 0.00328\n",
      "Epoch 1304/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 1.9932e-05 - val_loss: 0.0063\n",
      "\n",
      "Epoch 01304: val_loss did not improve from 0.00328\n",
      "Epoch 1305/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.0088e-05 - val_loss: 0.0063\n",
      "\n",
      "Epoch 01305: val_loss did not improve from 0.00328\n",
      "Epoch 1306/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.2543e-05 - val_loss: 0.0061\n",
      "\n",
      "Epoch 01306: val_loss did not improve from 0.00328\n",
      "Epoch 1307/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.0866e-05 - val_loss: 0.0060\n",
      "\n",
      "Epoch 01307: val_loss did not improve from 0.00328\n",
      "Epoch 1308/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.2936e-05 - val_loss: 0.0060\n",
      "\n",
      "Epoch 01308: val_loss did not improve from 0.00328\n",
      "Epoch 1309/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.5706e-05 - val_loss: 0.0060\n",
      "\n",
      "Epoch 01309: val_loss did not improve from 0.00328\n",
      "Epoch 1310/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.7723e-05 - val_loss: 0.0059\n",
      "\n",
      "Epoch 01310: val_loss did not improve from 0.00328\n",
      "Epoch 1311/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.3417e-05 - val_loss: 0.0057\n",
      "\n",
      "Epoch 01311: val_loss did not improve from 0.00328\n",
      "Epoch 1312/3000\n",
      "184/184 [==============================] - 0s 95us/step - loss: 2.5794e-05 - val_loss: 0.0057\n",
      "\n",
      "Epoch 01312: val_loss did not improve from 0.00328\n",
      "Epoch 1313/3000\n",
      "184/184 [==============================] - 0s 196us/step - loss: 2.5807e-05 - val_loss: 0.0058\n",
      "\n",
      "Epoch 01313: val_loss did not improve from 0.00328\n",
      "Epoch 1314/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 1.8933e-05 - val_loss: 0.0061\n",
      "\n",
      "Epoch 01314: val_loss did not improve from 0.00328\n",
      "Epoch 1315/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.4442e-05 - val_loss: 0.0061\n",
      "\n",
      "Epoch 01315: val_loss did not improve from 0.00328\n",
      "Epoch 1316/3000\n",
      "184/184 [==============================] - 0s 93us/step - loss: 1.8559e-05 - val_loss: 0.0058\n",
      "\n",
      "Epoch 01316: val_loss did not improve from 0.00328\n",
      "Epoch 1317/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.1331e-05 - val_loss: 0.0060\n",
      "\n",
      "Epoch 01317: val_loss did not improve from 0.00328\n",
      "Epoch 1318/3000\n",
      "184/184 [==============================] - ETA: 0s - loss: 1.3846e-0 - 0s 103us/step - loss: 2.3288e-05 - val_loss: 0.0064\n",
      "\n",
      "Epoch 01318: val_loss did not improve from 0.00328\n",
      "Epoch 1319/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.4592e-05 - val_loss: 0.0064\n",
      "\n",
      "Epoch 01319: val_loss did not improve from 0.00328\n",
      "Epoch 1320/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.6267e-05 - val_loss: 0.0060\n",
      "\n",
      "Epoch 01320: val_loss did not improve from 0.00328\n",
      "Epoch 1321/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 2.3673e-05 - val_loss: 0.0059\n",
      "\n",
      "Epoch 01321: val_loss did not improve from 0.00328\n",
      "Epoch 1322/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.5855e-05 - val_loss: 0.0063\n",
      "\n",
      "Epoch 01322: val_loss did not improve from 0.00328\n",
      "Epoch 1323/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.2812e-05 - val_loss: 0.0064\n",
      "\n",
      "Epoch 01323: val_loss did not improve from 0.00328\n",
      "Epoch 1324/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.3093e-05 - val_loss: 0.0063\n",
      "\n",
      "Epoch 01324: val_loss did not improve from 0.00328\n",
      "Epoch 1325/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.2307e-05 - val_loss: 0.0061\n",
      "\n",
      "Epoch 01325: val_loss did not improve from 0.00328\n",
      "Epoch 1326/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 87us/step - loss: 2.5897e-05 - val_loss: 0.0060\n",
      "\n",
      "Epoch 01326: val_loss did not improve from 0.00328\n",
      "Epoch 1327/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.0063e-05 - val_loss: 0.0061\n",
      "\n",
      "Epoch 01327: val_loss did not improve from 0.00328\n",
      "Epoch 1328/3000\n",
      "184/184 [==============================] - 0s 101us/step - loss: 1.9422e-05 - val_loss: 0.0063\n",
      "\n",
      "Epoch 01328: val_loss did not improve from 0.00328\n",
      "Epoch 1329/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.6932e-05 - val_loss: 0.0062\n",
      "\n",
      "Epoch 01329: val_loss did not improve from 0.00328\n",
      "Epoch 1330/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 1.6508e-05 - val_loss: 0.0058\n",
      "\n",
      "Epoch 01330: val_loss did not improve from 0.00328\n",
      "Epoch 1331/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.3842e-05 - val_loss: 0.0057\n",
      "\n",
      "Epoch 01331: val_loss did not improve from 0.00328\n",
      "Epoch 1332/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.0482e-05 - val_loss: 0.0061\n",
      "\n",
      "Epoch 01332: val_loss did not improve from 0.00328\n",
      "Epoch 1333/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.1714e-05 - val_loss: 0.0063\n",
      "\n",
      "Epoch 01333: val_loss did not improve from 0.00328\n",
      "Epoch 1334/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.5400e-05 - val_loss: 0.0061\n",
      "\n",
      "Epoch 01334: val_loss did not improve from 0.00328\n",
      "Epoch 1335/3000\n",
      "184/184 [==============================] - ETA: 0s - loss: 1.2030e-0 - 0s 114us/step - loss: 2.1207e-05 - val_loss: 0.0058\n",
      "\n",
      "Epoch 01335: val_loss did not improve from 0.00328\n",
      "Epoch 1336/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.5950e-05 - val_loss: 0.0059\n",
      "\n",
      "Epoch 01336: val_loss did not improve from 0.00328\n",
      "Epoch 1337/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.1331e-05 - val_loss: 0.0064\n",
      "\n",
      "Epoch 01337: val_loss did not improve from 0.00328\n",
      "Epoch 1338/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.6267e-05 - val_loss: 0.0065\n",
      "\n",
      "Epoch 01338: val_loss did not improve from 0.00328\n",
      "Epoch 1339/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.0469e-05 - val_loss: 0.0062\n",
      "\n",
      "Epoch 01339: val_loss did not improve from 0.00328\n",
      "Epoch 1340/3000\n",
      "184/184 [==============================] - 0s 131us/step - loss: 2.0385e-05 - val_loss: 0.0060\n",
      "\n",
      "Epoch 01340: val_loss did not improve from 0.00328\n",
      "Epoch 1341/3000\n",
      "184/184 [==============================] - 0s 119us/step - loss: 2.6069e-05 - val_loss: 0.0060\n",
      "\n",
      "Epoch 01341: val_loss did not improve from 0.00328\n",
      "Epoch 1342/3000\n",
      "184/184 [==============================] - 0s 158us/step - loss: 2.3203e-05 - val_loss: 0.0064\n",
      "\n",
      "Epoch 01342: val_loss did not improve from 0.00328\n",
      "Epoch 1343/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.4157e-05 - val_loss: 0.0070\n",
      "\n",
      "Epoch 01343: val_loss did not improve from 0.00328\n",
      "Epoch 1344/3000\n",
      "184/184 [==============================] - 0s 93us/step - loss: 3.1049e-05 - val_loss: 0.0068\n",
      "\n",
      "Epoch 01344: val_loss did not improve from 0.00328\n",
      "Epoch 1345/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 3.3415e-05 - val_loss: 0.0060\n",
      "\n",
      "Epoch 01345: val_loss did not improve from 0.00328\n",
      "Epoch 1346/3000\n",
      "184/184 [==============================] - 0s 93us/step - loss: 3.2813e-05 - val_loss: 0.0058\n",
      "\n",
      "Epoch 01346: val_loss did not improve from 0.00328\n",
      "Epoch 1347/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 3.0607e-05 - val_loss: 0.0063\n",
      "\n",
      "Epoch 01347: val_loss did not improve from 0.00328\n",
      "Epoch 1348/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.6269e-05 - val_loss: 0.0067\n",
      "\n",
      "Epoch 01348: val_loss did not improve from 0.00328\n",
      "Epoch 1349/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.4900e-05 - val_loss: 0.0062\n",
      "\n",
      "Epoch 01349: val_loss did not improve from 0.00328\n",
      "Epoch 1350/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.2172e-05 - val_loss: 0.0058\n",
      "\n",
      "Epoch 01350: val_loss did not improve from 0.00328\n",
      "Epoch 1351/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.3008e-05 - val_loss: 0.0060\n",
      "\n",
      "Epoch 01351: val_loss did not improve from 0.00328\n",
      "Epoch 1352/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.2474e-05 - val_loss: 0.0063\n",
      "\n",
      "Epoch 01352: val_loss did not improve from 0.00328\n",
      "Epoch 1353/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.6976e-05 - val_loss: 0.0061\n",
      "\n",
      "Epoch 01353: val_loss did not improve from 0.00328\n",
      "Epoch 1354/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 1.7945e-05 - val_loss: 0.0061\n",
      "\n",
      "Epoch 01354: val_loss did not improve from 0.00328\n",
      "Epoch 1355/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.2524e-05 - val_loss: 0.0063\n",
      "\n",
      "Epoch 01355: val_loss did not improve from 0.00328\n",
      "Epoch 1356/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 1.9489e-05 - val_loss: 0.0062\n",
      "\n",
      "Epoch 01356: val_loss did not improve from 0.00328\n",
      "Epoch 1357/3000\n",
      "184/184 [==============================] - 0s 141us/step - loss: 1.8782e-05 - val_loss: 0.0062\n",
      "\n",
      "Epoch 01357: val_loss did not improve from 0.00328\n",
      "Epoch 1358/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 1.6471e-05 - val_loss: 0.0062\n",
      "\n",
      "Epoch 01358: val_loss did not improve from 0.00328\n",
      "Epoch 1359/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.2939e-05 - val_loss: 0.0061\n",
      "\n",
      "Epoch 01359: val_loss did not improve from 0.00328\n",
      "Epoch 1360/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.1645e-05 - val_loss: 0.0064\n",
      "\n",
      "Epoch 01360: val_loss did not improve from 0.00328\n",
      "Epoch 1361/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 1.9104e-05 - val_loss: 0.0064\n",
      "\n",
      "Epoch 01361: val_loss did not improve from 0.00328\n",
      "Epoch 1362/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 1.8605e-05 - val_loss: 0.0063\n",
      "\n",
      "Epoch 01362: val_loss did not improve from 0.00328\n",
      "Epoch 1363/3000\n",
      "184/184 [==============================] - 0s 119us/step - loss: 1.9771e-05 - val_loss: 0.0060\n",
      "\n",
      "Epoch 01363: val_loss did not improve from 0.00328\n",
      "Epoch 1364/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 2.6550e-05 - val_loss: 0.0060\n",
      "\n",
      "Epoch 01364: val_loss did not improve from 0.00328\n",
      "Epoch 1365/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.4876e-05 - val_loss: 0.0064\n",
      "\n",
      "Epoch 01365: val_loss did not improve from 0.00328\n",
      "Epoch 1366/3000\n",
      "184/184 [==============================] - 0s 120us/step - loss: 2.3863e-05 - val_loss: 0.0064\n",
      "\n",
      "Epoch 01366: val_loss did not improve from 0.00328\n",
      "Epoch 1367/3000\n",
      "184/184 [==============================] - 0s 93us/step - loss: 2.5428e-05 - val_loss: 0.0062\n",
      "\n",
      "Epoch 01367: val_loss did not improve from 0.00328\n",
      "Epoch 1368/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 1.8209e-05 - val_loss: 0.0064\n",
      "\n",
      "Epoch 01368: val_loss did not improve from 0.00328\n",
      "Epoch 1369/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.5687e-05 - val_loss: 0.0066\n",
      "\n",
      "Epoch 01369: val_loss did not improve from 0.00328\n",
      "Epoch 1370/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 1.9916e-05 - val_loss: 0.0065\n",
      "\n",
      "Epoch 01370: val_loss did not improve from 0.00328\n",
      "Epoch 1371/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.3770e-05 - val_loss: 0.0063\n",
      "\n",
      "Epoch 01371: val_loss did not improve from 0.00328\n",
      "Epoch 1372/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.9994e-05 - val_loss: 0.0064\n",
      "\n",
      "Epoch 01372: val_loss did not improve from 0.00328\n",
      "Epoch 1373/3000\n",
      "184/184 [==============================] - 0s 120us/step - loss: 2.3078e-05 - val_loss: 0.0064\n",
      "\n",
      "Epoch 01373: val_loss did not improve from 0.00328\n",
      "Epoch 1374/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.5981e-05 - val_loss: 0.0062\n",
      "\n",
      "Epoch 01374: val_loss did not improve from 0.00328\n",
      "Epoch 1375/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.4411e-05 - val_loss: 0.0062\n",
      "\n",
      "Epoch 01375: val_loss did not improve from 0.00328\n",
      "Epoch 1376/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 98us/step - loss: 2.2411e-05 - val_loss: 0.0063\n",
      "\n",
      "Epoch 01376: val_loss did not improve from 0.00328\n",
      "Epoch 1377/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.1522e-05 - val_loss: 0.0063\n",
      "\n",
      "Epoch 01377: val_loss did not improve from 0.00328\n",
      "Epoch 1378/3000\n",
      "184/184 [==============================] - 0s 137us/step - loss: 2.5391e-05 - val_loss: 0.0063\n",
      "\n",
      "Epoch 01378: val_loss did not improve from 0.00328\n",
      "Epoch 1379/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.1387e-05 - val_loss: 0.0061\n",
      "\n",
      "Epoch 01379: val_loss did not improve from 0.00328\n",
      "Epoch 1380/3000\n",
      "184/184 [==============================] - 0s 158us/step - loss: 2.8082e-05 - val_loss: 0.0061\n",
      "\n",
      "Epoch 01380: val_loss did not improve from 0.00328\n",
      "Epoch 1381/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 2.3121e-05 - val_loss: 0.0063\n",
      "\n",
      "Epoch 01381: val_loss did not improve from 0.00328\n",
      "Epoch 1382/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 2.1937e-05 - val_loss: 0.0063\n",
      "\n",
      "Epoch 01382: val_loss did not improve from 0.00328\n",
      "Epoch 1383/3000\n",
      "184/184 [==============================] - ETA: 0s - loss: 1.1277e-0 - 0s 228us/step - loss: 1.8132e-05 - val_loss: 0.0060\n",
      "\n",
      "Epoch 01383: val_loss did not improve from 0.00328\n",
      "Epoch 1384/3000\n",
      "184/184 [==============================] - 0s 135us/step - loss: 1.8271e-05 - val_loss: 0.0060\n",
      "\n",
      "Epoch 01384: val_loss did not improve from 0.00328\n",
      "Epoch 1385/3000\n",
      "184/184 [==============================] - 0s 141us/step - loss: 2.0882e-05 - val_loss: 0.0062\n",
      "\n",
      "Epoch 01385: val_loss did not improve from 0.00328\n",
      "Epoch 1386/3000\n",
      "184/184 [==============================] - 0s 136us/step - loss: 2.2087e-05 - val_loss: 0.0064\n",
      "\n",
      "Epoch 01386: val_loss did not improve from 0.00328\n",
      "Epoch 1387/3000\n",
      "184/184 [==============================] - 0s 169us/step - loss: 2.0887e-05 - val_loss: 0.0062\n",
      "\n",
      "Epoch 01387: val_loss did not improve from 0.00328\n",
      "Epoch 1388/3000\n",
      "184/184 [==============================] - 0s 158us/step - loss: 2.5612e-05 - val_loss: 0.0061\n",
      "\n",
      "Epoch 01388: val_loss did not improve from 0.00328\n",
      "Epoch 1389/3000\n",
      "184/184 [==============================] - 0s 163us/step - loss: 2.1991e-05 - val_loss: 0.0064\n",
      "\n",
      "Epoch 01389: val_loss did not improve from 0.00328\n",
      "Epoch 1390/3000\n",
      "184/184 [==============================] - 0s 152us/step - loss: 2.4056e-05 - val_loss: 0.0066\n",
      "\n",
      "Epoch 01390: val_loss did not improve from 0.00328\n",
      "Epoch 1391/3000\n",
      "184/184 [==============================] - 0s 141us/step - loss: 1.7539e-05 - val_loss: 0.0066\n",
      "\n",
      "Epoch 01391: val_loss did not improve from 0.00328\n",
      "Epoch 1392/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.2022e-05 - val_loss: 0.0066\n",
      "\n",
      "Epoch 01392: val_loss did not improve from 0.00328\n",
      "Epoch 1393/3000\n",
      "184/184 [==============================] - 0s 158us/step - loss: 1.9621e-05 - val_loss: 0.0065\n",
      "\n",
      "Epoch 01393: val_loss did not improve from 0.00328\n",
      "Epoch 1394/3000\n",
      "184/184 [==============================] - 0s 174us/step - loss: 2.3580e-05 - val_loss: 0.0065\n",
      "\n",
      "Epoch 01394: val_loss did not improve from 0.00328\n",
      "Epoch 1395/3000\n",
      "184/184 [==============================] - 0s 152us/step - loss: 2.3360e-05 - val_loss: 0.0064\n",
      "\n",
      "Epoch 01395: val_loss did not improve from 0.00328\n",
      "Epoch 1396/3000\n",
      "184/184 [==============================] - 0s 217us/step - loss: 2.2869e-05 - val_loss: 0.0066\n",
      "\n",
      "Epoch 01396: val_loss did not improve from 0.00328\n",
      "Epoch 1397/3000\n",
      "184/184 [==============================] - 0s 152us/step - loss: 2.4969e-05 - val_loss: 0.0067\n",
      "\n",
      "Epoch 01397: val_loss did not improve from 0.00328\n",
      "Epoch 1398/3000\n",
      "184/184 [==============================] - 0s 158us/step - loss: 1.9106e-05 - val_loss: 0.0064\n",
      "\n",
      "Epoch 01398: val_loss did not improve from 0.00328\n",
      "Epoch 1399/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 2.2521e-05 - val_loss: 0.0061\n",
      "\n",
      "Epoch 01399: val_loss did not improve from 0.00328\n",
      "Epoch 1400/3000\n",
      "184/184 [==============================] - 0s 120us/step - loss: 2.5933e-05 - val_loss: 0.0061\n",
      "\n",
      "Epoch 01400: val_loss did not improve from 0.00328\n",
      "Epoch 1401/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 1.8519e-05 - val_loss: 0.0065\n",
      "\n",
      "Epoch 01401: val_loss did not improve from 0.00328\n",
      "Epoch 1402/3000\n",
      "184/184 [==============================] - ETA: 0s - loss: 1.0820e-0 - 0s 130us/step - loss: 2.0877e-05 - val_loss: 0.0068\n",
      "\n",
      "Epoch 01402: val_loss did not improve from 0.00328\n",
      "Epoch 1403/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.9123e-05 - val_loss: 0.0063\n",
      "\n",
      "Epoch 01403: val_loss did not improve from 0.00328\n",
      "Epoch 1404/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.2768e-05 - val_loss: 0.0059\n",
      "\n",
      "Epoch 01404: val_loss did not improve from 0.00328\n",
      "Epoch 1405/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.6021e-05 - val_loss: 0.0062\n",
      "\n",
      "Epoch 01405: val_loss did not improve from 0.00328\n",
      "Epoch 1406/3000\n",
      "184/184 [==============================] - 0s 223us/step - loss: 1.9957e-05 - val_loss: 0.0065\n",
      "\n",
      "Epoch 01406: val_loss did not improve from 0.00328\n",
      "Epoch 1407/3000\n",
      "184/184 [==============================] - 0s 158us/step - loss: 2.4290e-05 - val_loss: 0.0063\n",
      "\n",
      "Epoch 01407: val_loss did not improve from 0.00328\n",
      "Epoch 1408/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 2.8781e-05 - val_loss: 0.0063\n",
      "\n",
      "Epoch 01408: val_loss did not improve from 0.00328\n",
      "Epoch 1409/3000\n",
      "184/184 [==============================] - 0s 128us/step - loss: 2.3180e-05 - val_loss: 0.0066\n",
      "\n",
      "Epoch 01409: val_loss did not improve from 0.00328\n",
      "Epoch 1410/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 1.7928e-05 - val_loss: 0.0070\n",
      "\n",
      "Epoch 01410: val_loss did not improve from 0.00328\n",
      "Epoch 1411/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.5196e-05 - val_loss: 0.0068\n",
      "\n",
      "Epoch 01411: val_loss did not improve from 0.00328\n",
      "Epoch 1412/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.2727e-05 - val_loss: 0.0064\n",
      "\n",
      "Epoch 01412: val_loss did not improve from 0.00328\n",
      "Epoch 1413/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.1288e-05 - val_loss: 0.0065\n",
      "\n",
      "Epoch 01413: val_loss did not improve from 0.00328\n",
      "Epoch 1414/3000\n",
      "184/184 [==============================] - 0s 93us/step - loss: 1.9650e-05 - val_loss: 0.0067\n",
      "\n",
      "Epoch 01414: val_loss did not improve from 0.00328\n",
      "Epoch 1415/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.2809e-05 - val_loss: 0.0068\n",
      "\n",
      "Epoch 01415: val_loss did not improve from 0.00328\n",
      "Epoch 1416/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 1.9080e-05 - val_loss: 0.0067\n",
      "\n",
      "Epoch 01416: val_loss did not improve from 0.00328\n",
      "Epoch 1417/3000\n",
      "184/184 [==============================] - 0s 93us/step - loss: 1.7849e-05 - val_loss: 0.0064\n",
      "\n",
      "Epoch 01417: val_loss did not improve from 0.00328\n",
      "Epoch 1418/3000\n",
      "184/184 [==============================] - 0s 119us/step - loss: 2.5324e-05 - val_loss: 0.0063\n",
      "\n",
      "Epoch 01418: val_loss did not improve from 0.00328\n",
      "Epoch 1419/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.2262e-05 - val_loss: 0.0065\n",
      "\n",
      "Epoch 01419: val_loss did not improve from 0.00328\n",
      "Epoch 1420/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.3035e-05 - val_loss: 0.0066\n",
      "\n",
      "Epoch 01420: val_loss did not improve from 0.00328\n",
      "Epoch 1421/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.0019e-05 - val_loss: 0.0066\n",
      "\n",
      "Epoch 01421: val_loss did not improve from 0.00328\n",
      "Epoch 1422/3000\n",
      "184/184 [==============================] - 0s 133us/step - loss: 2.6376e-05 - val_loss: 0.0066\n",
      "\n",
      "Epoch 01422: val_loss did not improve from 0.00328\n",
      "Epoch 1423/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 2.2361e-05 - val_loss: 0.0066\n",
      "\n",
      "Epoch 01423: val_loss did not improve from 0.00328\n",
      "Epoch 1424/3000\n",
      "184/184 [==============================] - 0s 147us/step - loss: 2.0369e-05 - val_loss: 0.0065\n",
      "\n",
      "Epoch 01424: val_loss did not improve from 0.00328\n",
      "Epoch 1425/3000\n",
      "184/184 [==============================] - 0s 179us/step - loss: 1.9884e-05 - val_loss: 0.0065\n",
      "\n",
      "Epoch 01425: val_loss did not improve from 0.00328\n",
      "Epoch 1426/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 114us/step - loss: 2.3492e-05 - val_loss: 0.0065\n",
      "\n",
      "Epoch 01426: val_loss did not improve from 0.00328\n",
      "Epoch 1427/3000\n",
      "184/184 [==============================] - 0s 207us/step - loss: 2.1812e-05 - val_loss: 0.0062\n",
      "\n",
      "Epoch 01427: val_loss did not improve from 0.00328\n",
      "Epoch 1428/3000\n",
      "184/184 [==============================] - 0s 180us/step - loss: 1.9773e-05 - val_loss: 0.0061\n",
      "\n",
      "Epoch 01428: val_loss did not improve from 0.00328\n",
      "Epoch 1429/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 2.1395e-05 - val_loss: 0.0060\n",
      "\n",
      "Epoch 01429: val_loss did not improve from 0.00328\n",
      "Epoch 1430/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.0630e-05 - val_loss: 0.0062\n",
      "\n",
      "Epoch 01430: val_loss did not improve from 0.00328\n",
      "Epoch 1431/3000\n",
      "184/184 [==============================] - 0s 163us/step - loss: 2.0753e-05 - val_loss: 0.0063\n",
      "\n",
      "Epoch 01431: val_loss did not improve from 0.00328\n",
      "Epoch 1432/3000\n",
      "184/184 [==============================] - 0s 174us/step - loss: 2.1252e-05 - val_loss: 0.0064\n",
      "\n",
      "Epoch 01432: val_loss did not improve from 0.00328\n",
      "Epoch 1433/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.7329e-05 - val_loss: 0.0066\n",
      "\n",
      "Epoch 01433: val_loss did not improve from 0.00328\n",
      "Epoch 1434/3000\n",
      "184/184 [==============================] - 0s 206us/step - loss: 2.2610e-05 - val_loss: 0.0065\n",
      "\n",
      "Epoch 01434: val_loss did not improve from 0.00328\n",
      "Epoch 1435/3000\n",
      "184/184 [==============================] - 0s 185us/step - loss: 2.4942e-05 - val_loss: 0.0066\n",
      "\n",
      "Epoch 01435: val_loss did not improve from 0.00328\n",
      "Epoch 1436/3000\n",
      "184/184 [==============================] - 0s 190us/step - loss: 2.2016e-05 - val_loss: 0.0068\n",
      "\n",
      "Epoch 01436: val_loss did not improve from 0.00328\n",
      "Epoch 1437/3000\n",
      "184/184 [==============================] - 0s 136us/step - loss: 3.0691e-05 - val_loss: 0.0068\n",
      "\n",
      "Epoch 01437: val_loss did not improve from 0.00328\n",
      "Epoch 1438/3000\n",
      "184/184 [==============================] - 0s 168us/step - loss: 1.9939e-05 - val_loss: 0.0065\n",
      "\n",
      "Epoch 01438: val_loss did not improve from 0.00328\n",
      "Epoch 1439/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.3581e-05 - val_loss: 0.0063\n",
      "\n",
      "Epoch 01439: val_loss did not improve from 0.00328\n",
      "Epoch 1440/3000\n",
      "184/184 [==============================] - 0s 120us/step - loss: 2.7539e-05 - val_loss: 0.0063\n",
      "\n",
      "Epoch 01440: val_loss did not improve from 0.00328\n",
      "Epoch 1441/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 1.9943e-05 - val_loss: 0.0065\n",
      "\n",
      "Epoch 01441: val_loss did not improve from 0.00328\n",
      "Epoch 1442/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 1.9343e-05 - val_loss: 0.0068\n",
      "\n",
      "Epoch 01442: val_loss did not improve from 0.00328\n",
      "Epoch 1443/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.1645e-05 - val_loss: 0.0068\n",
      "\n",
      "Epoch 01443: val_loss did not improve from 0.00328\n",
      "Epoch 1444/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.1231e-05 - val_loss: 0.0066\n",
      "\n",
      "Epoch 01444: val_loss did not improve from 0.00328\n",
      "Epoch 1445/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.3047e-05 - val_loss: 0.0065\n",
      "\n",
      "Epoch 01445: val_loss did not improve from 0.00328\n",
      "Epoch 1446/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.7136e-05 - val_loss: 0.0065\n",
      "\n",
      "Epoch 01446: val_loss did not improve from 0.00328\n",
      "Epoch 1447/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 1.9884e-05 - val_loss: 0.0065\n",
      "\n",
      "Epoch 01447: val_loss did not improve from 0.00328\n",
      "Epoch 1448/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.0243e-05 - val_loss: 0.0067\n",
      "\n",
      "Epoch 01448: val_loss did not improve from 0.00328\n",
      "Epoch 1449/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.2060e-05 - val_loss: 0.0067\n",
      "\n",
      "Epoch 01449: val_loss did not improve from 0.00328\n",
      "Epoch 1450/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 1.8297e-05 - val_loss: 0.0064\n",
      "\n",
      "Epoch 01450: val_loss did not improve from 0.00328\n",
      "Epoch 1451/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 1.9447e-05 - val_loss: 0.0064\n",
      "\n",
      "Epoch 01451: val_loss did not improve from 0.00328\n",
      "Epoch 1452/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.4727e-05 - val_loss: 0.0066\n",
      "\n",
      "Epoch 01452: val_loss did not improve from 0.00328\n",
      "Epoch 1453/3000\n",
      "184/184 [==============================] - 0s 119us/step - loss: 1.9325e-05 - val_loss: 0.0068\n",
      "\n",
      "Epoch 01453: val_loss did not improve from 0.00328\n",
      "Epoch 1454/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 1.6950e-05 - val_loss: 0.0067\n",
      "\n",
      "Epoch 01454: val_loss did not improve from 0.00328\n",
      "Epoch 1455/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 1.9677e-05 - val_loss: 0.0067\n",
      "\n",
      "Epoch 01455: val_loss did not improve from 0.00328\n",
      "Epoch 1456/3000\n",
      "184/184 [==============================] - 0s 168us/step - loss: 2.0578e-05 - val_loss: 0.0069\n",
      "\n",
      "Epoch 01456: val_loss did not improve from 0.00328\n",
      "Epoch 1457/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 1.7260e-05 - val_loss: 0.0068\n",
      "\n",
      "Epoch 01457: val_loss did not improve from 0.00328\n",
      "Epoch 1458/3000\n",
      "184/184 [==============================] - 0s 136us/step - loss: 1.9902e-05 - val_loss: 0.0068\n",
      "\n",
      "Epoch 01458: val_loss did not improve from 0.00328\n",
      "Epoch 1459/3000\n",
      "184/184 [==============================] - 0s 152us/step - loss: 2.5155e-05 - val_loss: 0.0066\n",
      "\n",
      "Epoch 01459: val_loss did not improve from 0.00328\n",
      "Epoch 1460/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.7985e-05 - val_loss: 0.0064\n",
      "\n",
      "Epoch 01460: val_loss did not improve from 0.00328\n",
      "Epoch 1461/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 1.9578e-05 - val_loss: 0.0066\n",
      "\n",
      "Epoch 01461: val_loss did not improve from 0.00328\n",
      "Epoch 1462/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 1.9048e-05 - val_loss: 0.0068\n",
      "\n",
      "Epoch 01462: val_loss did not improve from 0.00328\n",
      "Epoch 1463/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.3936e-05 - val_loss: 0.0067\n",
      "\n",
      "Epoch 01463: val_loss did not improve from 0.00328\n",
      "Epoch 1464/3000\n",
      "184/184 [==============================] - 0s 261us/step - loss: 3.0633e-05 - val_loss: 0.0067\n",
      "\n",
      "Epoch 01464: val_loss did not improve from 0.00328\n",
      "Epoch 1465/3000\n",
      "184/184 [==============================] - 0s 163us/step - loss: 2.1822e-05 - val_loss: 0.0068\n",
      "\n",
      "Epoch 01465: val_loss did not improve from 0.00328\n",
      "Epoch 1466/3000\n",
      "184/184 [==============================] - 0s 130us/step - loss: 2.2051e-05 - val_loss: 0.0069\n",
      "\n",
      "Epoch 01466: val_loss did not improve from 0.00328\n",
      "Epoch 1467/3000\n",
      "184/184 [==============================] - 0s 147us/step - loss: 1.9572e-05 - val_loss: 0.0069\n",
      "\n",
      "Epoch 01467: val_loss did not improve from 0.00328\n",
      "Epoch 1468/3000\n",
      "184/184 [==============================] - 0s 201us/step - loss: 2.7486e-05 - val_loss: 0.0067\n",
      "\n",
      "Epoch 01468: val_loss did not improve from 0.00328\n",
      "Epoch 1469/3000\n",
      "184/184 [==============================] - 0s 185us/step - loss: 2.6279e-05 - val_loss: 0.0067\n",
      "\n",
      "Epoch 01469: val_loss did not improve from 0.00328\n",
      "Epoch 1470/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 1.9206e-05 - val_loss: 0.0069\n",
      "\n",
      "Epoch 01470: val_loss did not improve from 0.00328\n",
      "Epoch 1471/3000\n",
      "184/184 [==============================] - 0s 158us/step - loss: 2.0853e-05 - val_loss: 0.0068\n",
      "\n",
      "Epoch 01471: val_loss did not improve from 0.00328\n",
      "Epoch 1472/3000\n",
      "184/184 [==============================] - 0s 120us/step - loss: 1.9179e-05 - val_loss: 0.0065\n",
      "\n",
      "Epoch 01472: val_loss did not improve from 0.00328\n",
      "Epoch 1473/3000\n",
      "184/184 [==============================] - 0s 130us/step - loss: 2.1112e-05 - val_loss: 0.0065\n",
      "\n",
      "Epoch 01473: val_loss did not improve from 0.00328\n",
      "Epoch 1474/3000\n",
      "184/184 [==============================] - 0s 136us/step - loss: 2.1765e-05 - val_loss: 0.0067\n",
      "\n",
      "Epoch 01474: val_loss did not improve from 0.00328\n",
      "Epoch 1475/3000\n",
      "184/184 [==============================] - 0s 130us/step - loss: 2.3578e-05 - val_loss: 0.0067\n",
      "\n",
      "Epoch 01475: val_loss did not improve from 0.00328\n",
      "Epoch 1476/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 141us/step - loss: 1.7705e-05 - val_loss: 0.0065\n",
      "\n",
      "Epoch 01476: val_loss did not improve from 0.00328\n",
      "Epoch 1477/3000\n",
      "184/184 [==============================] - 0s 119us/step - loss: 1.7622e-05 - val_loss: 0.0064\n",
      "\n",
      "Epoch 01477: val_loss did not improve from 0.00328\n",
      "Epoch 1478/3000\n",
      "184/184 [==============================] - 0s 130us/step - loss: 2.7047e-05 - val_loss: 0.0068\n",
      "\n",
      "Epoch 01478: val_loss did not improve from 0.00328\n",
      "Epoch 1479/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 1.9968e-05 - val_loss: 0.0069\n",
      "\n",
      "Epoch 01479: val_loss did not improve from 0.00328\n",
      "Epoch 1480/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.1006e-05 - val_loss: 0.0070\n",
      "\n",
      "Epoch 01480: val_loss did not improve from 0.00328\n",
      "Epoch 1481/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.4111e-05 - val_loss: 0.0072\n",
      "\n",
      "Epoch 01481: val_loss did not improve from 0.00328\n",
      "Epoch 1482/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.4151e-05 - val_loss: 0.0071\n",
      "\n",
      "Epoch 01482: val_loss did not improve from 0.00328\n",
      "Epoch 1483/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.0097e-05 - val_loss: 0.0068\n",
      "\n",
      "Epoch 01483: val_loss did not improve from 0.00328\n",
      "Epoch 1484/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.0581e-05 - val_loss: 0.0067\n",
      "\n",
      "Epoch 01484: val_loss did not improve from 0.00328\n",
      "Epoch 1485/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 1.8636e-05 - val_loss: 0.0069\n",
      "\n",
      "Epoch 01485: val_loss did not improve from 0.00328\n",
      "Epoch 1486/3000\n",
      "184/184 [==============================] - ETA: 0s - loss: 1.1633e-0 - 0s 104us/step - loss: 2.9068e-05 - val_loss: 0.0070\n",
      "\n",
      "Epoch 01486: val_loss did not improve from 0.00328\n",
      "Epoch 1487/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.3898e-05 - val_loss: 0.0067\n",
      "\n",
      "Epoch 01487: val_loss did not improve from 0.00328\n",
      "Epoch 1488/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.3327e-05 - val_loss: 0.0066\n",
      "\n",
      "Epoch 01488: val_loss did not improve from 0.00328\n",
      "Epoch 1489/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.0402e-05 - val_loss: 0.0066\n",
      "\n",
      "Epoch 01489: val_loss did not improve from 0.00328\n",
      "Epoch 1490/3000\n",
      "184/184 [==============================] - 0s 136us/step - loss: 2.3462e-05 - val_loss: 0.0066\n",
      "\n",
      "Epoch 01490: val_loss did not improve from 0.00328\n",
      "Epoch 1491/3000\n",
      "184/184 [==============================] - 0s 174us/step - loss: 2.4517e-05 - val_loss: 0.0069\n",
      "\n",
      "Epoch 01491: val_loss did not improve from 0.00328\n",
      "Epoch 1492/3000\n",
      "184/184 [==============================] - 0s 130us/step - loss: 1.9301e-05 - val_loss: 0.0070\n",
      "\n",
      "Epoch 01492: val_loss did not improve from 0.00328\n",
      "Epoch 1493/3000\n",
      "184/184 [==============================] - 0s 196us/step - loss: 1.9405e-05 - val_loss: 0.0069\n",
      "\n",
      "Epoch 01493: val_loss did not improve from 0.00328\n",
      "Epoch 1494/3000\n",
      "184/184 [==============================] - 0s 174us/step - loss: 2.0668e-05 - val_loss: 0.0071\n",
      "\n",
      "Epoch 01494: val_loss did not improve from 0.00328\n",
      "Epoch 1495/3000\n",
      "184/184 [==============================] - 0s 212us/step - loss: 2.4612e-05 - val_loss: 0.0074\n",
      "\n",
      "Epoch 01495: val_loss did not improve from 0.00328\n",
      "Epoch 1496/3000\n",
      "184/184 [==============================] - 0s 261us/step - loss: 2.2754e-05 - val_loss: 0.0072\n",
      "\n",
      "Epoch 01496: val_loss did not improve from 0.00328\n",
      "Epoch 1497/3000\n",
      "184/184 [==============================] - 0s 136us/step - loss: 2.0802e-05 - val_loss: 0.0071\n",
      "\n",
      "Epoch 01497: val_loss did not improve from 0.00328\n",
      "Epoch 1498/3000\n",
      "184/184 [==============================] - 0s 141us/step - loss: 2.2908e-05 - val_loss: 0.0072\n",
      "\n",
      "Epoch 01498: val_loss did not improve from 0.00328\n",
      "Epoch 1499/3000\n",
      "184/184 [==============================] - 0s 120us/step - loss: 2.1983e-05 - val_loss: 0.0072\n",
      "\n",
      "Epoch 01499: val_loss did not improve from 0.00328\n",
      "Epoch 1500/3000\n",
      "184/184 [==============================] - 0s 136us/step - loss: 2.2304e-05 - val_loss: 0.0069\n",
      "\n",
      "Epoch 01500: val_loss did not improve from 0.00328\n",
      "Epoch 1501/3000\n",
      "184/184 [==============================] - 0s 120us/step - loss: 1.9257e-05 - val_loss: 0.0066\n",
      "\n",
      "Epoch 01501: val_loss did not improve from 0.00328\n",
      "Epoch 1502/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.4811e-05 - val_loss: 0.0066\n",
      "\n",
      "Epoch 01502: val_loss did not improve from 0.00328\n",
      "Epoch 1503/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 1.9199e-05 - val_loss: 0.0066\n",
      "\n",
      "Epoch 01503: val_loss did not improve from 0.00328\n",
      "Epoch 1504/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.5056e-05 - val_loss: 0.0064\n",
      "\n",
      "Epoch 01504: val_loss did not improve from 0.00328\n",
      "Epoch 1505/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.0549e-05 - val_loss: 0.0065\n",
      "\n",
      "Epoch 01505: val_loss did not improve from 0.00328\n",
      "Epoch 1506/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.2385e-05 - val_loss: 0.0066\n",
      "\n",
      "Epoch 01506: val_loss did not improve from 0.00328\n",
      "Epoch 1507/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.2649e-05 - val_loss: 0.0065\n",
      "\n",
      "Epoch 01507: val_loss did not improve from 0.00328\n",
      "Epoch 1508/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.4865e-05 - val_loss: 0.0066\n",
      "\n",
      "Epoch 01508: val_loss did not improve from 0.00328\n",
      "Epoch 1509/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.0741e-05 - val_loss: 0.0070\n",
      "\n",
      "Epoch 01509: val_loss did not improve from 0.00328\n",
      "Epoch 1510/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.1129e-05 - val_loss: 0.0072\n",
      "\n",
      "Epoch 01510: val_loss did not improve from 0.00328\n",
      "Epoch 1511/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.7125e-05 - val_loss: 0.0071\n",
      "\n",
      "Epoch 01511: val_loss did not improve from 0.00328\n",
      "Epoch 1512/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 1.9316e-05 - val_loss: 0.0071\n",
      "\n",
      "Epoch 01512: val_loss did not improve from 0.00328\n",
      "Epoch 1513/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.3864e-05 - val_loss: 0.0071\n",
      "\n",
      "Epoch 01513: val_loss did not improve from 0.00328\n",
      "Epoch 1514/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.1712e-05 - val_loss: 0.0070\n",
      "\n",
      "Epoch 01514: val_loss did not improve from 0.00328\n",
      "Epoch 1515/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.4169e-05 - val_loss: 0.0072\n",
      "\n",
      "Epoch 01515: val_loss did not improve from 0.00328\n",
      "Epoch 1516/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.4079e-05 - val_loss: 0.0073\n",
      "\n",
      "Epoch 01516: val_loss did not improve from 0.00328\n",
      "Epoch 1517/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.3102e-05 - val_loss: 0.0070\n",
      "\n",
      "Epoch 01517: val_loss did not improve from 0.00328\n",
      "Epoch 1518/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.2701e-05 - val_loss: 0.0065\n",
      "\n",
      "Epoch 01518: val_loss did not improve from 0.00328\n",
      "Epoch 1519/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 3.1234e-05 - val_loss: 0.0066\n",
      "\n",
      "Epoch 01519: val_loss did not improve from 0.00328\n",
      "Epoch 1520/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.3009e-05 - val_loss: 0.0072\n",
      "\n",
      "Epoch 01520: val_loss did not improve from 0.00328\n",
      "Epoch 1521/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.3784e-05 - val_loss: 0.0075\n",
      "\n",
      "Epoch 01521: val_loss did not improve from 0.00328\n",
      "Epoch 1522/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.2604e-05 - val_loss: 0.0072\n",
      "\n",
      "Epoch 01522: val_loss did not improve from 0.00328\n",
      "Epoch 1523/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.3423e-05 - val_loss: 0.0068\n",
      "\n",
      "Epoch 01523: val_loss did not improve from 0.00328\n",
      "Epoch 1524/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.7919e-05 - val_loss: 0.0069\n",
      "\n",
      "Epoch 01524: val_loss did not improve from 0.00328\n",
      "Epoch 1525/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.3269e-05 - val_loss: 0.0073\n",
      "\n",
      "Epoch 01525: val_loss did not improve from 0.00328\n",
      "Epoch 1526/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 136us/step - loss: 2.1136e-05 - val_loss: 0.0074\n",
      "\n",
      "Epoch 01526: val_loss did not improve from 0.00328\n",
      "Epoch 1527/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 1.9182e-05 - val_loss: 0.0073\n",
      "\n",
      "Epoch 01527: val_loss did not improve from 0.00328\n",
      "Epoch 1528/3000\n",
      "184/184 [==============================] - 0s 120us/step - loss: 2.5673e-05 - val_loss: 0.0068\n",
      "\n",
      "Epoch 01528: val_loss did not improve from 0.00328\n",
      "Epoch 1529/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 2.6168e-05 - val_loss: 0.0064\n",
      "\n",
      "Epoch 01529: val_loss did not improve from 0.00328\n",
      "Epoch 1530/3000\n",
      "184/184 [==============================] - 0s 120us/step - loss: 2.9096e-05 - val_loss: 0.0068\n",
      "\n",
      "Epoch 01530: val_loss did not improve from 0.00328\n",
      "Epoch 1531/3000\n",
      "184/184 [==============================] - 0s 141us/step - loss: 2.3110e-05 - val_loss: 0.0071\n",
      "\n",
      "Epoch 01531: val_loss did not improve from 0.00328\n",
      "Epoch 1532/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.3731e-05 - val_loss: 0.0072\n",
      "\n",
      "Epoch 01532: val_loss did not improve from 0.00328\n",
      "Epoch 1533/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.3459e-05 - val_loss: 0.0073\n",
      "\n",
      "Epoch 01533: val_loss did not improve from 0.00328\n",
      "Epoch 1534/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.0478e-05 - val_loss: 0.0073\n",
      "\n",
      "Epoch 01534: val_loss did not improve from 0.00328\n",
      "Epoch 1535/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 1.9757e-05 - val_loss: 0.0072\n",
      "\n",
      "Epoch 01535: val_loss did not improve from 0.00328\n",
      "Epoch 1536/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.2301e-05 - val_loss: 0.0072\n",
      "\n",
      "Epoch 01536: val_loss did not improve from 0.00328\n",
      "Epoch 1537/3000\n",
      "184/184 [==============================] - 0s 158us/step - loss: 2.4632e-05 - val_loss: 0.0072\n",
      "\n",
      "Epoch 01537: val_loss did not improve from 0.00328\n",
      "Epoch 1538/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.5637e-05 - val_loss: 0.0073\n",
      "\n",
      "Epoch 01538: val_loss did not improve from 0.00328\n",
      "Epoch 1539/3000\n",
      "184/184 [==============================] - 0s 93us/step - loss: 2.1624e-05 - val_loss: 0.0071\n",
      "\n",
      "Epoch 01539: val_loss did not improve from 0.00328\n",
      "Epoch 1540/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.3015e-05 - val_loss: 0.0069\n",
      "\n",
      "Epoch 01540: val_loss did not improve from 0.00328\n",
      "Epoch 1541/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.1546e-05 - val_loss: 0.0070\n",
      "\n",
      "Epoch 01541: val_loss did not improve from 0.00328\n",
      "Epoch 1542/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 1.9057e-05 - val_loss: 0.0070\n",
      "\n",
      "Epoch 01542: val_loss did not improve from 0.00328\n",
      "Epoch 1543/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.0415e-05 - val_loss: 0.0070\n",
      "\n",
      "Epoch 01543: val_loss did not improve from 0.00328\n",
      "Epoch 1544/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.5845e-05 - val_loss: 0.0073\n",
      "\n",
      "Epoch 01544: val_loss did not improve from 0.00328\n",
      "Epoch 1545/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.0123e-05 - val_loss: 0.0074\n",
      "\n",
      "Epoch 01545: val_loss did not improve from 0.00328\n",
      "Epoch 1546/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.2490e-05 - val_loss: 0.0072\n",
      "\n",
      "Epoch 01546: val_loss did not improve from 0.00328\n",
      "Epoch 1547/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.9664e-05 - val_loss: 0.0071\n",
      "\n",
      "Epoch 01547: val_loss did not improve from 0.00328\n",
      "Epoch 1548/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.1328e-05 - val_loss: 0.0072\n",
      "\n",
      "Epoch 01548: val_loss did not improve from 0.00328\n",
      "Epoch 1549/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 1.9747e-05 - val_loss: 0.0072\n",
      "\n",
      "Epoch 01549: val_loss did not improve from 0.00328\n",
      "Epoch 1550/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.2886e-05 - val_loss: 0.0072\n",
      "\n",
      "Epoch 01550: val_loss did not improve from 0.00328\n",
      "Epoch 1551/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 1.9837e-05 - val_loss: 0.0074\n",
      "\n",
      "Epoch 01551: val_loss did not improve from 0.00328\n",
      "Epoch 1552/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.2996e-05 - val_loss: 0.0074\n",
      "\n",
      "Epoch 01552: val_loss did not improve from 0.00328\n",
      "Epoch 1553/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.6366e-05 - val_loss: 0.0075\n",
      "\n",
      "Epoch 01553: val_loss did not improve from 0.00328\n",
      "Epoch 1554/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 1.8340e-05 - val_loss: 0.0077\n",
      "\n",
      "Epoch 01554: val_loss did not improve from 0.00328\n",
      "Epoch 1555/3000\n",
      "184/184 [==============================] - 0s 93us/step - loss: 2.4987e-05 - val_loss: 0.0075\n",
      "\n",
      "Epoch 01555: val_loss did not improve from 0.00328\n",
      "Epoch 1556/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.4430e-05 - val_loss: 0.0072\n",
      "\n",
      "Epoch 01556: val_loss did not improve from 0.00328\n",
      "Epoch 1557/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.1935e-05 - val_loss: 0.0071\n",
      "\n",
      "Epoch 01557: val_loss did not improve from 0.00328\n",
      "Epoch 1558/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.1497e-05 - val_loss: 0.0069\n",
      "\n",
      "Epoch 01558: val_loss did not improve from 0.00328\n",
      "Epoch 1559/3000\n",
      "184/184 [==============================] - 0s 120us/step - loss: 2.0629e-05 - val_loss: 0.0070\n",
      "\n",
      "Epoch 01559: val_loss did not improve from 0.00328\n",
      "Epoch 1560/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.0422e-05 - val_loss: 0.0068\n",
      "\n",
      "Epoch 01560: val_loss did not improve from 0.00328\n",
      "Epoch 1561/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 1.8625e-05 - val_loss: 0.0068\n",
      "\n",
      "Epoch 01561: val_loss did not improve from 0.00328\n",
      "Epoch 1562/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.7947e-05 - val_loss: 0.0071\n",
      "\n",
      "Epoch 01562: val_loss did not improve from 0.00328\n",
      "Epoch 1563/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.0679e-05 - val_loss: 0.0071\n",
      "\n",
      "Epoch 01563: val_loss did not improve from 0.00328\n",
      "Epoch 1564/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.5184e-05 - val_loss: 0.0071\n",
      "\n",
      "Epoch 01564: val_loss did not improve from 0.00328\n",
      "Epoch 1565/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 1.8478e-05 - val_loss: 0.0074\n",
      "\n",
      "Epoch 01565: val_loss did not improve from 0.00328\n",
      "Epoch 1566/3000\n",
      "184/184 [==============================] - 0s 81us/step - loss: 2.1946e-05 - val_loss: 0.0075\n",
      "\n",
      "Epoch 01566: val_loss did not improve from 0.00328\n",
      "Epoch 1567/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 1.8796e-05 - val_loss: 0.0073\n",
      "\n",
      "Epoch 01567: val_loss did not improve from 0.00328\n",
      "Epoch 1568/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 1.8415e-05 - val_loss: 0.0071\n",
      "\n",
      "Epoch 01568: val_loss did not improve from 0.00328\n",
      "Epoch 1569/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 1.9630e-05 - val_loss: 0.0072\n",
      "\n",
      "Epoch 01569: val_loss did not improve from 0.00328\n",
      "Epoch 1570/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.0201e-05 - val_loss: 0.0074\n",
      "\n",
      "Epoch 01570: val_loss did not improve from 0.00328\n",
      "Epoch 1571/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.5431e-05 - val_loss: 0.0071\n",
      "\n",
      "Epoch 01571: val_loss did not improve from 0.00328\n",
      "Epoch 1572/3000\n",
      "184/184 [==============================] - 0s 82us/step - loss: 2.6644e-05 - val_loss: 0.0067\n",
      "\n",
      "Epoch 01572: val_loss did not improve from 0.00328\n",
      "Epoch 1573/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.9558e-05 - val_loss: 0.0067\n",
      "\n",
      "Epoch 01573: val_loss did not improve from 0.00328\n",
      "Epoch 1574/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.6467e-05 - val_loss: 0.0071\n",
      "\n",
      "Epoch 01574: val_loss did not improve from 0.00328\n",
      "Epoch 1575/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.1846e-05 - val_loss: 0.0070\n",
      "\n",
      "Epoch 01575: val_loss did not improve from 0.00328\n",
      "Epoch 1576/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 1.6973e-05 - val_loss: 0.0069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 01576: val_loss did not improve from 0.00328\n",
      "Epoch 1577/3000\n",
      "184/184 [==============================] - 0s 93us/step - loss: 2.3853e-05 - val_loss: 0.0071\n",
      "\n",
      "Epoch 01577: val_loss did not improve from 0.00328\n",
      "Epoch 1578/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.0701e-05 - val_loss: 0.0075\n",
      "\n",
      "Epoch 01578: val_loss did not improve from 0.00328\n",
      "Epoch 1579/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.4275e-05 - val_loss: 0.0073\n",
      "\n",
      "Epoch 01579: val_loss did not improve from 0.00328\n",
      "Epoch 1580/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.5782e-05 - val_loss: 0.0070\n",
      "\n",
      "Epoch 01580: val_loss did not improve from 0.00328\n",
      "Epoch 1581/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.0815e-05 - val_loss: 0.0072\n",
      "\n",
      "Epoch 01581: val_loss did not improve from 0.00328\n",
      "Epoch 1582/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.2836e-05 - val_loss: 0.0072\n",
      "\n",
      "Epoch 01582: val_loss did not improve from 0.00328\n",
      "Epoch 1583/3000\n",
      "184/184 [==============================] - 0s 104us/step - loss: 1.9953e-05 - val_loss: 0.0071\n",
      "\n",
      "Epoch 01583: val_loss did not improve from 0.00328\n",
      "Epoch 1584/3000\n",
      "184/184 [==============================] - 0s 147us/step - loss: 2.2167e-05 - val_loss: 0.0072\n",
      "\n",
      "Epoch 01584: val_loss did not improve from 0.00328\n",
      "Epoch 1585/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.8714e-05 - val_loss: 0.0073\n",
      "\n",
      "Epoch 01585: val_loss did not improve from 0.00328\n",
      "Epoch 1586/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.0345e-05 - val_loss: 0.0071\n",
      "\n",
      "Epoch 01586: val_loss did not improve from 0.00328\n",
      "Epoch 1587/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.1410e-05 - val_loss: 0.0071\n",
      "\n",
      "Epoch 01587: val_loss did not improve from 0.00328\n",
      "Epoch 1588/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.1644e-05 - val_loss: 0.0070\n",
      "\n",
      "Epoch 01588: val_loss did not improve from 0.00328\n",
      "Epoch 1589/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 1.9311e-05 - val_loss: 0.0069\n",
      "\n",
      "Epoch 01589: val_loss did not improve from 0.00328\n",
      "Epoch 1590/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.4285e-05 - val_loss: 0.0071\n",
      "\n",
      "Epoch 01590: val_loss did not improve from 0.00328\n",
      "Epoch 1591/3000\n",
      "184/184 [==============================] - 0s 104us/step - loss: 2.1561e-05 - val_loss: 0.0073\n",
      "\n",
      "Epoch 01591: val_loss did not improve from 0.00328\n",
      "Epoch 1592/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.2638e-05 - val_loss: 0.0071\n",
      "\n",
      "Epoch 01592: val_loss did not improve from 0.00328\n",
      "Epoch 1593/3000\n",
      "184/184 [==============================] - ETA: 0s - loss: 1.2672e-0 - 0s 98us/step - loss: 2.5460e-05 - val_loss: 0.0069\n",
      "\n",
      "Epoch 01593: val_loss did not improve from 0.00328\n",
      "Epoch 1594/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.1056e-05 - val_loss: 0.0070\n",
      "\n",
      "Epoch 01594: val_loss did not improve from 0.00328\n",
      "Epoch 1595/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.4699e-05 - val_loss: 0.0072\n",
      "\n",
      "Epoch 01595: val_loss did not improve from 0.00328\n",
      "Epoch 1596/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.8357e-05 - val_loss: 0.0070\n",
      "\n",
      "Epoch 01596: val_loss did not improve from 0.00328\n",
      "Epoch 1597/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.4069e-05 - val_loss: 0.0070\n",
      "\n",
      "Epoch 01597: val_loss did not improve from 0.00328\n",
      "Epoch 1598/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.3831e-05 - val_loss: 0.0069\n",
      "\n",
      "Epoch 01598: val_loss did not improve from 0.00328\n",
      "Epoch 1599/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.1331e-05 - val_loss: 0.0070\n",
      "\n",
      "Epoch 01599: val_loss did not improve from 0.00328\n",
      "Epoch 1600/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 3.2779e-05 - val_loss: 0.0071\n",
      "\n",
      "Epoch 01600: val_loss did not improve from 0.00328\n",
      "Epoch 1601/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 1.9050e-05 - val_loss: 0.0071\n",
      "\n",
      "Epoch 01601: val_loss did not improve from 0.00328\n",
      "Epoch 1602/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 1.9749e-05 - val_loss: 0.0070\n",
      "\n",
      "Epoch 01602: val_loss did not improve from 0.00328\n",
      "Epoch 1603/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 1.8459e-05 - val_loss: 0.0068\n",
      "\n",
      "Epoch 01603: val_loss did not improve from 0.00328\n",
      "Epoch 1604/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.1598e-05 - val_loss: 0.0070\n",
      "\n",
      "Epoch 01604: val_loss did not improve from 0.00328\n",
      "Epoch 1605/3000\n",
      "184/184 [==============================] - 0s 90us/step - loss: 2.5135e-05 - val_loss: 0.0075\n",
      "\n",
      "Epoch 01605: val_loss did not improve from 0.00328\n",
      "Epoch 1606/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.7794e-05 - val_loss: 0.0077\n",
      "\n",
      "Epoch 01606: val_loss did not improve from 0.00328\n",
      "Epoch 1607/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 2.7622e-05 - val_loss: 0.0075\n",
      "\n",
      "Epoch 01607: val_loss did not improve from 0.00328\n",
      "Epoch 1608/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.1200e-05 - val_loss: 0.0069\n",
      "\n",
      "Epoch 01608: val_loss did not improve from 0.00328\n",
      "Epoch 1609/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.7700e-05 - val_loss: 0.0068\n",
      "\n",
      "Epoch 01609: val_loss did not improve from 0.00328\n",
      "Epoch 1610/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.6531e-05 - val_loss: 0.0072\n",
      "\n",
      "Epoch 01610: val_loss did not improve from 0.00328\n",
      "Epoch 1611/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.3387e-05 - val_loss: 0.0073\n",
      "\n",
      "Epoch 01611: val_loss did not improve from 0.00328\n",
      "Epoch 1612/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.5895e-05 - val_loss: 0.0069\n",
      "\n",
      "Epoch 01612: val_loss did not improve from 0.00328\n",
      "Epoch 1613/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.8556e-05 - val_loss: 0.0067\n",
      "\n",
      "Epoch 01613: val_loss did not improve from 0.00328\n",
      "Epoch 1614/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 1.8149e-05 - val_loss: 0.0070\n",
      "\n",
      "Epoch 01614: val_loss did not improve from 0.00328\n",
      "Epoch 1615/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.0669e-05 - val_loss: 0.0070\n",
      "\n",
      "Epoch 01615: val_loss did not improve from 0.00328\n",
      "Epoch 1616/3000\n",
      "184/184 [==============================] - 0s 81us/step - loss: 2.2858e-05 - val_loss: 0.0069\n",
      "\n",
      "Epoch 01616: val_loss did not improve from 0.00328\n",
      "Epoch 1617/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.5661e-05 - val_loss: 0.0068\n",
      "\n",
      "Epoch 01617: val_loss did not improve from 0.00328\n",
      "Epoch 1618/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.2725e-05 - val_loss: 0.0070\n",
      "\n",
      "Epoch 01618: val_loss did not improve from 0.00328\n",
      "Epoch 1619/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.0337e-05 - val_loss: 0.0073\n",
      "\n",
      "Epoch 01619: val_loss did not improve from 0.00328\n",
      "Epoch 1620/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.6411e-05 - val_loss: 0.0072\n",
      "\n",
      "Epoch 01620: val_loss did not improve from 0.00328\n",
      "Epoch 1621/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.0872e-05 - val_loss: 0.0069\n",
      "\n",
      "Epoch 01621: val_loss did not improve from 0.00328\n",
      "Epoch 1622/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.2881e-05 - val_loss: 0.0072\n",
      "\n",
      "Epoch 01622: val_loss did not improve from 0.00328\n",
      "Epoch 1623/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.3507e-05 - val_loss: 0.0076\n",
      "\n",
      "Epoch 01623: val_loss did not improve from 0.00328\n",
      "Epoch 1624/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.2895e-05 - val_loss: 0.0075\n",
      "\n",
      "Epoch 01624: val_loss did not improve from 0.00328\n",
      "Epoch 1625/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.3058e-05 - val_loss: 0.0072\n",
      "\n",
      "Epoch 01625: val_loss did not improve from 0.00328\n",
      "Epoch 1626/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.1913e-05 - val_loss: 0.0071\n",
      "\n",
      "Epoch 01626: val_loss did not improve from 0.00328\n",
      "Epoch 1627/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 87us/step - loss: 2.4035e-05 - val_loss: 0.0071\n",
      "\n",
      "Epoch 01627: val_loss did not improve from 0.00328\n",
      "Epoch 1628/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.1584e-05 - val_loss: 0.0070\n",
      "\n",
      "Epoch 01628: val_loss did not improve from 0.00328\n",
      "Epoch 1629/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.2394e-05 - val_loss: 0.0069\n",
      "\n",
      "Epoch 01629: val_loss did not improve from 0.00328\n",
      "Epoch 1630/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.1577e-05 - val_loss: 0.0069\n",
      "\n",
      "Epoch 01630: val_loss did not improve from 0.00328\n",
      "Epoch 1631/3000\n",
      "184/184 [==============================] - 0s 120us/step - loss: 1.6882e-05 - val_loss: 0.0069\n",
      "\n",
      "Epoch 01631: val_loss did not improve from 0.00328\n",
      "Epoch 1632/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 1.9939e-05 - val_loss: 0.0069\n",
      "\n",
      "Epoch 01632: val_loss did not improve from 0.00328\n",
      "Epoch 1633/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 1.9874e-05 - val_loss: 0.0068\n",
      "\n",
      "Epoch 01633: val_loss did not improve from 0.00328\n",
      "Epoch 1634/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.0548e-05 - val_loss: 0.0069\n",
      "\n",
      "Epoch 01634: val_loss did not improve from 0.00328\n",
      "Epoch 1635/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 1.7405e-05 - val_loss: 0.0068\n",
      "\n",
      "Epoch 01635: val_loss did not improve from 0.00328\n",
      "Epoch 1636/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.1123e-05 - val_loss: 0.0068\n",
      "\n",
      "Epoch 01636: val_loss did not improve from 0.00328\n",
      "Epoch 1637/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 1.6747e-05 - val_loss: 0.0070\n",
      "\n",
      "Epoch 01637: val_loss did not improve from 0.00328\n",
      "Epoch 1638/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.1729e-05 - val_loss: 0.0072\n",
      "\n",
      "Epoch 01638: val_loss did not improve from 0.00328\n",
      "Epoch 1639/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.6750e-05 - val_loss: 0.0072\n",
      "\n",
      "Epoch 01639: val_loss did not improve from 0.00328\n",
      "Epoch 1640/3000\n",
      "184/184 [==============================] - 0s 174us/step - loss: 2.3105e-05 - val_loss: 0.0071\n",
      "\n",
      "Epoch 01640: val_loss did not improve from 0.00328\n",
      "Epoch 1641/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.7362e-05 - val_loss: 0.0071\n",
      "\n",
      "Epoch 01641: val_loss did not improve from 0.00328\n",
      "Epoch 1642/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.4760e-05 - val_loss: 0.0074\n",
      "\n",
      "Epoch 01642: val_loss did not improve from 0.00328\n",
      "Epoch 1643/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 1.9088e-05 - val_loss: 0.0076\n",
      "\n",
      "Epoch 01643: val_loss did not improve from 0.00328\n",
      "Epoch 1644/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 1.6998e-05 - val_loss: 0.0077\n",
      "\n",
      "Epoch 01644: val_loss did not improve from 0.00328\n",
      "Epoch 1645/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.1383e-05 - val_loss: 0.0075\n",
      "\n",
      "Epoch 01645: val_loss did not improve from 0.00328\n",
      "Epoch 1646/3000\n",
      "184/184 [==============================] - 0s 93us/step - loss: 2.7409e-05 - val_loss: 0.0071\n",
      "\n",
      "Epoch 01646: val_loss did not improve from 0.00328\n",
      "Epoch 1647/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.1944e-05 - val_loss: 0.0071\n",
      "\n",
      "Epoch 01647: val_loss did not improve from 0.00328\n",
      "Epoch 1648/3000\n",
      "184/184 [==============================] - 0s 120us/step - loss: 2.0038e-05 - val_loss: 0.0074\n",
      "\n",
      "Epoch 01648: val_loss did not improve from 0.00328\n",
      "Epoch 1649/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 1.9889e-05 - val_loss: 0.0076\n",
      "\n",
      "Epoch 01649: val_loss did not improve from 0.00328\n",
      "Epoch 1650/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.3695e-05 - val_loss: 0.0075\n",
      "\n",
      "Epoch 01650: val_loss did not improve from 0.00328\n",
      "Epoch 1651/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 1.8603e-05 - val_loss: 0.0073\n",
      "\n",
      "Epoch 01651: val_loss did not improve from 0.00328\n",
      "Epoch 1652/3000\n",
      "184/184 [==============================] - ETA: 0s - loss: 1.5246e-0 - 0s 125us/step - loss: 2.0426e-05 - val_loss: 0.0074\n",
      "\n",
      "Epoch 01652: val_loss did not improve from 0.00328\n",
      "Epoch 1653/3000\n",
      "184/184 [==============================] - 0s 120us/step - loss: 2.0912e-05 - val_loss: 0.0077\n",
      "\n",
      "Epoch 01653: val_loss did not improve from 0.00328\n",
      "Epoch 1654/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.0303e-05 - val_loss: 0.0073\n",
      "\n",
      "Epoch 01654: val_loss did not improve from 0.00328\n",
      "Epoch 1655/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 3.0065e-05 - val_loss: 0.0070\n",
      "\n",
      "Epoch 01655: val_loss did not improve from 0.00328\n",
      "Epoch 1656/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.3110e-05 - val_loss: 0.0072\n",
      "\n",
      "Epoch 01656: val_loss did not improve from 0.00328\n",
      "Epoch 1657/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.2372e-05 - val_loss: 0.0074\n",
      "\n",
      "Epoch 01657: val_loss did not improve from 0.00328\n",
      "Epoch 1658/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 1.9257e-05 - val_loss: 0.0072\n",
      "\n",
      "Epoch 01658: val_loss did not improve from 0.00328\n",
      "Epoch 1659/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.4630e-05 - val_loss: 0.0070\n",
      "\n",
      "Epoch 01659: val_loss did not improve from 0.00328\n",
      "Epoch 1660/3000\n",
      "184/184 [==============================] - 0s 84us/step - loss: 2.7026e-05 - val_loss: 0.0069\n",
      "\n",
      "Epoch 01660: val_loss did not improve from 0.00328\n",
      "Epoch 1661/3000\n",
      "184/184 [==============================] - ETA: 0s - loss: 1.2171e-0 - 0s 81us/step - loss: 2.0342e-05 - val_loss: 0.0071\n",
      "\n",
      "Epoch 01661: val_loss did not improve from 0.00328\n",
      "Epoch 1662/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.6133e-05 - val_loss: 0.0070\n",
      "\n",
      "Epoch 01662: val_loss did not improve from 0.00328\n",
      "Epoch 1663/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 1.9154e-05 - val_loss: 0.0070\n",
      "\n",
      "Epoch 01663: val_loss did not improve from 0.00328\n",
      "Epoch 1664/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 1.8512e-05 - val_loss: 0.0072\n",
      "\n",
      "Epoch 01664: val_loss did not improve from 0.00328\n",
      "Epoch 1665/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 1.9955e-05 - val_loss: 0.0074\n",
      "\n",
      "Epoch 01665: val_loss did not improve from 0.00328\n",
      "Epoch 1666/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.0288e-05 - val_loss: 0.0074\n",
      "\n",
      "Epoch 01666: val_loss did not improve from 0.00328\n",
      "Epoch 1667/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.2673e-05 - val_loss: 0.0074\n",
      "\n",
      "Epoch 01667: val_loss did not improve from 0.00328\n",
      "Epoch 1668/3000\n",
      "184/184 [==============================] - 0s 81us/step - loss: 1.7782e-05 - val_loss: 0.0074\n",
      "\n",
      "Epoch 01668: val_loss did not improve from 0.00328\n",
      "Epoch 1669/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.1633e-05 - val_loss: 0.0076\n",
      "\n",
      "Epoch 01669: val_loss did not improve from 0.00328\n",
      "Epoch 1670/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.1097e-05 - val_loss: 0.0076\n",
      "\n",
      "Epoch 01670: val_loss did not improve from 0.00328\n",
      "Epoch 1671/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.2761e-05 - val_loss: 0.0075\n",
      "\n",
      "Epoch 01671: val_loss did not improve from 0.00328\n",
      "Epoch 1672/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.5525e-05 - val_loss: 0.0075\n",
      "\n",
      "Epoch 01672: val_loss did not improve from 0.00328\n",
      "Epoch 1673/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.0073e-05 - val_loss: 0.0077\n",
      "\n",
      "Epoch 01673: val_loss did not improve from 0.00328\n",
      "Epoch 1674/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.1682e-05 - val_loss: 0.0077\n",
      "\n",
      "Epoch 01674: val_loss did not improve from 0.00328\n",
      "Epoch 1675/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.4653e-05 - val_loss: 0.0075\n",
      "\n",
      "Epoch 01675: val_loss did not improve from 0.00328\n",
      "Epoch 1676/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.2522e-05 - val_loss: 0.0072\n",
      "\n",
      "Epoch 01676: val_loss did not improve from 0.00328\n",
      "Epoch 1677/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 103us/step - loss: 1.8871e-05 - val_loss: 0.0074\n",
      "\n",
      "Epoch 01677: val_loss did not improve from 0.00328\n",
      "Epoch 1678/3000\n",
      "184/184 [==============================] - 0s 152us/step - loss: 2.4111e-05 - val_loss: 0.0076\n",
      "\n",
      "Epoch 01678: val_loss did not improve from 0.00328\n",
      "Epoch 1679/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 1.9955e-05 - val_loss: 0.0077\n",
      "\n",
      "Epoch 01679: val_loss did not improve from 0.00328\n",
      "Epoch 1680/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.1088e-05 - val_loss: 0.0075\n",
      "\n",
      "Epoch 01680: val_loss did not improve from 0.00328\n",
      "Epoch 1681/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.2508e-05 - val_loss: 0.0074\n",
      "\n",
      "Epoch 01681: val_loss did not improve from 0.00328\n",
      "Epoch 1682/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.4688e-05 - val_loss: 0.0073\n",
      "\n",
      "Epoch 01682: val_loss did not improve from 0.00328\n",
      "Epoch 1683/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.2264e-05 - val_loss: 0.0072\n",
      "\n",
      "Epoch 01683: val_loss did not improve from 0.00328\n",
      "Epoch 1684/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 1.9849e-05 - val_loss: 0.0072\n",
      "\n",
      "Epoch 01684: val_loss did not improve from 0.00328\n",
      "Epoch 1685/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.7396e-05 - val_loss: 0.0069\n",
      "\n",
      "Epoch 01685: val_loss did not improve from 0.00328\n",
      "Epoch 1686/3000\n",
      "184/184 [==============================] - 0s 91us/step - loss: 1.6660e-05 - val_loss: 0.0068\n",
      "\n",
      "Epoch 01686: val_loss did not improve from 0.00328\n",
      "Epoch 1687/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.5966e-05 - val_loss: 0.0069\n",
      "\n",
      "Epoch 01687: val_loss did not improve from 0.00328\n",
      "Epoch 1688/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.0658e-05 - val_loss: 0.0071\n",
      "\n",
      "Epoch 01688: val_loss did not improve from 0.00328\n",
      "Epoch 1689/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.3670e-05 - val_loss: 0.0074\n",
      "\n",
      "Epoch 01689: val_loss did not improve from 0.00328\n",
      "Epoch 1690/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.6883e-05 - val_loss: 0.0075\n",
      "\n",
      "Epoch 01690: val_loss did not improve from 0.00328\n",
      "Epoch 1691/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.7478e-05 - val_loss: 0.0073\n",
      "\n",
      "Epoch 01691: val_loss did not improve from 0.00328\n",
      "Epoch 1692/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 1.9856e-05 - val_loss: 0.0072\n",
      "\n",
      "Epoch 01692: val_loss did not improve from 0.00328\n",
      "Epoch 1693/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.4842e-05 - val_loss: 0.0075\n",
      "\n",
      "Epoch 01693: val_loss did not improve from 0.00328\n",
      "Epoch 1694/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.3220e-05 - val_loss: 0.0079\n",
      "\n",
      "Epoch 01694: val_loss did not improve from 0.00328\n",
      "Epoch 1695/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 1.9980e-05 - val_loss: 0.0079\n",
      "\n",
      "Epoch 01695: val_loss did not improve from 0.00328\n",
      "Epoch 1696/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.1587e-05 - val_loss: 0.0075\n",
      "\n",
      "Epoch 01696: val_loss did not improve from 0.00328\n",
      "Epoch 1697/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.0695e-05 - val_loss: 0.0075\n",
      "\n",
      "Epoch 01697: val_loss did not improve from 0.00328\n",
      "Epoch 1698/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.3156e-05 - val_loss: 0.0079\n",
      "\n",
      "Epoch 01698: val_loss did not improve from 0.00328\n",
      "Epoch 1699/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.7243e-05 - val_loss: 0.0078\n",
      "\n",
      "Epoch 01699: val_loss did not improve from 0.00328\n",
      "Epoch 1700/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 1.7753e-05 - val_loss: 0.0074\n",
      "\n",
      "Epoch 01700: val_loss did not improve from 0.00328\n",
      "Epoch 1701/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.5924e-05 - val_loss: 0.0073\n",
      "\n",
      "Epoch 01701: val_loss did not improve from 0.00328\n",
      "Epoch 1702/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 3.0420e-05 - val_loss: 0.0075\n",
      "\n",
      "Epoch 01702: val_loss did not improve from 0.00328\n",
      "Epoch 1703/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.3720e-05 - val_loss: 0.0074\n",
      "\n",
      "Epoch 01703: val_loss did not improve from 0.00328\n",
      "Epoch 1704/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.2380e-05 - val_loss: 0.0073\n",
      "\n",
      "Epoch 01704: val_loss did not improve from 0.00328\n",
      "Epoch 1705/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 1.5172e-05 - val_loss: 0.0074\n",
      "\n",
      "Epoch 01705: val_loss did not improve from 0.00328\n",
      "Epoch 1706/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.2494e-05 - val_loss: 0.0073\n",
      "\n",
      "Epoch 01706: val_loss did not improve from 0.00328\n",
      "Epoch 1707/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.0226e-05 - val_loss: 0.0072\n",
      "\n",
      "Epoch 01707: val_loss did not improve from 0.00328\n",
      "Epoch 1708/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.0342e-05 - val_loss: 0.0073\n",
      "\n",
      "Epoch 01708: val_loss did not improve from 0.00328\n",
      "Epoch 1709/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.1029e-05 - val_loss: 0.0076\n",
      "\n",
      "Epoch 01709: val_loss did not improve from 0.00328\n",
      "Epoch 1710/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 1.6937e-05 - val_loss: 0.0077\n",
      "\n",
      "Epoch 01710: val_loss did not improve from 0.00328\n",
      "Epoch 1711/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.2317e-05 - val_loss: 0.0077\n",
      "\n",
      "Epoch 01711: val_loss did not improve from 0.00328\n",
      "Epoch 1712/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.2296e-05 - val_loss: 0.0076\n",
      "\n",
      "Epoch 01712: val_loss did not improve from 0.00328\n",
      "Epoch 1713/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.6544e-05 - val_loss: 0.0075\n",
      "\n",
      "Epoch 01713: val_loss did not improve from 0.00328\n",
      "Epoch 1714/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.1290e-05 - val_loss: 0.0074\n",
      "\n",
      "Epoch 01714: val_loss did not improve from 0.00328\n",
      "Epoch 1715/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 1.9090e-05 - val_loss: 0.0075\n",
      "\n",
      "Epoch 01715: val_loss did not improve from 0.00328\n",
      "Epoch 1716/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.5414e-05 - val_loss: 0.0073\n",
      "\n",
      "Epoch 01716: val_loss did not improve from 0.00328\n",
      "Epoch 1717/3000\n",
      "184/184 [==============================] - 0s 136us/step - loss: 2.5613e-05 - val_loss: 0.0071\n",
      "\n",
      "Epoch 01717: val_loss did not improve from 0.00328\n",
      "Epoch 1718/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.0440e-05 - val_loss: 0.0072\n",
      "\n",
      "Epoch 01718: val_loss did not improve from 0.00328\n",
      "Epoch 1719/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.4585e-05 - val_loss: 0.0075\n",
      "\n",
      "Epoch 01719: val_loss did not improve from 0.00328\n",
      "Epoch 1720/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.7091e-05 - val_loss: 0.0076\n",
      "\n",
      "Epoch 01720: val_loss did not improve from 0.00328\n",
      "Epoch 1721/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.2799e-05 - val_loss: 0.0073\n",
      "\n",
      "Epoch 01721: val_loss did not improve from 0.00328\n",
      "Epoch 1722/3000\n",
      "184/184 [==============================] - 0s 81us/step - loss: 2.3408e-05 - val_loss: 0.0073\n",
      "\n",
      "Epoch 01722: val_loss did not improve from 0.00328\n",
      "Epoch 1723/3000\n",
      "184/184 [==============================] - 0s 76us/step - loss: 2.0804e-05 - val_loss: 0.0079\n",
      "\n",
      "Epoch 01723: val_loss did not improve from 0.00328\n",
      "Epoch 1724/3000\n",
      "184/184 [==============================] - ETA: 0s - loss: 1.2278e-0 - 0s 81us/step - loss: 2.3713e-05 - val_loss: 0.0083\n",
      "\n",
      "Epoch 01724: val_loss did not improve from 0.00328\n",
      "Epoch 1725/3000\n",
      "184/184 [==============================] - 0s 81us/step - loss: 2.0132e-05 - val_loss: 0.0081\n",
      "\n",
      "Epoch 01725: val_loss did not improve from 0.00328\n",
      "Epoch 1726/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 1.7804e-05 - val_loss: 0.0076\n",
      "\n",
      "Epoch 01726: val_loss did not improve from 0.00328\n",
      "Epoch 1727/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 119us/step - loss: 2.6767e-05 - val_loss: 0.0077\n",
      "\n",
      "Epoch 01727: val_loss did not improve from 0.00328\n",
      "Epoch 1728/3000\n",
      "184/184 [==============================] - ETA: 0s - loss: 1.4485e-0 - 0s 87us/step - loss: 2.3023e-05 - val_loss: 0.0081\n",
      "\n",
      "Epoch 01728: val_loss did not improve from 0.00328\n",
      "Epoch 1729/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.4214e-05 - val_loss: 0.0080\n",
      "\n",
      "Epoch 01729: val_loss did not improve from 0.00328\n",
      "Epoch 1730/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.3342e-05 - val_loss: 0.0075\n",
      "\n",
      "Epoch 01730: val_loss did not improve from 0.00328\n",
      "Epoch 1731/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.5124e-05 - val_loss: 0.0076\n",
      "\n",
      "Epoch 01731: val_loss did not improve from 0.00328\n",
      "Epoch 1732/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.6693e-05 - val_loss: 0.0080\n",
      "\n",
      "Epoch 01732: val_loss did not improve from 0.00328\n",
      "Epoch 1733/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.4415e-05 - val_loss: 0.0079\n",
      "\n",
      "Epoch 01733: val_loss did not improve from 0.00328\n",
      "Epoch 1734/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.4866e-05 - val_loss: 0.0077\n",
      "\n",
      "Epoch 01734: val_loss did not improve from 0.00328\n",
      "Epoch 1735/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.0714e-05 - val_loss: 0.0073\n",
      "\n",
      "Epoch 01735: val_loss did not improve from 0.00328\n",
      "Epoch 1736/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 3.1682e-05 - val_loss: 0.0072\n",
      "\n",
      "Epoch 01736: val_loss did not improve from 0.00328\n",
      "Epoch 1737/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.3800e-05 - val_loss: 0.0074\n",
      "\n",
      "Epoch 01737: val_loss did not improve from 0.00328\n",
      "Epoch 1738/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.1280e-05 - val_loss: 0.0076\n",
      "\n",
      "Epoch 01738: val_loss did not improve from 0.00328\n",
      "Epoch 1739/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.4184e-05 - val_loss: 0.0076\n",
      "\n",
      "Epoch 01739: val_loss did not improve from 0.00328\n",
      "Epoch 1740/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 1.9740e-05 - val_loss: 0.0075\n",
      "\n",
      "Epoch 01740: val_loss did not improve from 0.00328\n",
      "Epoch 1741/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.0593e-05 - val_loss: 0.0072\n",
      "\n",
      "Epoch 01741: val_loss did not improve from 0.00328\n",
      "Epoch 1742/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.4664e-05 - val_loss: 0.0073\n",
      "\n",
      "Epoch 01742: val_loss did not improve from 0.00328\n",
      "Epoch 1743/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.1858e-05 - val_loss: 0.0079\n",
      "\n",
      "Epoch 01743: val_loss did not improve from 0.00328\n",
      "Epoch 1744/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.6646e-05 - val_loss: 0.0080\n",
      "\n",
      "Epoch 01744: val_loss did not improve from 0.00328\n",
      "Epoch 1745/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 1.9590e-05 - val_loss: 0.0078\n",
      "\n",
      "Epoch 01745: val_loss did not improve from 0.00328\n",
      "Epoch 1746/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.1495e-05 - val_loss: 0.0079\n",
      "\n",
      "Epoch 01746: val_loss did not improve from 0.00328\n",
      "Epoch 1747/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 1.9685e-05 - val_loss: 0.0080\n",
      "\n",
      "Epoch 01747: val_loss did not improve from 0.00328\n",
      "Epoch 1748/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 1.7924e-05 - val_loss: 0.0080\n",
      "\n",
      "Epoch 01748: val_loss did not improve from 0.00328\n",
      "Epoch 1749/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 1.8556e-05 - val_loss: 0.0079\n",
      "\n",
      "Epoch 01749: val_loss did not improve from 0.00328\n",
      "Epoch 1750/3000\n",
      "184/184 [==============================] - ETA: 0s - loss: 1.3834e-0 - 0s 109us/step - loss: 1.7331e-05 - val_loss: 0.0078\n",
      "\n",
      "Epoch 01750: val_loss did not improve from 0.00328\n",
      "Epoch 1751/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 1.9984e-05 - val_loss: 0.0078\n",
      "\n",
      "Epoch 01751: val_loss did not improve from 0.00328\n",
      "Epoch 1752/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.6894e-05 - val_loss: 0.0077\n",
      "\n",
      "Epoch 01752: val_loss did not improve from 0.00328\n",
      "Epoch 1753/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.2686e-05 - val_loss: 0.0074\n",
      "\n",
      "Epoch 01753: val_loss did not improve from 0.00328\n",
      "Epoch 1754/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 1.8314e-05 - val_loss: 0.0074\n",
      "\n",
      "Epoch 01754: val_loss did not improve from 0.00328\n",
      "Epoch 1755/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.1830e-05 - val_loss: 0.0076\n",
      "\n",
      "Epoch 01755: val_loss did not improve from 0.00328\n",
      "Epoch 1756/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 1.9148e-05 - val_loss: 0.0076\n",
      "\n",
      "Epoch 01756: val_loss did not improve from 0.00328\n",
      "Epoch 1757/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.1607e-05 - val_loss: 0.0078\n",
      "\n",
      "Epoch 01757: val_loss did not improve from 0.00328\n",
      "Epoch 1758/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.3775e-05 - val_loss: 0.0078\n",
      "\n",
      "Epoch 01758: val_loss did not improve from 0.00328\n",
      "Epoch 1759/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.3376e-05 - val_loss: 0.0074\n",
      "\n",
      "Epoch 01759: val_loss did not improve from 0.00328\n",
      "Epoch 1760/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.5868e-05 - val_loss: 0.0073\n",
      "\n",
      "Epoch 01760: val_loss did not improve from 0.00328\n",
      "Epoch 1761/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.4751e-05 - val_loss: 0.0076\n",
      "\n",
      "Epoch 01761: val_loss did not improve from 0.00328\n",
      "Epoch 1762/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.1972e-05 - val_loss: 0.0078\n",
      "\n",
      "Epoch 01762: val_loss did not improve from 0.00328\n",
      "Epoch 1763/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.7642e-05 - val_loss: 0.0080\n",
      "\n",
      "Epoch 01763: val_loss did not improve from 0.00328\n",
      "Epoch 1764/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 3.1939e-05 - val_loss: 0.0077\n",
      "\n",
      "Epoch 01764: val_loss did not improve from 0.00328\n",
      "Epoch 1765/3000\n",
      "184/184 [==============================] - 0s 93us/step - loss: 2.2348e-05 - val_loss: 0.0077\n",
      "\n",
      "Epoch 01765: val_loss did not improve from 0.00328\n",
      "Epoch 1766/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 1.9626e-05 - val_loss: 0.0079\n",
      "\n",
      "Epoch 01766: val_loss did not improve from 0.00328\n",
      "Epoch 1767/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.3336e-05 - val_loss: 0.0080\n",
      "\n",
      "Epoch 01767: val_loss did not improve from 0.00328\n",
      "Epoch 1768/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.1030e-05 - val_loss: 0.0079\n",
      "\n",
      "Epoch 01768: val_loss did not improve from 0.00328\n",
      "Epoch 1769/3000\n",
      "184/184 [==============================] - 0s 255us/step - loss: 2.1038e-05 - val_loss: 0.0079\n",
      "\n",
      "Epoch 01769: val_loss did not improve from 0.00328\n",
      "Epoch 1770/3000\n",
      "184/184 [==============================] - 0s 430us/step - loss: 2.0927e-05 - val_loss: 0.0080\n",
      "\n",
      "Epoch 01770: val_loss did not improve from 0.00328\n",
      "Epoch 1771/3000\n",
      "184/184 [==============================] - 0s 152us/step - loss: 2.4775e-05 - val_loss: 0.0082\n",
      "\n",
      "Epoch 01771: val_loss did not improve from 0.00328\n",
      "Epoch 1772/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.1170e-05 - val_loss: 0.0081\n",
      "\n",
      "Epoch 01772: val_loss did not improve from 0.00328\n",
      "Epoch 1773/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.2708e-05 - val_loss: 0.0080\n",
      "\n",
      "Epoch 01773: val_loss did not improve from 0.00328\n",
      "Epoch 1774/3000\n",
      "184/184 [==============================] - ETA: 0s - loss: 1.2881e-0 - 0s 130us/step - loss: 2.3011e-05 - val_loss: 0.0080\n",
      "\n",
      "Epoch 01774: val_loss did not improve from 0.00328\n",
      "Epoch 1775/3000\n",
      "184/184 [==============================] - 0s 120us/step - loss: 2.4153e-05 - val_loss: 0.0078\n",
      "\n",
      "Epoch 01775: val_loss did not improve from 0.00328\n",
      "Epoch 1776/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.5767e-05 - val_loss: 0.0078\n",
      "\n",
      "Epoch 01776: val_loss did not improve from 0.00328\n",
      "Epoch 1777/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 109us/step - loss: 2.0120e-05 - val_loss: 0.0080\n",
      "\n",
      "Epoch 01777: val_loss did not improve from 0.00328\n",
      "Epoch 1778/3000\n",
      "184/184 [==============================] - 0s 141us/step - loss: 2.9729e-05 - val_loss: 0.0076\n",
      "\n",
      "Epoch 01778: val_loss did not improve from 0.00328\n",
      "Epoch 1779/3000\n",
      "184/184 [==============================] - 0s 119us/step - loss: 2.1644e-05 - val_loss: 0.0073\n",
      "\n",
      "Epoch 01779: val_loss did not improve from 0.00328\n",
      "Epoch 1780/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 2.0887e-05 - val_loss: 0.0076\n",
      "\n",
      "Epoch 01780: val_loss did not improve from 0.00328\n",
      "Epoch 1781/3000\n",
      "184/184 [==============================] - 0s 136us/step - loss: 2.1754e-05 - val_loss: 0.0077\n",
      "\n",
      "Epoch 01781: val_loss did not improve from 0.00328\n",
      "Epoch 1782/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 2.3397e-05 - val_loss: 0.0077\n",
      "\n",
      "Epoch 01782: val_loss did not improve from 0.00328\n",
      "Epoch 1783/3000\n",
      "184/184 [==============================] - 0s 120us/step - loss: 2.1355e-05 - val_loss: 0.0081\n",
      "\n",
      "Epoch 01783: val_loss did not improve from 0.00328\n",
      "Epoch 1784/3000\n",
      "184/184 [==============================] - 0s 130us/step - loss: 2.2099e-05 - val_loss: 0.0082\n",
      "\n",
      "Epoch 01784: val_loss did not improve from 0.00328\n",
      "Epoch 1785/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 2.5659e-05 - val_loss: 0.0081\n",
      "\n",
      "Epoch 01785: val_loss did not improve from 0.00328\n",
      "Epoch 1786/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.7089e-05 - val_loss: 0.0083\n",
      "\n",
      "Epoch 01786: val_loss did not improve from 0.00328\n",
      "Epoch 1787/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.3029e-05 - val_loss: 0.0084\n",
      "\n",
      "Epoch 01787: val_loss did not improve from 0.00328\n",
      "Epoch 1788/3000\n",
      "184/184 [==============================] - 0s 120us/step - loss: 2.3301e-05 - val_loss: 0.0080\n",
      "\n",
      "Epoch 01788: val_loss did not improve from 0.00328\n",
      "Epoch 1789/3000\n",
      "184/184 [==============================] - 0s 120us/step - loss: 2.0506e-05 - val_loss: 0.0079\n",
      "\n",
      "Epoch 01789: val_loss did not improve from 0.00328\n",
      "Epoch 1790/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.0321e-05 - val_loss: 0.0082\n",
      "\n",
      "Epoch 01790: val_loss did not improve from 0.00328\n",
      "Epoch 1791/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.0487e-05 - val_loss: 0.0080\n",
      "\n",
      "Epoch 01791: val_loss did not improve from 0.00328\n",
      "Epoch 1792/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.5350e-05 - val_loss: 0.0077\n",
      "\n",
      "Epoch 01792: val_loss did not improve from 0.00328\n",
      "Epoch 1793/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.6753e-05 - val_loss: 0.0077\n",
      "\n",
      "Epoch 01793: val_loss did not improve from 0.00328\n",
      "Epoch 1794/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 1.9448e-05 - val_loss: 0.0076\n",
      "\n",
      "Epoch 01794: val_loss did not improve from 0.00328\n",
      "Epoch 1795/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 1.5495e-05 - val_loss: 0.0077\n",
      "\n",
      "Epoch 01795: val_loss did not improve from 0.00328\n",
      "Epoch 1796/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.5205e-05 - val_loss: 0.0078\n",
      "\n",
      "Epoch 01796: val_loss did not improve from 0.00328\n",
      "Epoch 1797/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.2099e-05 - val_loss: 0.0079\n",
      "\n",
      "Epoch 01797: val_loss did not improve from 0.00328\n",
      "Epoch 1798/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 1.8914e-05 - val_loss: 0.0078\n",
      "\n",
      "Epoch 01798: val_loss did not improve from 0.00328\n",
      "Epoch 1799/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.3884e-05 - val_loss: 0.0077\n",
      "\n",
      "Epoch 01799: val_loss did not improve from 0.00328\n",
      "Epoch 1800/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.7290e-05 - val_loss: 0.0075\n",
      "\n",
      "Epoch 01800: val_loss did not improve from 0.00328\n",
      "Epoch 1801/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.4932e-05 - val_loss: 0.0079\n",
      "\n",
      "Epoch 01801: val_loss did not improve from 0.00328\n",
      "Epoch 1802/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.1817e-05 - val_loss: 0.0082\n",
      "\n",
      "Epoch 01802: val_loss did not improve from 0.00328\n",
      "Epoch 1803/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 1.8673e-05 - val_loss: 0.0080\n",
      "\n",
      "Epoch 01803: val_loss did not improve from 0.00328\n",
      "Epoch 1804/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.4824e-05 - val_loss: 0.0078\n",
      "\n",
      "Epoch 01804: val_loss did not improve from 0.00328\n",
      "Epoch 1805/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.3102e-05 - val_loss: 0.0081\n",
      "\n",
      "Epoch 01805: val_loss did not improve from 0.00328\n",
      "Epoch 1806/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.1270e-05 - val_loss: 0.0084\n",
      "\n",
      "Epoch 01806: val_loss did not improve from 0.00328\n",
      "Epoch 1807/3000\n",
      "184/184 [==============================] - 0s 104us/step - loss: 2.1920e-05 - val_loss: 0.0082\n",
      "\n",
      "Epoch 01807: val_loss did not improve from 0.00328\n",
      "Epoch 1808/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.1555e-05 - val_loss: 0.0081\n",
      "\n",
      "Epoch 01808: val_loss did not improve from 0.00328\n",
      "Epoch 1809/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.1248e-05 - val_loss: 0.0083\n",
      "\n",
      "Epoch 01809: val_loss did not improve from 0.00328\n",
      "Epoch 1810/3000\n",
      "184/184 [==============================] - 0s 120us/step - loss: 2.1032e-05 - val_loss: 0.0081\n",
      "\n",
      "Epoch 01810: val_loss did not improve from 0.00328\n",
      "Epoch 1811/3000\n",
      "184/184 [==============================] - 0s 158us/step - loss: 2.2611e-05 - val_loss: 0.0077\n",
      "\n",
      "Epoch 01811: val_loss did not improve from 0.00328\n",
      "Epoch 1812/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.8391e-05 - val_loss: 0.0076\n",
      "\n",
      "Epoch 01812: val_loss did not improve from 0.00328\n",
      "Epoch 1813/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.1774e-05 - val_loss: 0.0077\n",
      "\n",
      "Epoch 01813: val_loss did not improve from 0.00328\n",
      "Epoch 1814/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.4311e-05 - val_loss: 0.0078\n",
      "\n",
      "Epoch 01814: val_loss did not improve from 0.00328\n",
      "Epoch 1815/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.1648e-05 - val_loss: 0.0080\n",
      "\n",
      "Epoch 01815: val_loss did not improve from 0.00328\n",
      "Epoch 1816/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.3913e-05 - val_loss: 0.0079\n",
      "\n",
      "Epoch 01816: val_loss did not improve from 0.00328\n",
      "Epoch 1817/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.6482e-05 - val_loss: 0.0078\n",
      "\n",
      "Epoch 01817: val_loss did not improve from 0.00328\n",
      "Epoch 1818/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.3958e-05 - val_loss: 0.0080\n",
      "\n",
      "Epoch 01818: val_loss did not improve from 0.00328\n",
      "Epoch 1819/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.1043e-05 - val_loss: 0.0080\n",
      "\n",
      "Epoch 01819: val_loss did not improve from 0.00328\n",
      "Epoch 1820/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.3099e-05 - val_loss: 0.0076\n",
      "\n",
      "Epoch 01820: val_loss did not improve from 0.00328\n",
      "Epoch 1821/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.8523e-05 - val_loss: 0.0077\n",
      "\n",
      "Epoch 01821: val_loss did not improve from 0.00328\n",
      "Epoch 1822/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 1.8709e-05 - val_loss: 0.0082\n",
      "\n",
      "Epoch 01822: val_loss did not improve from 0.00328\n",
      "Epoch 1823/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.7705e-05 - val_loss: 0.0084\n",
      "\n",
      "Epoch 01823: val_loss did not improve from 0.00328\n",
      "Epoch 1824/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.1483e-05 - val_loss: 0.0082\n",
      "\n",
      "Epoch 01824: val_loss did not improve from 0.00328\n",
      "Epoch 1825/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 1.9335e-05 - val_loss: 0.0083\n",
      "\n",
      "Epoch 01825: val_loss did not improve from 0.00328\n",
      "Epoch 1826/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.2545e-05 - val_loss: 0.0082\n",
      "\n",
      "Epoch 01826: val_loss did not improve from 0.00328\n",
      "Epoch 1827/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 92us/step - loss: 2.4430e-05 - val_loss: 0.0080\n",
      "\n",
      "Epoch 01827: val_loss did not improve from 0.00328\n",
      "Epoch 1828/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.3915e-05 - val_loss: 0.0079\n",
      "\n",
      "Epoch 01828: val_loss did not improve from 0.00328\n",
      "Epoch 1829/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.7325e-05 - val_loss: 0.0079\n",
      "\n",
      "Epoch 01829: val_loss did not improve from 0.00328\n",
      "Epoch 1830/3000\n",
      "184/184 [==============================] - 0s 100us/step - loss: 2.0975e-05 - val_loss: 0.0079\n",
      "\n",
      "Epoch 01830: val_loss did not improve from 0.00328\n",
      "Epoch 1831/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.3677e-05 - val_loss: 0.0083\n",
      "\n",
      "Epoch 01831: val_loss did not improve from 0.00328\n",
      "Epoch 1832/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.4289e-05 - val_loss: 0.0084\n",
      "\n",
      "Epoch 01832: val_loss did not improve from 0.00328\n",
      "Epoch 1833/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 1.9972e-05 - val_loss: 0.0081\n",
      "\n",
      "Epoch 01833: val_loss did not improve from 0.00328\n",
      "Epoch 1834/3000\n",
      "184/184 [==============================] - 0s 168us/step - loss: 2.1527e-05 - val_loss: 0.0081\n",
      "\n",
      "Epoch 01834: val_loss did not improve from 0.00328\n",
      "Epoch 1835/3000\n",
      "184/184 [==============================] - 0s 147us/step - loss: 1.9758e-05 - val_loss: 0.0082\n",
      "\n",
      "Epoch 01835: val_loss did not improve from 0.00328\n",
      "Epoch 1836/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 1.8776e-05 - val_loss: 0.0085\n",
      "\n",
      "Epoch 01836: val_loss did not improve from 0.00328\n",
      "Epoch 1837/3000\n",
      "184/184 [==============================] - 0s 119us/step - loss: 2.4875e-05 - val_loss: 0.0086\n",
      "\n",
      "Epoch 01837: val_loss did not improve from 0.00328\n",
      "Epoch 1838/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.2335e-05 - val_loss: 0.0082\n",
      "\n",
      "Epoch 01838: val_loss did not improve from 0.00328\n",
      "Epoch 1839/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 1.7509e-05 - val_loss: 0.0079\n",
      "\n",
      "Epoch 01839: val_loss did not improve from 0.00328\n",
      "Epoch 1840/3000\n",
      "184/184 [==============================] - 0s 120us/step - loss: 2.6553e-05 - val_loss: 0.0083\n",
      "\n",
      "Epoch 01840: val_loss did not improve from 0.00328\n",
      "Epoch 1841/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.2029e-05 - val_loss: 0.0089\n",
      "\n",
      "Epoch 01841: val_loss did not improve from 0.00328\n",
      "Epoch 1842/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.0761e-05 - val_loss: 0.0087\n",
      "\n",
      "Epoch 01842: val_loss did not improve from 0.00328\n",
      "Epoch 1843/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 1.9897e-05 - val_loss: 0.0083\n",
      "\n",
      "Epoch 01843: val_loss did not improve from 0.00328\n",
      "Epoch 1844/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 1.9066e-05 - val_loss: 0.0083\n",
      "\n",
      "Epoch 01844: val_loss did not improve from 0.00328\n",
      "Epoch 1845/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.2149e-05 - val_loss: 0.0082\n",
      "\n",
      "Epoch 01845: val_loss did not improve from 0.00328\n",
      "Epoch 1846/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.2285e-05 - val_loss: 0.0080\n",
      "\n",
      "Epoch 01846: val_loss did not improve from 0.00328\n",
      "Epoch 1847/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.0805e-05 - val_loss: 0.0080\n",
      "\n",
      "Epoch 01847: val_loss did not improve from 0.00328\n",
      "Epoch 1848/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.5229e-05 - val_loss: 0.0084\n",
      "\n",
      "Epoch 01848: val_loss did not improve from 0.00328\n",
      "Epoch 1849/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.5340e-05 - val_loss: 0.0084\n",
      "\n",
      "Epoch 01849: val_loss did not improve from 0.00328\n",
      "Epoch 1850/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.3045e-05 - val_loss: 0.0079\n",
      "\n",
      "Epoch 01850: val_loss did not improve from 0.00328\n",
      "Epoch 1851/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.3980e-05 - val_loss: 0.0079\n",
      "\n",
      "Epoch 01851: val_loss did not improve from 0.00328\n",
      "Epoch 1852/3000\n",
      "184/184 [==============================] - 0s 93us/step - loss: 1.9558e-05 - val_loss: 0.0079\n",
      "\n",
      "Epoch 01852: val_loss did not improve from 0.00328\n",
      "Epoch 1853/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.1766e-05 - val_loss: 0.0078\n",
      "\n",
      "Epoch 01853: val_loss did not improve from 0.00328\n",
      "Epoch 1854/3000\n",
      "184/184 [==============================] - 0s 120us/step - loss: 1.7281e-05 - val_loss: 0.0080\n",
      "\n",
      "Epoch 01854: val_loss did not improve from 0.00328\n",
      "Epoch 1855/3000\n",
      "184/184 [==============================] - 0s 147us/step - loss: 2.1035e-05 - val_loss: 0.0081\n",
      "\n",
      "Epoch 01855: val_loss did not improve from 0.00328\n",
      "Epoch 1856/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.5039e-05 - val_loss: 0.0079\n",
      "\n",
      "Epoch 01856: val_loss did not improve from 0.00328\n",
      "Epoch 1857/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.1373e-05 - val_loss: 0.0084\n",
      "\n",
      "Epoch 01857: val_loss did not improve from 0.00328\n",
      "Epoch 1858/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.3908e-05 - val_loss: 0.0085\n",
      "\n",
      "Epoch 01858: val_loss did not improve from 0.00328\n",
      "Epoch 1859/3000\n",
      "184/184 [==============================] - ETA: 0s - loss: 1.1316e-0 - 0s 114us/step - loss: 2.4853e-05 - val_loss: 0.0082\n",
      "\n",
      "Epoch 01859: val_loss did not improve from 0.00328\n",
      "Epoch 1860/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.4714e-05 - val_loss: 0.0081\n",
      "\n",
      "Epoch 01860: val_loss did not improve from 0.00328\n",
      "Epoch 1861/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.1814e-05 - val_loss: 0.0083\n",
      "\n",
      "Epoch 01861: val_loss did not improve from 0.00328\n",
      "Epoch 1862/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.7240e-05 - val_loss: 0.0085\n",
      "\n",
      "Epoch 01862: val_loss did not improve from 0.00328\n",
      "Epoch 1863/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 1.9749e-05 - val_loss: 0.0081\n",
      "\n",
      "Epoch 01863: val_loss did not improve from 0.00328\n",
      "Epoch 1864/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.7782e-05 - val_loss: 0.0081\n",
      "\n",
      "Epoch 01864: val_loss did not improve from 0.00328\n",
      "Epoch 1865/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.2887e-05 - val_loss: 0.0085\n",
      "\n",
      "Epoch 01865: val_loss did not improve from 0.00328\n",
      "Epoch 1866/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.0023e-05 - val_loss: 0.0086\n",
      "\n",
      "Epoch 01866: val_loss did not improve from 0.00328\n",
      "Epoch 1867/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.2998e-05 - val_loss: 0.0083\n",
      "\n",
      "Epoch 01867: val_loss did not improve from 0.00328\n",
      "Epoch 1868/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 1.8846e-05 - val_loss: 0.0077\n",
      "\n",
      "Epoch 01868: val_loss did not improve from 0.00328\n",
      "Epoch 1869/3000\n",
      "184/184 [==============================] - 0s 196us/step - loss: 2.6799e-05 - val_loss: 0.0077\n",
      "\n",
      "Epoch 01869: val_loss did not improve from 0.00328\n",
      "Epoch 1870/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.6580e-05 - val_loss: 0.0080\n",
      "\n",
      "Epoch 01870: val_loss did not improve from 0.00328\n",
      "Epoch 1871/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 1.9375e-05 - val_loss: 0.0078\n",
      "\n",
      "Epoch 01871: val_loss did not improve from 0.00328\n",
      "Epoch 1872/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 1.6774e-05 - val_loss: 0.0076\n",
      "\n",
      "Epoch 01872: val_loss did not improve from 0.00328\n",
      "Epoch 1873/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 3.1195e-05 - val_loss: 0.0077\n",
      "\n",
      "Epoch 01873: val_loss did not improve from 0.00328\n",
      "Epoch 1874/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.3079e-05 - val_loss: 0.0082\n",
      "\n",
      "Epoch 01874: val_loss did not improve from 0.00328\n",
      "Epoch 1875/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.9565e-05 - val_loss: 0.0085\n",
      "\n",
      "Epoch 01875: val_loss did not improve from 0.00328\n",
      "Epoch 1876/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.1913e-05 - val_loss: 0.0082\n",
      "\n",
      "Epoch 01876: val_loss did not improve from 0.00328\n",
      "Epoch 1877/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 114us/step - loss: 2.3821e-05 - val_loss: 0.0080\n",
      "\n",
      "Epoch 01877: val_loss did not improve from 0.00328\n",
      "Epoch 1878/3000\n",
      "184/184 [==============================] - 0s 117us/step - loss: 2.2498e-05 - val_loss: 0.0081\n",
      "\n",
      "Epoch 01878: val_loss did not improve from 0.00328\n",
      "Epoch 1879/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.0569e-05 - val_loss: 0.0083\n",
      "\n",
      "Epoch 01879: val_loss did not improve from 0.00328\n",
      "Epoch 1880/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.6207e-05 - val_loss: 0.0083\n",
      "\n",
      "Epoch 01880: val_loss did not improve from 0.00328\n",
      "Epoch 1881/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.5704e-05 - val_loss: 0.0081\n",
      "\n",
      "Epoch 01881: val_loss did not improve from 0.00328\n",
      "Epoch 1882/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.3076e-05 - val_loss: 0.0080\n",
      "\n",
      "Epoch 01882: val_loss did not improve from 0.00328\n",
      "Epoch 1883/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.3544e-05 - val_loss: 0.0082\n",
      "\n",
      "Epoch 01883: val_loss did not improve from 0.00328\n",
      "Epoch 1884/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.7682e-05 - val_loss: 0.0083\n",
      "\n",
      "Epoch 01884: val_loss did not improve from 0.00328\n",
      "Epoch 1885/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.2520e-05 - val_loss: 0.0084\n",
      "\n",
      "Epoch 01885: val_loss did not improve from 0.00328\n",
      "Epoch 1886/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.1096e-05 - val_loss: 0.0082\n",
      "\n",
      "Epoch 01886: val_loss did not improve from 0.00328\n",
      "Epoch 1887/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.8268e-05 - val_loss: 0.0079\n",
      "\n",
      "Epoch 01887: val_loss did not improve from 0.00328\n",
      "Epoch 1888/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.4539e-05 - val_loss: 0.0082\n",
      "\n",
      "Epoch 01888: val_loss did not improve from 0.00328\n",
      "Epoch 1889/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.3304e-05 - val_loss: 0.0085\n",
      "\n",
      "Epoch 01889: val_loss did not improve from 0.00328\n",
      "Epoch 1890/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.2809e-05 - val_loss: 0.0080\n",
      "\n",
      "Epoch 01890: val_loss did not improve from 0.00328\n",
      "Epoch 1891/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 1.9951e-05 - val_loss: 0.0077\n",
      "\n",
      "Epoch 01891: val_loss did not improve from 0.00328\n",
      "Epoch 1892/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.2791e-05 - val_loss: 0.0081\n",
      "\n",
      "Epoch 01892: val_loss did not improve from 0.00328\n",
      "Epoch 1893/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.3282e-05 - val_loss: 0.0087\n",
      "\n",
      "Epoch 01893: val_loss did not improve from 0.00328\n",
      "Epoch 1894/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.0257e-05 - val_loss: 0.0085\n",
      "\n",
      "Epoch 01894: val_loss did not improve from 0.00328\n",
      "Epoch 1895/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.7396e-05 - val_loss: 0.0081\n",
      "\n",
      "Epoch 01895: val_loss did not improve from 0.00328\n",
      "Epoch 1896/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.4996e-05 - val_loss: 0.0082\n",
      "\n",
      "Epoch 01896: val_loss did not improve from 0.00328\n",
      "Epoch 1897/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.4572e-05 - val_loss: 0.0085\n",
      "\n",
      "Epoch 01897: val_loss did not improve from 0.00328\n",
      "Epoch 1898/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 1.9159e-05 - val_loss: 0.0087\n",
      "\n",
      "Epoch 01898: val_loss did not improve from 0.00328\n",
      "Epoch 1899/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.4119e-05 - val_loss: 0.0084\n",
      "\n",
      "Epoch 01899: val_loss did not improve from 0.00328\n",
      "Epoch 1900/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.0282e-05 - val_loss: 0.0080\n",
      "\n",
      "Epoch 01900: val_loss did not improve from 0.00328\n",
      "Epoch 1901/3000\n",
      "184/184 [==============================] - 0s 141us/step - loss: 3.1886e-05 - val_loss: 0.0081\n",
      "\n",
      "Epoch 01901: val_loss did not improve from 0.00328\n",
      "Epoch 1902/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.1433e-05 - val_loss: 0.0085\n",
      "\n",
      "Epoch 01902: val_loss did not improve from 0.00328\n",
      "Epoch 1903/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.4439e-05 - val_loss: 0.0086\n",
      "\n",
      "Epoch 01903: val_loss did not improve from 0.00328\n",
      "Epoch 1904/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 1.9947e-05 - val_loss: 0.0083\n",
      "\n",
      "Epoch 01904: val_loss did not improve from 0.00328\n",
      "Epoch 1905/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.2840e-05 - val_loss: 0.0080\n",
      "\n",
      "Epoch 01905: val_loss did not improve from 0.00328\n",
      "Epoch 1906/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.1452e-05 - val_loss: 0.0080\n",
      "\n",
      "Epoch 01906: val_loss did not improve from 0.00328\n",
      "Epoch 1907/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 1.5929e-05 - val_loss: 0.0083\n",
      "\n",
      "Epoch 01907: val_loss did not improve from 0.00328\n",
      "Epoch 1908/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.0437e-05 - val_loss: 0.0083\n",
      "\n",
      "Epoch 01908: val_loss did not improve from 0.00328\n",
      "Epoch 1909/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 1.9772e-05 - val_loss: 0.0081\n",
      "\n",
      "Epoch 01909: val_loss did not improve from 0.00328\n",
      "Epoch 1910/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.2629e-05 - val_loss: 0.0083\n",
      "\n",
      "Epoch 01910: val_loss did not improve from 0.00328\n",
      "Epoch 1911/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 1.9438e-05 - val_loss: 0.0087\n",
      "\n",
      "Epoch 01911: val_loss did not improve from 0.00328\n",
      "Epoch 1912/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.4446e-05 - val_loss: 0.0087\n",
      "\n",
      "Epoch 01912: val_loss did not improve from 0.00328\n",
      "Epoch 1913/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 1.8838e-05 - val_loss: 0.0083\n",
      "\n",
      "Epoch 01913: val_loss did not improve from 0.00328\n",
      "Epoch 1914/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.3735e-05 - val_loss: 0.0081\n",
      "\n",
      "Epoch 01914: val_loss did not improve from 0.00328\n",
      "Epoch 1915/3000\n",
      "184/184 [==============================] - 0s 141us/step - loss: 1.9736e-05 - val_loss: 0.0083\n",
      "\n",
      "Epoch 01915: val_loss did not improve from 0.00328\n",
      "Epoch 1916/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.3952e-05 - val_loss: 0.0085\n",
      "\n",
      "Epoch 01916: val_loss did not improve from 0.00328\n",
      "Epoch 1917/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 1.9259e-05 - val_loss: 0.0082\n",
      "\n",
      "Epoch 01917: val_loss did not improve from 0.00328\n",
      "Epoch 1918/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.2211e-05 - val_loss: 0.0079\n",
      "\n",
      "Epoch 01918: val_loss did not improve from 0.00328\n",
      "Epoch 1919/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.5258e-05 - val_loss: 0.0080\n",
      "\n",
      "Epoch 01919: val_loss did not improve from 0.00328\n",
      "Epoch 1920/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 1.9186e-05 - val_loss: 0.0082\n",
      "\n",
      "Epoch 01920: val_loss did not improve from 0.00328\n",
      "Epoch 1921/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.4910e-05 - val_loss: 0.0083\n",
      "\n",
      "Epoch 01921: val_loss did not improve from 0.00328\n",
      "Epoch 1922/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.3034e-05 - val_loss: 0.0085\n",
      "\n",
      "Epoch 01922: val_loss did not improve from 0.00328\n",
      "Epoch 1923/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.3236e-05 - val_loss: 0.0085\n",
      "\n",
      "Epoch 01923: val_loss did not improve from 0.00328\n",
      "Epoch 1924/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.2241e-05 - val_loss: 0.0082\n",
      "\n",
      "Epoch 01924: val_loss did not improve from 0.00328\n",
      "Epoch 1925/3000\n",
      "184/184 [==============================] - 0s 136us/step - loss: 1.8624e-05 - val_loss: 0.0080\n",
      "\n",
      "Epoch 01925: val_loss did not improve from 0.00328\n",
      "Epoch 1926/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 1.9637e-05 - val_loss: 0.0083\n",
      "\n",
      "Epoch 01926: val_loss did not improve from 0.00328\n",
      "Epoch 1927/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.4341e-05 - val_loss: 0.0085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 01927: val_loss did not improve from 0.00328\n",
      "Epoch 1928/3000\n",
      "184/184 [==============================] - 0s 81us/step - loss: 2.4276e-05 - val_loss: 0.0083\n",
      "\n",
      "Epoch 01928: val_loss did not improve from 0.00328\n",
      "Epoch 1929/3000\n",
      "184/184 [==============================] - 0s 93us/step - loss: 2.3318e-05 - val_loss: 0.0078\n",
      "\n",
      "Epoch 01929: val_loss did not improve from 0.00328\n",
      "Epoch 1930/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.5062e-05 - val_loss: 0.0077\n",
      "\n",
      "Epoch 01930: val_loss did not improve from 0.00328\n",
      "Epoch 1931/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.4831e-05 - val_loss: 0.0083\n",
      "\n",
      "Epoch 01931: val_loss did not improve from 0.00328\n",
      "Epoch 1932/3000\n",
      "184/184 [==============================] - 0s 93us/step - loss: 2.5631e-05 - val_loss: 0.0087\n",
      "\n",
      "Epoch 01932: val_loss did not improve from 0.00328\n",
      "Epoch 1933/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 1.9997e-05 - val_loss: 0.0083\n",
      "\n",
      "Epoch 01933: val_loss did not improve from 0.00328\n",
      "Epoch 1934/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.1769e-05 - val_loss: 0.0078\n",
      "\n",
      "Epoch 01934: val_loss did not improve from 0.00328\n",
      "Epoch 1935/3000\n",
      "184/184 [==============================] - 0s 93us/step - loss: 2.3880e-05 - val_loss: 0.0079\n",
      "\n",
      "Epoch 01935: val_loss did not improve from 0.00328\n",
      "Epoch 1936/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.3423e-05 - val_loss: 0.0084\n",
      "\n",
      "Epoch 01936: val_loss did not improve from 0.00328\n",
      "Epoch 1937/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.1079e-05 - val_loss: 0.0086\n",
      "\n",
      "Epoch 01937: val_loss did not improve from 0.00328\n",
      "Epoch 1938/3000\n",
      "184/184 [==============================] - 0s 82us/step - loss: 2.1283e-05 - val_loss: 0.0080\n",
      "\n",
      "Epoch 01938: val_loss did not improve from 0.00328\n",
      "Epoch 1939/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.4752e-05 - val_loss: 0.0076\n",
      "\n",
      "Epoch 01939: val_loss did not improve from 0.00328\n",
      "Epoch 1940/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.7770e-05 - val_loss: 0.0079\n",
      "\n",
      "Epoch 01940: val_loss did not improve from 0.00328\n",
      "Epoch 1941/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.1791e-05 - val_loss: 0.0083\n",
      "\n",
      "Epoch 01941: val_loss did not improve from 0.00328\n",
      "Epoch 1942/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.7052e-05 - val_loss: 0.0084\n",
      "\n",
      "Epoch 01942: val_loss did not improve from 0.00328\n",
      "Epoch 1943/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.1343e-05 - val_loss: 0.0082\n",
      "\n",
      "Epoch 01943: val_loss did not improve from 0.00328\n",
      "Epoch 1944/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.0810e-05 - val_loss: 0.0083\n",
      "\n",
      "Epoch 01944: val_loss did not improve from 0.00328\n",
      "Epoch 1945/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.2113e-05 - val_loss: 0.0084\n",
      "\n",
      "Epoch 01945: val_loss did not improve from 0.00328\n",
      "Epoch 1946/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.2145e-05 - val_loss: 0.0083\n",
      "\n",
      "Epoch 01946: val_loss did not improve from 0.00328\n",
      "Epoch 1947/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.4828e-05 - val_loss: 0.0083\n",
      "\n",
      "Epoch 01947: val_loss did not improve from 0.00328\n",
      "Epoch 1948/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.0779e-05 - val_loss: 0.0082\n",
      "\n",
      "Epoch 01948: val_loss did not improve from 0.00328\n",
      "Epoch 1949/3000\n",
      "184/184 [==============================] - 0s 152us/step - loss: 2.6349e-05 - val_loss: 0.0081\n",
      "\n",
      "Epoch 01949: val_loss did not improve from 0.00328\n",
      "Epoch 1950/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.5028e-05 - val_loss: 0.0081\n",
      "\n",
      "Epoch 01950: val_loss did not improve from 0.00328\n",
      "Epoch 1951/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.4575e-05 - val_loss: 0.0083\n",
      "\n",
      "Epoch 01951: val_loss did not improve from 0.00328\n",
      "Epoch 1952/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.2908e-05 - val_loss: 0.0084\n",
      "\n",
      "Epoch 01952: val_loss did not improve from 0.00328\n",
      "Epoch 1953/3000\n",
      "184/184 [==============================] - 0s 93us/step - loss: 1.9738e-05 - val_loss: 0.0082\n",
      "\n",
      "Epoch 01953: val_loss did not improve from 0.00328\n",
      "Epoch 1954/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.6075e-05 - val_loss: 0.0082\n",
      "\n",
      "Epoch 01954: val_loss did not improve from 0.00328\n",
      "Epoch 1955/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.1763e-05 - val_loss: 0.0081\n",
      "\n",
      "Epoch 01955: val_loss did not improve from 0.00328\n",
      "Epoch 1956/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.2253e-05 - val_loss: 0.0081\n",
      "\n",
      "Epoch 01956: val_loss did not improve from 0.00328\n",
      "Epoch 1957/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 1.9881e-05 - val_loss: 0.0083\n",
      "\n",
      "Epoch 01957: val_loss did not improve from 0.00328\n",
      "Epoch 1958/3000\n",
      "184/184 [==============================] - 0s 81us/step - loss: 2.1697e-05 - val_loss: 0.0082\n",
      "\n",
      "Epoch 01958: val_loss did not improve from 0.00328\n",
      "Epoch 1959/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 1.8945e-05 - val_loss: 0.0080\n",
      "\n",
      "Epoch 01959: val_loss did not improve from 0.00328\n",
      "Epoch 1960/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.0806e-05 - val_loss: 0.0081\n",
      "\n",
      "Epoch 01960: val_loss did not improve from 0.00328\n",
      "Epoch 1961/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.0773e-05 - val_loss: 0.0086\n",
      "\n",
      "Epoch 01961: val_loss did not improve from 0.00328\n",
      "Epoch 1962/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.5675e-05 - val_loss: 0.0087\n",
      "\n",
      "Epoch 01962: val_loss did not improve from 0.00328\n",
      "Epoch 1963/3000\n",
      "184/184 [==============================] - 0s 81us/step - loss: 2.5434e-05 - val_loss: 0.0081\n",
      "\n",
      "Epoch 01963: val_loss did not improve from 0.00328\n",
      "Epoch 1964/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 3.1105e-05 - val_loss: 0.0079\n",
      "\n",
      "Epoch 01964: val_loss did not improve from 0.00328\n",
      "Epoch 1965/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.2455e-05 - val_loss: 0.0082\n",
      "\n",
      "Epoch 01965: val_loss did not improve from 0.00328\n",
      "Epoch 1966/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.1187e-05 - val_loss: 0.0087\n",
      "\n",
      "Epoch 01966: val_loss did not improve from 0.00328\n",
      "Epoch 1967/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.7520e-05 - val_loss: 0.0086\n",
      "\n",
      "Epoch 01967: val_loss did not improve from 0.00328\n",
      "Epoch 1968/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.1073e-05 - val_loss: 0.0082\n",
      "\n",
      "Epoch 01968: val_loss did not improve from 0.00328\n",
      "Epoch 1969/3000\n",
      "184/184 [==============================] - 0s 95us/step - loss: 2.6779e-05 - val_loss: 0.0082\n",
      "\n",
      "Epoch 01969: val_loss did not improve from 0.00328\n",
      "Epoch 1970/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.3026e-05 - val_loss: 0.0086\n",
      "\n",
      "Epoch 01970: val_loss did not improve from 0.00328\n",
      "Epoch 1971/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.1476e-05 - val_loss: 0.0088\n",
      "\n",
      "Epoch 01971: val_loss did not improve from 0.00328\n",
      "Epoch 1972/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.5773e-05 - val_loss: 0.0087\n",
      "\n",
      "Epoch 01972: val_loss did not improve from 0.00328\n",
      "Epoch 1973/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.5298e-05 - val_loss: 0.0083\n",
      "\n",
      "Epoch 01973: val_loss did not improve from 0.00328\n",
      "Epoch 1974/3000\n",
      "184/184 [==============================] - 0s 119us/step - loss: 2.2218e-05 - val_loss: 0.0081\n",
      "\n",
      "Epoch 01974: val_loss did not improve from 0.00328\n",
      "Epoch 1975/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.6308e-05 - val_loss: 0.0081\n",
      "\n",
      "Epoch 01975: val_loss did not improve from 0.00328\n",
      "Epoch 1976/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.8781e-05 - val_loss: 0.0084\n",
      "\n",
      "Epoch 01976: val_loss did not improve from 0.00328\n",
      "Epoch 1977/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.2398e-05 - val_loss: 0.0082\n",
      "\n",
      "Epoch 01977: val_loss did not improve from 0.00328\n",
      "Epoch 1978/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 98us/step - loss: 2.1945e-05 - val_loss: 0.0079\n",
      "\n",
      "Epoch 01978: val_loss did not improve from 0.00328\n",
      "Epoch 1979/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.3407e-05 - val_loss: 0.0078\n",
      "\n",
      "Epoch 01979: val_loss did not improve from 0.00328\n",
      "Epoch 1980/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.0720e-05 - val_loss: 0.0081\n",
      "\n",
      "Epoch 01980: val_loss did not improve from 0.00328\n",
      "Epoch 1981/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.1943e-05 - val_loss: 0.0083\n",
      "\n",
      "Epoch 01981: val_loss did not improve from 0.00328\n",
      "Epoch 1982/3000\n",
      "184/184 [==============================] - 0s 93us/step - loss: 1.8921e-05 - val_loss: 0.0082\n",
      "\n",
      "Epoch 01982: val_loss did not improve from 0.00328\n",
      "Epoch 1983/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.4703e-05 - val_loss: 0.0080\n",
      "\n",
      "Epoch 01983: val_loss did not improve from 0.00328\n",
      "Epoch 1984/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.3716e-05 - val_loss: 0.0080\n",
      "\n",
      "Epoch 01984: val_loss did not improve from 0.00328\n",
      "Epoch 1985/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.2400e-05 - val_loss: 0.0078\n",
      "\n",
      "Epoch 01985: val_loss did not improve from 0.00328\n",
      "Epoch 1986/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.5688e-05 - val_loss: 0.0078\n",
      "\n",
      "Epoch 01986: val_loss did not improve from 0.00328\n",
      "Epoch 1987/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.7868e-05 - val_loss: 0.0083\n",
      "\n",
      "Epoch 01987: val_loss did not improve from 0.00328\n",
      "Epoch 1988/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.3580e-05 - val_loss: 0.0086\n",
      "\n",
      "Epoch 01988: val_loss did not improve from 0.00328\n",
      "Epoch 1989/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.1459e-05 - val_loss: 0.0083\n",
      "\n",
      "Epoch 01989: val_loss did not improve from 0.00328\n",
      "Epoch 1990/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 1.9293e-05 - val_loss: 0.0081\n",
      "\n",
      "Epoch 01990: val_loss did not improve from 0.00328\n",
      "Epoch 1991/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.7845e-05 - val_loss: 0.0083\n",
      "\n",
      "Epoch 01991: val_loss did not improve from 0.00328\n",
      "Epoch 1992/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.4162e-05 - val_loss: 0.0087\n",
      "\n",
      "Epoch 01992: val_loss did not improve from 0.00328\n",
      "Epoch 1993/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.3655e-05 - val_loss: 0.0084\n",
      "\n",
      "Epoch 01993: val_loss did not improve from 0.00328\n",
      "Epoch 1994/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.4907e-05 - val_loss: 0.0080\n",
      "\n",
      "Epoch 01994: val_loss did not improve from 0.00328\n",
      "Epoch 1995/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.5474e-05 - val_loss: 0.0081\n",
      "\n",
      "Epoch 01995: val_loss did not improve from 0.00328\n",
      "Epoch 1996/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.4051e-05 - val_loss: 0.0083\n",
      "\n",
      "Epoch 01996: val_loss did not improve from 0.00328\n",
      "Epoch 1997/3000\n",
      "184/184 [==============================] - 0s 136us/step - loss: 2.2736e-05 - val_loss: 0.0080\n",
      "\n",
      "Epoch 01997: val_loss did not improve from 0.00328\n",
      "Epoch 1998/3000\n",
      "184/184 [==============================] - 0s 120us/step - loss: 2.3116e-05 - val_loss: 0.0077\n",
      "\n",
      "Epoch 01998: val_loss did not improve from 0.00328\n",
      "Epoch 1999/3000\n",
      "184/184 [==============================] - ETA: 0s - loss: 1.3361e-0 - 0s 109us/step - loss: 1.8790e-05 - val_loss: 0.0075\n",
      "\n",
      "Epoch 01999: val_loss did not improve from 0.00328\n",
      "Epoch 2000/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.4591e-05 - val_loss: 0.0076\n",
      "\n",
      "Epoch 02000: val_loss did not improve from 0.00328\n",
      "Epoch 2001/3000\n",
      "184/184 [==============================] - 0s 141us/step - loss: 2.3053e-05 - val_loss: 0.0079\n",
      "\n",
      "Epoch 02001: val_loss did not improve from 0.00328\n",
      "Epoch 2002/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.1981e-05 - val_loss: 0.0080\n",
      "\n",
      "Epoch 02002: val_loss did not improve from 0.00328\n",
      "Epoch 2003/3000\n",
      "184/184 [==============================] - 0s 101us/step - loss: 2.4097e-05 - val_loss: 0.0080\n",
      "\n",
      "Epoch 02003: val_loss did not improve from 0.00328\n",
      "Epoch 2004/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.1855e-05 - val_loss: 0.0080\n",
      "\n",
      "Epoch 02004: val_loss did not improve from 0.00328\n",
      "Epoch 2005/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.5976e-05 - val_loss: 0.0081\n",
      "\n",
      "Epoch 02005: val_loss did not improve from 0.00328\n",
      "Epoch 2006/3000\n",
      "184/184 [==============================] - 0s 93us/step - loss: 2.1062e-05 - val_loss: 0.0082\n",
      "\n",
      "Epoch 02006: val_loss did not improve from 0.00328\n",
      "Epoch 2007/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.5906e-05 - val_loss: 0.0083\n",
      "\n",
      "Epoch 02007: val_loss did not improve from 0.00328\n",
      "Epoch 2008/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.2118e-05 - val_loss: 0.0082\n",
      "\n",
      "Epoch 02008: val_loss did not improve from 0.00328\n",
      "Epoch 2009/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.2383e-05 - val_loss: 0.0081\n",
      "\n",
      "Epoch 02009: val_loss did not improve from 0.00328\n",
      "Epoch 2010/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.4376e-05 - val_loss: 0.0082\n",
      "\n",
      "Epoch 02010: val_loss did not improve from 0.00328\n",
      "Epoch 2011/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 1.9437e-05 - val_loss: 0.0084\n",
      "\n",
      "Epoch 02011: val_loss did not improve from 0.00328\n",
      "Epoch 2012/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.2576e-05 - val_loss: 0.0086\n",
      "\n",
      "Epoch 02012: val_loss did not improve from 0.00328\n",
      "Epoch 2013/3000\n",
      "184/184 [==============================] - 0s 93us/step - loss: 1.9318e-05 - val_loss: 0.0086\n",
      "\n",
      "Epoch 02013: val_loss did not improve from 0.00328\n",
      "Epoch 2014/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 1.5795e-05 - val_loss: 0.0085\n",
      "\n",
      "Epoch 02014: val_loss did not improve from 0.00328\n",
      "Epoch 2015/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.3667e-05 - val_loss: 0.0084\n",
      "\n",
      "Epoch 02015: val_loss did not improve from 0.00328\n",
      "Epoch 2016/3000\n",
      "184/184 [==============================] - 0s 93us/step - loss: 2.6431e-05 - val_loss: 0.0085\n",
      "\n",
      "Epoch 02016: val_loss did not improve from 0.00328\n",
      "Epoch 2017/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 1.8234e-05 - val_loss: 0.0085\n",
      "\n",
      "Epoch 02017: val_loss did not improve from 0.00328\n",
      "Epoch 2018/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.2757e-05 - val_loss: 0.0084\n",
      "\n",
      "Epoch 02018: val_loss did not improve from 0.00328\n",
      "Epoch 2019/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.0883e-05 - val_loss: 0.0082\n",
      "\n",
      "Epoch 02019: val_loss did not improve from 0.00328\n",
      "Epoch 2020/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 1.7987e-05 - val_loss: 0.0083\n",
      "\n",
      "Epoch 02020: val_loss did not improve from 0.00328\n",
      "Epoch 2021/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 3.4065e-05 - val_loss: 0.0084\n",
      "\n",
      "Epoch 02021: val_loss did not improve from 0.00328\n",
      "Epoch 2022/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.7613e-05 - val_loss: 0.0085\n",
      "\n",
      "Epoch 02022: val_loss did not improve from 0.00328\n",
      "Epoch 2023/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.3259e-05 - val_loss: 0.0085\n",
      "\n",
      "Epoch 02023: val_loss did not improve from 0.00328\n",
      "Epoch 2024/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.0014e-05 - val_loss: 0.0086\n",
      "\n",
      "Epoch 02024: val_loss did not improve from 0.00328\n",
      "Epoch 2025/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.6883e-05 - val_loss: 0.0088\n",
      "\n",
      "Epoch 02025: val_loss did not improve from 0.00328\n",
      "Epoch 2026/3000\n",
      "184/184 [==============================] - 0s 81us/step - loss: 1.9432e-05 - val_loss: 0.0089\n",
      "\n",
      "Epoch 02026: val_loss did not improve from 0.00328\n",
      "Epoch 2027/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.6457e-05 - val_loss: 0.0089\n",
      "\n",
      "Epoch 02027: val_loss did not improve from 0.00328\n",
      "Epoch 2028/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 93us/step - loss: 2.3195e-05 - val_loss: 0.0087\n",
      "\n",
      "Epoch 02028: val_loss did not improve from 0.00328\n",
      "Epoch 2029/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.1670e-05 - val_loss: 0.0081\n",
      "\n",
      "Epoch 02029: val_loss did not improve from 0.00328\n",
      "Epoch 2030/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 3.0028e-05 - val_loss: 0.0079\n",
      "\n",
      "Epoch 02030: val_loss did not improve from 0.00328\n",
      "Epoch 2031/3000\n",
      "184/184 [==============================] - 0s 93us/step - loss: 2.2570e-05 - val_loss: 0.0081\n",
      "\n",
      "Epoch 02031: val_loss did not improve from 0.00328\n",
      "Epoch 2032/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.4358e-05 - val_loss: 0.0085\n",
      "\n",
      "Epoch 02032: val_loss did not improve from 0.00328\n",
      "Epoch 2033/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.9528e-05 - val_loss: 0.0086\n",
      "\n",
      "Epoch 02033: val_loss did not improve from 0.00328\n",
      "Epoch 2034/3000\n",
      "184/184 [==============================] - 0s 93us/step - loss: 2.4494e-05 - val_loss: 0.0082\n",
      "\n",
      "Epoch 02034: val_loss did not improve from 0.00328\n",
      "Epoch 2035/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.4528e-05 - val_loss: 0.0081\n",
      "\n",
      "Epoch 02035: val_loss did not improve from 0.00328\n",
      "Epoch 2036/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.5113e-05 - val_loss: 0.0084\n",
      "\n",
      "Epoch 02036: val_loss did not improve from 0.00328\n",
      "Epoch 2037/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.1056e-05 - val_loss: 0.0088\n",
      "\n",
      "Epoch 02037: val_loss did not improve from 0.00328\n",
      "Epoch 2038/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.5272e-05 - val_loss: 0.0089\n",
      "\n",
      "Epoch 02038: val_loss did not improve from 0.00328\n",
      "Epoch 2039/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.1714e-05 - val_loss: 0.0085\n",
      "\n",
      "Epoch 02039: val_loss did not improve from 0.00328\n",
      "Epoch 2040/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.4124e-05 - val_loss: 0.0084\n",
      "\n",
      "Epoch 02040: val_loss did not improve from 0.00328\n",
      "Epoch 2041/3000\n",
      "184/184 [==============================] - 0s 93us/step - loss: 2.1297e-05 - val_loss: 0.0086\n",
      "\n",
      "Epoch 02041: val_loss did not improve from 0.00328\n",
      "Epoch 2042/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.0433e-05 - val_loss: 0.0087\n",
      "\n",
      "Epoch 02042: val_loss did not improve from 0.00328\n",
      "Epoch 2043/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 1.8114e-05 - val_loss: 0.0085\n",
      "\n",
      "Epoch 02043: val_loss did not improve from 0.00328\n",
      "Epoch 2044/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 1.7695e-05 - val_loss: 0.0085\n",
      "\n",
      "Epoch 02044: val_loss did not improve from 0.00328\n",
      "Epoch 2045/3000\n",
      "184/184 [==============================] - 0s 119us/step - loss: 1.7333e-05 - val_loss: 0.0085\n",
      "\n",
      "Epoch 02045: val_loss did not improve from 0.00328\n",
      "Epoch 2046/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 1.7981e-05 - val_loss: 0.0084\n",
      "\n",
      "Epoch 02046: val_loss did not improve from 0.00328\n",
      "Epoch 2047/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.0307e-05 - val_loss: 0.0085\n",
      "\n",
      "Epoch 02047: val_loss did not improve from 0.00328\n",
      "Epoch 2048/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 1.8629e-05 - val_loss: 0.0085\n",
      "\n",
      "Epoch 02048: val_loss did not improve from 0.00328\n",
      "Epoch 2049/3000\n",
      "184/184 [==============================] - 0s 93us/step - loss: 1.9056e-05 - val_loss: 0.0086\n",
      "\n",
      "Epoch 02049: val_loss did not improve from 0.00328\n",
      "Epoch 2050/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.0265e-05 - val_loss: 0.0089\n",
      "\n",
      "Epoch 02050: val_loss did not improve from 0.00328\n",
      "Epoch 2051/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.4155e-05 - val_loss: 0.0090\n",
      "\n",
      "Epoch 02051: val_loss did not improve from 0.00328\n",
      "Epoch 2052/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 1.9812e-05 - val_loss: 0.0087\n",
      "\n",
      "Epoch 02052: val_loss did not improve from 0.00328\n",
      "Epoch 2053/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.0967e-05 - val_loss: 0.0086\n",
      "\n",
      "Epoch 02053: val_loss did not improve from 0.00328\n",
      "Epoch 2054/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 1.8603e-05 - val_loss: 0.0086\n",
      "\n",
      "Epoch 02054: val_loss did not improve from 0.00328\n",
      "Epoch 2055/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.6014e-05 - val_loss: 0.0085\n",
      "\n",
      "Epoch 02055: val_loss did not improve from 0.00328\n",
      "Epoch 2056/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 1.8101e-05 - val_loss: 0.0084\n",
      "\n",
      "Epoch 02056: val_loss did not improve from 0.00328\n",
      "Epoch 2057/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.1984e-05 - val_loss: 0.0087\n",
      "\n",
      "Epoch 02057: val_loss did not improve from 0.00328\n",
      "Epoch 2058/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.1291e-05 - val_loss: 0.0087\n",
      "\n",
      "Epoch 02058: val_loss did not improve from 0.00328\n",
      "Epoch 2059/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.1037e-05 - val_loss: 0.0083\n",
      "\n",
      "Epoch 02059: val_loss did not improve from 0.00328\n",
      "Epoch 2060/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.9042e-05 - val_loss: 0.0081\n",
      "\n",
      "Epoch 02060: val_loss did not improve from 0.00328\n",
      "Epoch 2061/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.6213e-05 - val_loss: 0.0084\n",
      "\n",
      "Epoch 02061: val_loss did not improve from 0.00328\n",
      "Epoch 2062/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.0392e-05 - val_loss: 0.0087\n",
      "\n",
      "Epoch 02062: val_loss did not improve from 0.00328\n",
      "Epoch 2063/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.2357e-05 - val_loss: 0.0086\n",
      "\n",
      "Epoch 02063: val_loss did not improve from 0.00328\n",
      "Epoch 2064/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.1932e-05 - val_loss: 0.0083\n",
      "\n",
      "Epoch 02064: val_loss did not improve from 0.00328\n",
      "Epoch 2065/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.2391e-05 - val_loss: 0.0085\n",
      "\n",
      "Epoch 02065: val_loss did not improve from 0.00328\n",
      "Epoch 2066/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.4689e-05 - val_loss: 0.0086\n",
      "\n",
      "Epoch 02066: val_loss did not improve from 0.00328\n",
      "Epoch 2067/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 1.8916e-05 - val_loss: 0.0086\n",
      "\n",
      "Epoch 02067: val_loss did not improve from 0.00328\n",
      "Epoch 2068/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.8410e-05 - val_loss: 0.0087\n",
      "\n",
      "Epoch 02068: val_loss did not improve from 0.00328\n",
      "Epoch 2069/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 1.8304e-05 - val_loss: 0.0086\n",
      "\n",
      "Epoch 02069: val_loss did not improve from 0.00328\n",
      "Epoch 2070/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.0007e-05 - val_loss: 0.0084\n",
      "\n",
      "Epoch 02070: val_loss did not improve from 0.00328\n",
      "Epoch 2071/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 1.8392e-05 - val_loss: 0.0083\n",
      "\n",
      "Epoch 02071: val_loss did not improve from 0.00328\n",
      "Epoch 2072/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 1.8227e-05 - val_loss: 0.0085\n",
      "\n",
      "Epoch 02072: val_loss did not improve from 0.00328\n",
      "Epoch 2073/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.1594e-05 - val_loss: 0.0088\n",
      "\n",
      "Epoch 02073: val_loss did not improve from 0.00328\n",
      "Epoch 2074/3000\n",
      "184/184 [==============================] - 0s 93us/step - loss: 2.2630e-05 - val_loss: 0.0087\n",
      "\n",
      "Epoch 02074: val_loss did not improve from 0.00328\n",
      "Epoch 2075/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 1.5658e-05 - val_loss: 0.0087\n",
      "\n",
      "Epoch 02075: val_loss did not improve from 0.00328\n",
      "Epoch 2076/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 1.9716e-05 - val_loss: 0.0086\n",
      "\n",
      "Epoch 02076: val_loss did not improve from 0.00328\n",
      "Epoch 2077/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.4956e-05 - val_loss: 0.0084\n",
      "\n",
      "Epoch 02077: val_loss did not improve from 0.00328\n",
      "Epoch 2078/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.3899e-05 - val_loss: 0.0083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 02078: val_loss did not improve from 0.00328\n",
      "Epoch 2079/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 1.9530e-05 - val_loss: 0.0083\n",
      "\n",
      "Epoch 02079: val_loss did not improve from 0.00328\n",
      "Epoch 2080/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 1.8656e-05 - val_loss: 0.0084\n",
      "\n",
      "Epoch 02080: val_loss did not improve from 0.00328\n",
      "Epoch 2081/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 1.9342e-05 - val_loss: 0.0085\n",
      "\n",
      "Epoch 02081: val_loss did not improve from 0.00328\n",
      "Epoch 2082/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.3544e-05 - val_loss: 0.0085\n",
      "\n",
      "Epoch 02082: val_loss did not improve from 0.00328\n",
      "Epoch 2083/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.3548e-05 - val_loss: 0.0086\n",
      "\n",
      "Epoch 02083: val_loss did not improve from 0.00328\n",
      "Epoch 2084/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.3759e-05 - val_loss: 0.0085\n",
      "\n",
      "Epoch 02084: val_loss did not improve from 0.00328\n",
      "Epoch 2085/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.0475e-05 - val_loss: 0.0085\n",
      "\n",
      "Epoch 02085: val_loss did not improve from 0.00328\n",
      "Epoch 2086/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.6990e-05 - val_loss: 0.0088\n",
      "\n",
      "Epoch 02086: val_loss did not improve from 0.00328\n",
      "Epoch 2087/3000\n",
      "184/184 [==============================] - 0s 93us/step - loss: 2.1006e-05 - val_loss: 0.0090\n",
      "\n",
      "Epoch 02087: val_loss did not improve from 0.00328\n",
      "Epoch 2088/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.5102e-05 - val_loss: 0.0088\n",
      "\n",
      "Epoch 02088: val_loss did not improve from 0.00328\n",
      "Epoch 2089/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.2408e-05 - val_loss: 0.0085\n",
      "\n",
      "Epoch 02089: val_loss did not improve from 0.00328\n",
      "Epoch 2090/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.0862e-05 - val_loss: 0.0089\n",
      "\n",
      "Epoch 02090: val_loss did not improve from 0.00328\n",
      "Epoch 2091/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.2938e-05 - val_loss: 0.0090\n",
      "\n",
      "Epoch 02091: val_loss did not improve from 0.00328\n",
      "Epoch 2092/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 1.8529e-05 - val_loss: 0.0085\n",
      "\n",
      "Epoch 02092: val_loss did not improve from 0.00328\n",
      "Epoch 2093/3000\n",
      "184/184 [==============================] - 0s 119us/step - loss: 1.7678e-05 - val_loss: 0.0082\n",
      "\n",
      "Epoch 02093: val_loss did not improve from 0.00328\n",
      "Epoch 2094/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 1.9729e-05 - val_loss: 0.0082\n",
      "\n",
      "Epoch 02094: val_loss did not improve from 0.00328\n",
      "Epoch 2095/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 1.9818e-05 - val_loss: 0.0083\n",
      "\n",
      "Epoch 02095: val_loss did not improve from 0.00328\n",
      "Epoch 2096/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.0027e-05 - val_loss: 0.0087\n",
      "\n",
      "Epoch 02096: val_loss did not improve from 0.00328\n",
      "Epoch 2097/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.0110e-05 - val_loss: 0.0089\n",
      "\n",
      "Epoch 02097: val_loss did not improve from 0.00328\n",
      "Epoch 2098/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 1.8132e-05 - val_loss: 0.0087\n",
      "\n",
      "Epoch 02098: val_loss did not improve from 0.00328\n",
      "Epoch 2099/3000\n",
      "184/184 [==============================] - 0s 93us/step - loss: 2.4552e-05 - val_loss: 0.0087\n",
      "\n",
      "Epoch 02099: val_loss did not improve from 0.00328\n",
      "Epoch 2100/3000\n",
      "184/184 [==============================] - 0s 119us/step - loss: 2.6749e-05 - val_loss: 0.0089\n",
      "\n",
      "Epoch 02100: val_loss did not improve from 0.00328\n",
      "Epoch 2101/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 1.9612e-05 - val_loss: 0.0091\n",
      "\n",
      "Epoch 02101: val_loss did not improve from 0.00328\n",
      "Epoch 2102/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.6687e-05 - val_loss: 0.0092\n",
      "\n",
      "Epoch 02102: val_loss did not improve from 0.00328\n",
      "Epoch 2103/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 1.8869e-05 - val_loss: 0.0087\n",
      "\n",
      "Epoch 02103: val_loss did not improve from 0.00328\n",
      "Epoch 2104/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 1.8661e-05 - val_loss: 0.0085\n",
      "\n",
      "Epoch 02104: val_loss did not improve from 0.00328\n",
      "Epoch 2105/3000\n",
      "184/184 [==============================] - 0s 93us/step - loss: 2.1582e-05 - val_loss: 0.0087\n",
      "\n",
      "Epoch 02105: val_loss did not improve from 0.00328\n",
      "Epoch 2106/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.1321e-05 - val_loss: 0.0085\n",
      "\n",
      "Epoch 02106: val_loss did not improve from 0.00328\n",
      "Epoch 2107/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 1.9699e-05 - val_loss: 0.0082\n",
      "\n",
      "Epoch 02107: val_loss did not improve from 0.00328\n",
      "Epoch 2108/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.1445e-05 - val_loss: 0.0079\n",
      "\n",
      "Epoch 02108: val_loss did not improve from 0.00328\n",
      "Epoch 2109/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.1922e-05 - val_loss: 0.0081\n",
      "\n",
      "Epoch 02109: val_loss did not improve from 0.00328\n",
      "Epoch 2110/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.1704e-05 - val_loss: 0.0081\n",
      "\n",
      "Epoch 02110: val_loss did not improve from 0.00328\n",
      "Epoch 2111/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.2746e-05 - val_loss: 0.0084\n",
      "\n",
      "Epoch 02111: val_loss did not improve from 0.00328\n",
      "Epoch 2112/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.5909e-05 - val_loss: 0.0086\n",
      "\n",
      "Epoch 02112: val_loss did not improve from 0.00328\n",
      "Epoch 2113/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.2434e-05 - val_loss: 0.0084\n",
      "\n",
      "Epoch 02113: val_loss did not improve from 0.00328\n",
      "Epoch 2114/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.1526e-05 - val_loss: 0.0085\n",
      "\n",
      "Epoch 02114: val_loss did not improve from 0.00328\n",
      "Epoch 2115/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.1549e-05 - val_loss: 0.0088\n",
      "\n",
      "Epoch 02115: val_loss did not improve from 0.00328\n",
      "Epoch 2116/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.0780e-05 - val_loss: 0.0086\n",
      "\n",
      "Epoch 02116: val_loss did not improve from 0.00328\n",
      "Epoch 2117/3000\n",
      "184/184 [==============================] - 0s 120us/step - loss: 1.9232e-05 - val_loss: 0.0086\n",
      "\n",
      "Epoch 02117: val_loss did not improve from 0.00328\n",
      "Epoch 2118/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.4354e-05 - val_loss: 0.0088\n",
      "\n",
      "Epoch 02118: val_loss did not improve from 0.00328\n",
      "Epoch 2119/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 1.6469e-05 - val_loss: 0.0087\n",
      "\n",
      "Epoch 02119: val_loss did not improve from 0.00328\n",
      "Epoch 2120/3000\n",
      "184/184 [==============================] - 0s 93us/step - loss: 2.0331e-05 - val_loss: 0.0086\n",
      "\n",
      "Epoch 02120: val_loss did not improve from 0.00328\n",
      "Epoch 2121/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.5287e-05 - val_loss: 0.0085\n",
      "\n",
      "Epoch 02121: val_loss did not improve from 0.00328\n",
      "Epoch 2122/3000\n",
      "184/184 [==============================] - 0s 81us/step - loss: 2.0519e-05 - val_loss: 0.0084\n",
      "\n",
      "Epoch 02122: val_loss did not improve from 0.00328\n",
      "Epoch 2123/3000\n",
      "184/184 [==============================] - 0s 100us/step - loss: 2.2671e-05 - val_loss: 0.0084\n",
      "\n",
      "Epoch 02123: val_loss did not improve from 0.00328\n",
      "Epoch 2124/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.5207e-05 - val_loss: 0.0086\n",
      "\n",
      "Epoch 02124: val_loss did not improve from 0.00328\n",
      "Epoch 2125/3000\n",
      "184/184 [==============================] - 0s 101us/step - loss: 2.4025e-05 - val_loss: 0.0088\n",
      "\n",
      "Epoch 02125: val_loss did not improve from 0.00328\n",
      "Epoch 2126/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.6962e-05 - val_loss: 0.0085\n",
      "\n",
      "Epoch 02126: val_loss did not improve from 0.00328\n",
      "Epoch 2127/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.0171e-05 - val_loss: 0.0082\n",
      "\n",
      "Epoch 02127: val_loss did not improve from 0.00328\n",
      "Epoch 2128/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.5377e-05 - val_loss: 0.0082\n",
      "\n",
      "Epoch 02128: val_loss did not improve from 0.00328\n",
      "Epoch 2129/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 98us/step - loss: 2.0181e-05 - val_loss: 0.0084\n",
      "\n",
      "Epoch 02129: val_loss did not improve from 0.00328\n",
      "Epoch 2130/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 1.9345e-05 - val_loss: 0.0087\n",
      "\n",
      "Epoch 02130: val_loss did not improve from 0.00328\n",
      "Epoch 2131/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.1486e-05 - val_loss: 0.0084\n",
      "\n",
      "Epoch 02131: val_loss did not improve from 0.00328\n",
      "Epoch 2132/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.5760e-05 - val_loss: 0.0080\n",
      "\n",
      "Epoch 02132: val_loss did not improve from 0.00328\n",
      "Epoch 2133/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.5266e-05 - val_loss: 0.0078\n",
      "\n",
      "Epoch 02133: val_loss did not improve from 0.00328\n",
      "Epoch 2134/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.5055e-05 - val_loss: 0.0080\n",
      "\n",
      "Epoch 02134: val_loss did not improve from 0.00328\n",
      "Epoch 2135/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.1418e-05 - val_loss: 0.0083\n",
      "\n",
      "Epoch 02135: val_loss did not improve from 0.00328\n",
      "Epoch 2136/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.0979e-05 - val_loss: 0.0084\n",
      "\n",
      "Epoch 02136: val_loss did not improve from 0.00328\n",
      "Epoch 2137/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 1.9095e-05 - val_loss: 0.0084\n",
      "\n",
      "Epoch 02137: val_loss did not improve from 0.00328\n",
      "Epoch 2138/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.0154e-05 - val_loss: 0.0085\n",
      "\n",
      "Epoch 02138: val_loss did not improve from 0.00328\n",
      "Epoch 2139/3000\n",
      "184/184 [==============================] - 0s 179us/step - loss: 2.2367e-05 - val_loss: 0.0087\n",
      "\n",
      "Epoch 02139: val_loss did not improve from 0.00328\n",
      "Epoch 2140/3000\n",
      "184/184 [==============================] - 0s 130us/step - loss: 2.3786e-05 - val_loss: 0.0088\n",
      "\n",
      "Epoch 02140: val_loss did not improve from 0.00328\n",
      "Epoch 2141/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.0459e-05 - val_loss: 0.0088\n",
      "\n",
      "Epoch 02141: val_loss did not improve from 0.00328\n",
      "Epoch 2142/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 3.4131e-05 - val_loss: 0.0088\n",
      "\n",
      "Epoch 02142: val_loss did not improve from 0.00328\n",
      "Epoch 2143/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.3274e-05 - val_loss: 0.0087\n",
      "\n",
      "Epoch 02143: val_loss did not improve from 0.00328\n",
      "Epoch 2144/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.3184e-05 - val_loss: 0.0083\n",
      "\n",
      "Epoch 02144: val_loss did not improve from 0.00328\n",
      "Epoch 2145/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.5665e-05 - val_loss: 0.0081\n",
      "\n",
      "Epoch 02145: val_loss did not improve from 0.00328\n",
      "Epoch 2146/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.2600e-05 - val_loss: 0.0085\n",
      "\n",
      "Epoch 02146: val_loss did not improve from 0.00328\n",
      "Epoch 2147/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.3234e-05 - val_loss: 0.0086\n",
      "\n",
      "Epoch 02147: val_loss did not improve from 0.00328\n",
      "Epoch 2148/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.2620e-05 - val_loss: 0.0086\n",
      "\n",
      "Epoch 02148: val_loss did not improve from 0.00328\n",
      "Epoch 2149/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 1.7744e-05 - val_loss: 0.0086\n",
      "\n",
      "Epoch 02149: val_loss did not improve from 0.00328\n",
      "Epoch 2150/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.1521e-05 - val_loss: 0.0090\n",
      "\n",
      "Epoch 02150: val_loss did not improve from 0.00328\n",
      "Epoch 2151/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.6543e-05 - val_loss: 0.0093\n",
      "\n",
      "Epoch 02151: val_loss did not improve from 0.00328\n",
      "Epoch 2152/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.4964e-05 - val_loss: 0.0089\n",
      "\n",
      "Epoch 02152: val_loss did not improve from 0.00328\n",
      "Epoch 2153/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.1006e-05 - val_loss: 0.0086\n",
      "\n",
      "Epoch 02153: val_loss did not improve from 0.00328\n",
      "Epoch 2154/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.0928e-05 - val_loss: 0.0087\n",
      "\n",
      "Epoch 02154: val_loss did not improve from 0.00328\n",
      "Epoch 2155/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.4313e-05 - val_loss: 0.0088\n",
      "\n",
      "Epoch 02155: val_loss did not improve from 0.00328\n",
      "Epoch 2156/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.2410e-05 - val_loss: 0.0089\n",
      "\n",
      "Epoch 02156: val_loss did not improve from 0.00328\n",
      "Epoch 2157/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 1.9378e-05 - val_loss: 0.0088\n",
      "\n",
      "Epoch 02157: val_loss did not improve from 0.00328\n",
      "Epoch 2158/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 1.8655e-05 - val_loss: 0.0087\n",
      "\n",
      "Epoch 02158: val_loss did not improve from 0.00328\n",
      "Epoch 2159/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.9756e-05 - val_loss: 0.0088\n",
      "\n",
      "Epoch 02159: val_loss did not improve from 0.00328\n",
      "Epoch 2160/3000\n",
      "184/184 [==============================] - 0s 119us/step - loss: 2.2821e-05 - val_loss: 0.0090\n",
      "\n",
      "Epoch 02160: val_loss did not improve from 0.00328\n",
      "Epoch 2161/3000\n",
      "184/184 [==============================] - 0s 130us/step - loss: 2.0946e-05 - val_loss: 0.0090\n",
      "\n",
      "Epoch 02161: val_loss did not improve from 0.00328\n",
      "Epoch 2162/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.2241e-05 - val_loss: 0.0086\n",
      "\n",
      "Epoch 02162: val_loss did not improve from 0.00328\n",
      "Epoch 2163/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.9831e-05 - val_loss: 0.0085\n",
      "\n",
      "Epoch 02163: val_loss did not improve from 0.00328\n",
      "Epoch 2164/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.7990e-05 - val_loss: 0.0089\n",
      "\n",
      "Epoch 02164: val_loss did not improve from 0.00328\n",
      "Epoch 2165/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.2942e-05 - val_loss: 0.0090\n",
      "\n",
      "Epoch 02165: val_loss did not improve from 0.00328\n",
      "Epoch 2166/3000\n",
      "184/184 [==============================] - 0s 106us/step - loss: 2.6487e-05 - val_loss: 0.0088\n",
      "\n",
      "Epoch 02166: val_loss did not improve from 0.00328\n",
      "Epoch 2167/3000\n",
      "184/184 [==============================] - 0s 119us/step - loss: 2.6174e-05 - val_loss: 0.0088\n",
      "\n",
      "Epoch 02167: val_loss did not improve from 0.00328\n",
      "Epoch 2168/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 1.8068e-05 - val_loss: 0.0091\n",
      "\n",
      "Epoch 02168: val_loss did not improve from 0.00328\n",
      "Epoch 2169/3000\n",
      "184/184 [==============================] - 0s 96us/step - loss: 2.2052e-05 - val_loss: 0.0093\n",
      "\n",
      "Epoch 02169: val_loss did not improve from 0.00328\n",
      "Epoch 2170/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.6380e-05 - val_loss: 0.0089\n",
      "\n",
      "Epoch 02170: val_loss did not improve from 0.00328\n",
      "Epoch 2171/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.2063e-05 - val_loss: 0.0087\n",
      "\n",
      "Epoch 02171: val_loss did not improve from 0.00328\n",
      "Epoch 2172/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.0003e-05 - val_loss: 0.0088\n",
      "\n",
      "Epoch 02172: val_loss did not improve from 0.00328\n",
      "Epoch 2173/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 1.9354e-05 - val_loss: 0.0089\n",
      "\n",
      "Epoch 02173: val_loss did not improve from 0.00328\n",
      "Epoch 2174/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.6559e-05 - val_loss: 0.0086\n",
      "\n",
      "Epoch 02174: val_loss did not improve from 0.00328\n",
      "Epoch 2175/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.3682e-05 - val_loss: 0.0082\n",
      "\n",
      "Epoch 02175: val_loss did not improve from 0.00328\n",
      "Epoch 2176/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.0132e-05 - val_loss: 0.0084\n",
      "\n",
      "Epoch 02176: val_loss did not improve from 0.00328\n",
      "Epoch 2177/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.1307e-05 - val_loss: 0.0088\n",
      "\n",
      "Epoch 02177: val_loss did not improve from 0.00328\n",
      "Epoch 2178/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.7476e-05 - val_loss: 0.0087\n",
      "\n",
      "Epoch 02178: val_loss did not improve from 0.00328\n",
      "Epoch 2179/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 87us/step - loss: 2.0539e-05 - val_loss: 0.0084\n",
      "\n",
      "Epoch 02179: val_loss did not improve from 0.00328\n",
      "Epoch 2180/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.5770e-05 - val_loss: 0.0083\n",
      "\n",
      "Epoch 02180: val_loss did not improve from 0.00328\n",
      "Epoch 2181/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.6003e-05 - val_loss: 0.0088\n",
      "\n",
      "Epoch 02181: val_loss did not improve from 0.00328\n",
      "Epoch 2182/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.1404e-05 - val_loss: 0.0089\n",
      "\n",
      "Epoch 02182: val_loss did not improve from 0.00328\n",
      "Epoch 2183/3000\n",
      "184/184 [==============================] - 0s 119us/step - loss: 2.4851e-05 - val_loss: 0.0085\n",
      "\n",
      "Epoch 02183: val_loss did not improve from 0.00328\n",
      "Epoch 2184/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.3859e-05 - val_loss: 0.0084\n",
      "\n",
      "Epoch 02184: val_loss did not improve from 0.00328\n",
      "Epoch 2185/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.4516e-05 - val_loss: 0.0090\n",
      "\n",
      "Epoch 02185: val_loss did not improve from 0.00328\n",
      "Epoch 2186/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.2137e-05 - val_loss: 0.0093\n",
      "\n",
      "Epoch 02186: val_loss did not improve from 0.00328\n",
      "Epoch 2187/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.2968e-05 - val_loss: 0.0093\n",
      "\n",
      "Epoch 02187: val_loss did not improve from 0.00328\n",
      "Epoch 2188/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.3927e-05 - val_loss: 0.0088\n",
      "\n",
      "Epoch 02188: val_loss did not improve from 0.00328\n",
      "Epoch 2189/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.5121e-05 - val_loss: 0.0087\n",
      "\n",
      "Epoch 02189: val_loss did not improve from 0.00328\n",
      "Epoch 2190/3000\n",
      "184/184 [==============================] - ETA: 0s - loss: 1.4308e-0 - 0s 109us/step - loss: 2.7295e-05 - val_loss: 0.0088\n",
      "\n",
      "Epoch 02190: val_loss did not improve from 0.00328\n",
      "Epoch 2191/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.1779e-05 - val_loss: 0.0089\n",
      "\n",
      "Epoch 02191: val_loss did not improve from 0.00328\n",
      "Epoch 2192/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.1949e-05 - val_loss: 0.0090\n",
      "\n",
      "Epoch 02192: val_loss did not improve from 0.00328\n",
      "Epoch 2193/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.2216e-05 - val_loss: 0.0090\n",
      "\n",
      "Epoch 02193: val_loss did not improve from 0.00328\n",
      "Epoch 2194/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 1.9556e-05 - val_loss: 0.0091\n",
      "\n",
      "Epoch 02194: val_loss did not improve from 0.00328\n",
      "Epoch 2195/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 1.9241e-05 - val_loss: 0.0096\n",
      "\n",
      "Epoch 02195: val_loss did not improve from 0.00328\n",
      "Epoch 2196/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.5702e-05 - val_loss: 0.0096\n",
      "\n",
      "Epoch 02196: val_loss did not improve from 0.00328\n",
      "Epoch 2197/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 1.9235e-05 - val_loss: 0.0090\n",
      "\n",
      "Epoch 02197: val_loss did not improve from 0.00328\n",
      "Epoch 2198/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.7612e-05 - val_loss: 0.0089\n",
      "\n",
      "Epoch 02198: val_loss did not improve from 0.00328\n",
      "Epoch 2199/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.3267e-05 - val_loss: 0.0091\n",
      "\n",
      "Epoch 02199: val_loss did not improve from 0.00328\n",
      "Epoch 2200/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.0098e-05 - val_loss: 0.0091\n",
      "\n",
      "Epoch 02200: val_loss did not improve from 0.00328\n",
      "Epoch 2201/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 1.8101e-05 - val_loss: 0.0088\n",
      "\n",
      "Epoch 02201: val_loss did not improve from 0.00328\n",
      "Epoch 2202/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.2742e-05 - val_loss: 0.0086\n",
      "\n",
      "Epoch 02202: val_loss did not improve from 0.00328\n",
      "Epoch 2203/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.0552e-05 - val_loss: 0.0086\n",
      "\n",
      "Epoch 02203: val_loss did not improve from 0.00328\n",
      "Epoch 2204/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.6330e-05 - val_loss: 0.0086\n",
      "\n",
      "Epoch 02204: val_loss did not improve from 0.00328\n",
      "Epoch 2205/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 1.8118e-05 - val_loss: 0.0085\n",
      "\n",
      "Epoch 02205: val_loss did not improve from 0.00328\n",
      "Epoch 2206/3000\n",
      "184/184 [==============================] - 0s 130us/step - loss: 2.1907e-05 - val_loss: 0.0087\n",
      "\n",
      "Epoch 02206: val_loss did not improve from 0.00328\n",
      "Epoch 2207/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.1651e-05 - val_loss: 0.0092\n",
      "\n",
      "Epoch 02207: val_loss did not improve from 0.00328\n",
      "Epoch 2208/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.1548e-05 - val_loss: 0.0092\n",
      "\n",
      "Epoch 02208: val_loss did not improve from 0.00328\n",
      "Epoch 2209/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 1.9274e-05 - val_loss: 0.0090\n",
      "\n",
      "Epoch 02209: val_loss did not improve from 0.00328\n",
      "Epoch 2210/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.1331e-05 - val_loss: 0.0086\n",
      "\n",
      "Epoch 02210: val_loss did not improve from 0.00328\n",
      "Epoch 2211/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.7766e-05 - val_loss: 0.0085\n",
      "\n",
      "Epoch 02211: val_loss did not improve from 0.00328\n",
      "Epoch 2212/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.0521e-05 - val_loss: 0.0090\n",
      "\n",
      "Epoch 02212: val_loss did not improve from 0.00328\n",
      "Epoch 2213/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.5857e-05 - val_loss: 0.0092\n",
      "\n",
      "Epoch 02213: val_loss did not improve from 0.00328\n",
      "Epoch 2214/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.1666e-05 - val_loss: 0.0088\n",
      "\n",
      "Epoch 02214: val_loss did not improve from 0.00328\n",
      "Epoch 2215/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.7593e-05 - val_loss: 0.0087\n",
      "\n",
      "Epoch 02215: val_loss did not improve from 0.00328\n",
      "Epoch 2216/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.4804e-05 - val_loss: 0.0093\n",
      "\n",
      "Epoch 02216: val_loss did not improve from 0.00328\n",
      "Epoch 2217/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.0650e-05 - val_loss: 0.0095\n",
      "\n",
      "Epoch 02217: val_loss did not improve from 0.00328\n",
      "Epoch 2218/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 3.0909e-05 - val_loss: 0.0091\n",
      "\n",
      "Epoch 02218: val_loss did not improve from 0.00328\n",
      "Epoch 2219/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.7484e-05 - val_loss: 0.0088\n",
      "\n",
      "Epoch 02219: val_loss did not improve from 0.00328\n",
      "Epoch 2220/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.3433e-05 - val_loss: 0.0093\n",
      "\n",
      "Epoch 02220: val_loss did not improve from 0.00328\n",
      "Epoch 2221/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 1.8651e-05 - val_loss: 0.0095\n",
      "\n",
      "Epoch 02221: val_loss did not improve from 0.00328\n",
      "Epoch 2222/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.4748e-05 - val_loss: 0.0090\n",
      "\n",
      "Epoch 02222: val_loss did not improve from 0.00328\n",
      "Epoch 2223/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.1502e-05 - val_loss: 0.0086\n",
      "\n",
      "Epoch 02223: val_loss did not improve from 0.00328\n",
      "Epoch 2224/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.2989e-05 - val_loss: 0.0086\n",
      "\n",
      "Epoch 02224: val_loss did not improve from 0.00328\n",
      "Epoch 2225/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.3679e-05 - val_loss: 0.0089\n",
      "\n",
      "Epoch 02225: val_loss did not improve from 0.00328\n",
      "Epoch 2226/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.0136e-05 - val_loss: 0.0090\n",
      "\n",
      "Epoch 02226: val_loss did not improve from 0.00328\n",
      "Epoch 2227/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 1.7779e-05 - val_loss: 0.0089\n",
      "\n",
      "Epoch 02227: val_loss did not improve from 0.00328\n",
      "Epoch 2228/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.0183e-05 - val_loss: 0.0088\n",
      "\n",
      "Epoch 02228: val_loss did not improve from 0.00328\n",
      "Epoch 2229/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 163us/step - loss: 2.3819e-05 - val_loss: 0.0090\n",
      "\n",
      "Epoch 02229: val_loss did not improve from 0.00328\n",
      "Epoch 2230/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 1.9776e-05 - val_loss: 0.0089\n",
      "\n",
      "Epoch 02230: val_loss did not improve from 0.00328\n",
      "Epoch 2231/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 1.7235e-05 - val_loss: 0.0090\n",
      "\n",
      "Epoch 02231: val_loss did not improve from 0.00328\n",
      "Epoch 2232/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.3000e-05 - val_loss: 0.0093\n",
      "\n",
      "Epoch 02232: val_loss did not improve from 0.00328\n",
      "Epoch 2233/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 1.9794e-05 - val_loss: 0.0093\n",
      "\n",
      "Epoch 02233: val_loss did not improve from 0.00328\n",
      "Epoch 2234/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.0159e-05 - val_loss: 0.0092\n",
      "\n",
      "Epoch 02234: val_loss did not improve from 0.00328\n",
      "Epoch 2235/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 1.9867e-05 - val_loss: 0.0091\n",
      "\n",
      "Epoch 02235: val_loss did not improve from 0.00328\n",
      "Epoch 2236/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 1.5200e-05 - val_loss: 0.0089\n",
      "\n",
      "Epoch 02236: val_loss did not improve from 0.00328\n",
      "Epoch 2237/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.6143e-05 - val_loss: 0.0089\n",
      "\n",
      "Epoch 02237: val_loss did not improve from 0.00328\n",
      "Epoch 2238/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.2587e-05 - val_loss: 0.0092\n",
      "\n",
      "Epoch 02238: val_loss did not improve from 0.00328\n",
      "Epoch 2239/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.3859e-05 - val_loss: 0.0089\n",
      "\n",
      "Epoch 02239: val_loss did not improve from 0.00328\n",
      "Epoch 2240/3000\n",
      "184/184 [==============================] - 0s 120us/step - loss: 2.1226e-05 - val_loss: 0.0087\n",
      "\n",
      "Epoch 02240: val_loss did not improve from 0.00328\n",
      "Epoch 2241/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.3423e-05 - val_loss: 0.0089\n",
      "\n",
      "Epoch 02241: val_loss did not improve from 0.00328\n",
      "Epoch 2242/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 1.8876e-05 - val_loss: 0.0095\n",
      "\n",
      "Epoch 02242: val_loss did not improve from 0.00328\n",
      "Epoch 2243/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.9959e-05 - val_loss: 0.0099\n",
      "\n",
      "Epoch 02243: val_loss did not improve from 0.00328\n",
      "Epoch 2244/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.6999e-05 - val_loss: 0.0096\n",
      "\n",
      "Epoch 02244: val_loss did not improve from 0.00328\n",
      "Epoch 2245/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.2813e-05 - val_loss: 0.0090\n",
      "\n",
      "Epoch 02245: val_loss did not improve from 0.00328\n",
      "Epoch 2246/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.6820e-05 - val_loss: 0.0091\n",
      "\n",
      "Epoch 02246: val_loss did not improve from 0.00328\n",
      "Epoch 2247/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.3039e-05 - val_loss: 0.0095\n",
      "\n",
      "Epoch 02247: val_loss did not improve from 0.00328\n",
      "Epoch 2248/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.8445e-05 - val_loss: 0.0093\n",
      "\n",
      "Epoch 02248: val_loss did not improve from 0.00328\n",
      "Epoch 2249/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 1.6636e-05 - val_loss: 0.0087\n",
      "\n",
      "Epoch 02249: val_loss did not improve from 0.00328\n",
      "Epoch 2250/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.5399e-05 - val_loss: 0.0085\n",
      "\n",
      "Epoch 02250: val_loss did not improve from 0.00328\n",
      "Epoch 2251/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.2779e-05 - val_loss: 0.0089\n",
      "\n",
      "Epoch 02251: val_loss did not improve from 0.00328\n",
      "Epoch 2252/3000\n",
      "184/184 [==============================] - 0s 141us/step - loss: 2.5300e-05 - val_loss: 0.0094\n",
      "\n",
      "Epoch 02252: val_loss did not improve from 0.00328\n",
      "Epoch 2253/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.2865e-05 - val_loss: 0.0093\n",
      "\n",
      "Epoch 02253: val_loss did not improve from 0.00328\n",
      "Epoch 2254/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.2953e-05 - val_loss: 0.0089\n",
      "\n",
      "Epoch 02254: val_loss did not improve from 0.00328\n",
      "Epoch 2255/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.1288e-05 - val_loss: 0.0089\n",
      "\n",
      "Epoch 02255: val_loss did not improve from 0.00328\n",
      "Epoch 2256/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.2280e-05 - val_loss: 0.0091\n",
      "\n",
      "Epoch 02256: val_loss did not improve from 0.00328\n",
      "Epoch 2257/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 1.9134e-05 - val_loss: 0.0091\n",
      "\n",
      "Epoch 02257: val_loss did not improve from 0.00328\n",
      "Epoch 2258/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 1.9872e-05 - val_loss: 0.0087\n",
      "\n",
      "Epoch 02258: val_loss did not improve from 0.00328\n",
      "Epoch 2259/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.4296e-05 - val_loss: 0.0087\n",
      "\n",
      "Epoch 02259: val_loss did not improve from 0.00328\n",
      "Epoch 2260/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.0618e-05 - val_loss: 0.0088\n",
      "\n",
      "Epoch 02260: val_loss did not improve from 0.00328\n",
      "Epoch 2261/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.3445e-05 - val_loss: 0.0089\n",
      "\n",
      "Epoch 02261: val_loss did not improve from 0.00328\n",
      "Epoch 2262/3000\n",
      "184/184 [==============================] - 0s 81us/step - loss: 2.3948e-05 - val_loss: 0.0088\n",
      "\n",
      "Epoch 02262: val_loss did not improve from 0.00328\n",
      "Epoch 2263/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 1.9960e-05 - val_loss: 0.0088\n",
      "\n",
      "Epoch 02263: val_loss did not improve from 0.00328\n",
      "Epoch 2264/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.6609e-05 - val_loss: 0.0090\n",
      "\n",
      "Epoch 02264: val_loss did not improve from 0.00328\n",
      "Epoch 2265/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.2267e-05 - val_loss: 0.0091\n",
      "\n",
      "Epoch 02265: val_loss did not improve from 0.00328\n",
      "Epoch 2266/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.3184e-05 - val_loss: 0.0091\n",
      "\n",
      "Epoch 02266: val_loss did not improve from 0.00328\n",
      "Epoch 2267/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.2472e-05 - val_loss: 0.0091\n",
      "\n",
      "Epoch 02267: val_loss did not improve from 0.00328\n",
      "Epoch 2268/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 1.8610e-05 - val_loss: 0.0091\n",
      "\n",
      "Epoch 02268: val_loss did not improve from 0.00328\n",
      "Epoch 2269/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.1518e-05 - val_loss: 0.0093\n",
      "\n",
      "Epoch 02269: val_loss did not improve from 0.00328\n",
      "Epoch 2270/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.0769e-05 - val_loss: 0.0093\n",
      "\n",
      "Epoch 02270: val_loss did not improve from 0.00328\n",
      "Epoch 2271/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.2473e-05 - val_loss: 0.0093\n",
      "\n",
      "Epoch 02271: val_loss did not improve from 0.00328\n",
      "Epoch 2272/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 1.9622e-05 - val_loss: 0.0093\n",
      "\n",
      "Epoch 02272: val_loss did not improve from 0.00328\n",
      "Epoch 2273/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.4496e-05 - val_loss: 0.0092\n",
      "\n",
      "Epoch 02273: val_loss did not improve from 0.00328\n",
      "Epoch 2274/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.4212e-05 - val_loss: 0.0092\n",
      "\n",
      "Epoch 02274: val_loss did not improve from 0.00328\n",
      "Epoch 2275/3000\n",
      "184/184 [==============================] - 0s 130us/step - loss: 2.5337e-05 - val_loss: 0.0091\n",
      "\n",
      "Epoch 02275: val_loss did not improve from 0.00328\n",
      "Epoch 2276/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 1.7573e-05 - val_loss: 0.0092\n",
      "\n",
      "Epoch 02276: val_loss did not improve from 0.00328\n",
      "Epoch 2277/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 1.7959e-05 - val_loss: 0.0091\n",
      "\n",
      "Epoch 02277: val_loss did not improve from 0.00328\n",
      "Epoch 2278/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.1408e-05 - val_loss: 0.0088\n",
      "\n",
      "Epoch 02278: val_loss did not improve from 0.00328\n",
      "Epoch 2279/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 1.9314e-05 - val_loss: 0.0086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 02279: val_loss did not improve from 0.00328\n",
      "Epoch 2280/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.0960e-05 - val_loss: 0.0084\n",
      "\n",
      "Epoch 02280: val_loss did not improve from 0.00328\n",
      "Epoch 2281/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.2536e-05 - val_loss: 0.0084\n",
      "\n",
      "Epoch 02281: val_loss did not improve from 0.00328\n",
      "Epoch 2282/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.3864e-05 - val_loss: 0.0085\n",
      "\n",
      "Epoch 02282: val_loss did not improve from 0.00328\n",
      "Epoch 2283/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.4553e-05 - val_loss: 0.0086\n",
      "\n",
      "Epoch 02283: val_loss did not improve from 0.00328\n",
      "Epoch 2284/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.2044e-05 - val_loss: 0.0089\n",
      "\n",
      "Epoch 02284: val_loss did not improve from 0.00328\n",
      "Epoch 2285/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 1.9461e-05 - val_loss: 0.0090\n",
      "\n",
      "Epoch 02285: val_loss did not improve from 0.00328\n",
      "Epoch 2286/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 1.6363e-05 - val_loss: 0.0087\n",
      "\n",
      "Epoch 02286: val_loss did not improve from 0.00328\n",
      "Epoch 2287/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.2045e-05 - val_loss: 0.0087\n",
      "\n",
      "Epoch 02287: val_loss did not improve from 0.00328\n",
      "Epoch 2288/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.2908e-05 - val_loss: 0.0089\n",
      "\n",
      "Epoch 02288: val_loss did not improve from 0.00328\n",
      "Epoch 2289/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.0242e-05 - val_loss: 0.0091\n",
      "\n",
      "Epoch 02289: val_loss did not improve from 0.00328\n",
      "Epoch 2290/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.3432e-05 - val_loss: 0.0089\n",
      "\n",
      "Epoch 02290: val_loss did not improve from 0.00328\n",
      "Epoch 2291/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.3228e-05 - val_loss: 0.0089\n",
      "\n",
      "Epoch 02291: val_loss did not improve from 0.00328\n",
      "Epoch 2292/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.4913e-05 - val_loss: 0.0091\n",
      "\n",
      "Epoch 02292: val_loss did not improve from 0.00328\n",
      "Epoch 2293/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 2.1361e-05 - val_loss: 0.0092\n",
      "\n",
      "Epoch 02293: val_loss did not improve from 0.00328\n",
      "Epoch 2294/3000\n",
      "184/184 [==============================] - 0s 133us/step - loss: 1.8178e-05 - val_loss: 0.0090\n",
      "\n",
      "Epoch 02294: val_loss did not improve from 0.00328\n",
      "Epoch 2295/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 1.8541e-05 - val_loss: 0.0092\n",
      "\n",
      "Epoch 02295: val_loss did not improve from 0.00328\n",
      "Epoch 2296/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.4192e-05 - val_loss: 0.0093\n",
      "\n",
      "Epoch 02296: val_loss did not improve from 0.00328\n",
      "Epoch 2297/3000\n",
      "184/184 [==============================] - 0s 119us/step - loss: 2.4449e-05 - val_loss: 0.0091\n",
      "\n",
      "Epoch 02297: val_loss did not improve from 0.00328\n",
      "Epoch 2298/3000\n",
      "184/184 [==============================] - 0s 120us/step - loss: 2.2396e-05 - val_loss: 0.0091\n",
      "\n",
      "Epoch 02298: val_loss did not improve from 0.00328\n",
      "Epoch 2299/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.3160e-05 - val_loss: 0.0089\n",
      "\n",
      "Epoch 02299: val_loss did not improve from 0.00328\n",
      "Epoch 2300/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.6987e-05 - val_loss: 0.0090\n",
      "\n",
      "Epoch 02300: val_loss did not improve from 0.00328\n",
      "Epoch 2301/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.2604e-05 - val_loss: 0.0093\n",
      "\n",
      "Epoch 02301: val_loss did not improve from 0.00328\n",
      "Epoch 2302/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 1.8033e-05 - val_loss: 0.0090\n",
      "\n",
      "Epoch 02302: val_loss did not improve from 0.00328\n",
      "Epoch 2303/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.1182e-05 - val_loss: 0.0087\n",
      "\n",
      "Epoch 02303: val_loss did not improve from 0.00328\n",
      "Epoch 2304/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.0561e-05 - val_loss: 0.0089\n",
      "\n",
      "Epoch 02304: val_loss did not improve from 0.00328\n",
      "Epoch 2305/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.1623e-05 - val_loss: 0.0095\n",
      "\n",
      "Epoch 02305: val_loss did not improve from 0.00328\n",
      "Epoch 2306/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.3568e-05 - val_loss: 0.0097\n",
      "\n",
      "Epoch 02306: val_loss did not improve from 0.00328\n",
      "Epoch 2307/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.1204e-05 - val_loss: 0.0091\n",
      "\n",
      "Epoch 02307: val_loss did not improve from 0.00328\n",
      "Epoch 2308/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.5364e-05 - val_loss: 0.0089\n",
      "\n",
      "Epoch 02308: val_loss did not improve from 0.00328\n",
      "Epoch 2309/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.8665e-05 - val_loss: 0.0092\n",
      "\n",
      "Epoch 02309: val_loss did not improve from 0.00328\n",
      "Epoch 2310/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.1531e-05 - val_loss: 0.0096\n",
      "\n",
      "Epoch 02310: val_loss did not improve from 0.00328\n",
      "Epoch 2311/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.1267e-05 - val_loss: 0.0095\n",
      "\n",
      "Epoch 02311: val_loss did not improve from 0.00328\n",
      "Epoch 2312/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.3266e-05 - val_loss: 0.0093\n",
      "\n",
      "Epoch 02312: val_loss did not improve from 0.00328\n",
      "Epoch 2313/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.1779e-05 - val_loss: 0.0093\n",
      "\n",
      "Epoch 02313: val_loss did not improve from 0.00328\n",
      "Epoch 2314/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.3795e-05 - val_loss: 0.0091\n",
      "\n",
      "Epoch 02314: val_loss did not improve from 0.00328\n",
      "Epoch 2315/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 1.8183e-05 - val_loss: 0.0092\n",
      "\n",
      "Epoch 02315: val_loss did not improve from 0.00328\n",
      "Epoch 2316/3000\n",
      "184/184 [==============================] - 0s 108us/step - loss: 2.7531e-05 - val_loss: 0.0090\n",
      "\n",
      "Epoch 02316: val_loss did not improve from 0.00328\n",
      "Epoch 2317/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 1.9583e-05 - val_loss: 0.0088\n",
      "\n",
      "Epoch 02317: val_loss did not improve from 0.00328\n",
      "Epoch 2318/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.3289e-05 - val_loss: 0.0089\n",
      "\n",
      "Epoch 02318: val_loss did not improve from 0.00328\n",
      "Epoch 2319/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.7116e-05 - val_loss: 0.0092\n",
      "\n",
      "Epoch 02319: val_loss did not improve from 0.00328\n",
      "Epoch 2320/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.3617e-05 - val_loss: 0.0094\n",
      "\n",
      "Epoch 02320: val_loss did not improve from 0.00328\n",
      "Epoch 2321/3000\n",
      "184/184 [==============================] - 0s 147us/step - loss: 1.9387e-05 - val_loss: 0.0093\n",
      "\n",
      "Epoch 02321: val_loss did not improve from 0.00328\n",
      "Epoch 2322/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.4157e-05 - val_loss: 0.0092\n",
      "\n",
      "Epoch 02322: val_loss did not improve from 0.00328\n",
      "Epoch 2323/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.5513e-05 - val_loss: 0.0095\n",
      "\n",
      "Epoch 02323: val_loss did not improve from 0.00328\n",
      "Epoch 2324/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.1763e-05 - val_loss: 0.0096\n",
      "\n",
      "Epoch 02324: val_loss did not improve from 0.00328\n",
      "Epoch 2325/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 1.9556e-05 - val_loss: 0.0093\n",
      "\n",
      "Epoch 02325: val_loss did not improve from 0.00328\n",
      "Epoch 2326/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.7447e-05 - val_loss: 0.0092\n",
      "\n",
      "Epoch 02326: val_loss did not improve from 0.00328\n",
      "Epoch 2327/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.5439e-05 - val_loss: 0.0090\n",
      "\n",
      "Epoch 02327: val_loss did not improve from 0.00328\n",
      "Epoch 2328/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.8074e-05 - val_loss: 0.0092\n",
      "\n",
      "Epoch 02328: val_loss did not improve from 0.00328\n",
      "Epoch 2329/3000\n",
      "184/184 [==============================] - 0s 97us/step - loss: 2.2440e-05 - val_loss: 0.0099\n",
      "\n",
      "Epoch 02329: val_loss did not improve from 0.00328\n",
      "Epoch 2330/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 109us/step - loss: 2.5208e-05 - val_loss: 0.0098\n",
      "\n",
      "Epoch 02330: val_loss did not improve from 0.00328\n",
      "Epoch 2331/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 1.9524e-05 - val_loss: 0.0093\n",
      "\n",
      "Epoch 02331: val_loss did not improve from 0.00328\n",
      "Epoch 2332/3000\n",
      "184/184 [==============================] - 0s 130us/step - loss: 2.6143e-05 - val_loss: 0.0092\n",
      "\n",
      "Epoch 02332: val_loss did not improve from 0.00328\n",
      "Epoch 2333/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.7193e-05 - val_loss: 0.0092\n",
      "\n",
      "Epoch 02333: val_loss did not improve from 0.00328\n",
      "Epoch 2334/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.0965e-05 - val_loss: 0.0091\n",
      "\n",
      "Epoch 02334: val_loss did not improve from 0.00328\n",
      "Epoch 2335/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 1.9505e-05 - val_loss: 0.0090\n",
      "\n",
      "Epoch 02335: val_loss did not improve from 0.00328\n",
      "Epoch 2336/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.5548e-05 - val_loss: 0.0091\n",
      "\n",
      "Epoch 02336: val_loss did not improve from 0.00328\n",
      "Epoch 2337/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 1.9847e-05 - val_loss: 0.0093\n",
      "\n",
      "Epoch 02337: val_loss did not improve from 0.00328\n",
      "Epoch 2338/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 1.8100e-05 - val_loss: 0.0091\n",
      "\n",
      "Epoch 02338: val_loss did not improve from 0.00328\n",
      "Epoch 2339/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.1224e-05 - val_loss: 0.0093\n",
      "\n",
      "Epoch 02339: val_loss did not improve from 0.00328\n",
      "Epoch 2340/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 1.8360e-05 - val_loss: 0.0098\n",
      "\n",
      "Epoch 02340: val_loss did not improve from 0.00328\n",
      "Epoch 2341/3000\n",
      "184/184 [==============================] - 0s 223us/step - loss: 1.7988e-05 - val_loss: 0.0098\n",
      "\n",
      "Epoch 02341: val_loss did not improve from 0.00328\n",
      "Epoch 2342/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.1916e-05 - val_loss: 0.0094\n",
      "\n",
      "Epoch 02342: val_loss did not improve from 0.00328\n",
      "Epoch 2343/3000\n",
      "184/184 [==============================] - 0s 120us/step - loss: 2.2042e-05 - val_loss: 0.0094\n",
      "\n",
      "Epoch 02343: val_loss did not improve from 0.00328\n",
      "Epoch 2344/3000\n",
      "184/184 [==============================] - 0s 119us/step - loss: 3.0490e-05 - val_loss: 0.0098\n",
      "\n",
      "Epoch 02344: val_loss did not improve from 0.00328\n",
      "Epoch 2345/3000\n",
      "184/184 [==============================] - 0s 163us/step - loss: 2.4955e-05 - val_loss: 0.0095\n",
      "\n",
      "Epoch 02345: val_loss did not improve from 0.00328\n",
      "Epoch 2346/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.1945e-05 - val_loss: 0.0090\n",
      "\n",
      "Epoch 02346: val_loss did not improve from 0.00328\n",
      "Epoch 2347/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.0950e-05 - val_loss: 0.0089\n",
      "\n",
      "Epoch 02347: val_loss did not improve from 0.00328\n",
      "Epoch 2348/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.3269e-05 - val_loss: 0.0092\n",
      "\n",
      "Epoch 02348: val_loss did not improve from 0.00328\n",
      "Epoch 2349/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 1.7698e-05 - val_loss: 0.0098\n",
      "\n",
      "Epoch 02349: val_loss did not improve from 0.00328\n",
      "Epoch 2350/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.2914e-05 - val_loss: 0.0098\n",
      "\n",
      "Epoch 02350: val_loss did not improve from 0.00328\n",
      "Epoch 2351/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 1.6718e-05 - val_loss: 0.0094\n",
      "\n",
      "Epoch 02351: val_loss did not improve from 0.00328\n",
      "Epoch 2352/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.2156e-05 - val_loss: 0.0092\n",
      "\n",
      "Epoch 02352: val_loss did not improve from 0.00328\n",
      "Epoch 2353/3000\n",
      "184/184 [==============================] - 0s 119us/step - loss: 1.9924e-05 - val_loss: 0.0093\n",
      "\n",
      "Epoch 02353: val_loss did not improve from 0.00328\n",
      "Epoch 2354/3000\n",
      "184/184 [==============================] - 0s 119us/step - loss: 2.2696e-05 - val_loss: 0.0095\n",
      "\n",
      "Epoch 02354: val_loss did not improve from 0.00328\n",
      "Epoch 2355/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.3693e-05 - val_loss: 0.0092\n",
      "\n",
      "Epoch 02355: val_loss did not improve from 0.00328\n",
      "Epoch 2356/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 1.8253e-05 - val_loss: 0.0089\n",
      "\n",
      "Epoch 02356: val_loss did not improve from 0.00328\n",
      "Epoch 2357/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.0810e-05 - val_loss: 0.0091\n",
      "\n",
      "Epoch 02357: val_loss did not improve from 0.00328\n",
      "Epoch 2358/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.1250e-05 - val_loss: 0.0094\n",
      "\n",
      "Epoch 02358: val_loss did not improve from 0.00328\n",
      "Epoch 2359/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.6396e-05 - val_loss: 0.0094\n",
      "\n",
      "Epoch 02359: val_loss did not improve from 0.00328\n",
      "Epoch 2360/3000\n",
      "184/184 [==============================] - ETA: 0s - loss: 1.0879e-0 - 0s 114us/step - loss: 2.5374e-05 - val_loss: 0.0092\n",
      "\n",
      "Epoch 02360: val_loss did not improve from 0.00328\n",
      "Epoch 2361/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.0796e-05 - val_loss: 0.0091\n",
      "\n",
      "Epoch 02361: val_loss did not improve from 0.00328\n",
      "Epoch 2362/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.4780e-05 - val_loss: 0.0091\n",
      "\n",
      "Epoch 02362: val_loss did not improve from 0.00328\n",
      "Epoch 2363/3000\n",
      "184/184 [==============================] - 0s 147us/step - loss: 2.1508e-05 - val_loss: 0.0096\n",
      "\n",
      "Epoch 02363: val_loss did not improve from 0.00328\n",
      "Epoch 2364/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.2015e-05 - val_loss: 0.0099\n",
      "\n",
      "Epoch 02364: val_loss did not improve from 0.00328\n",
      "Epoch 2365/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.3403e-05 - val_loss: 0.0093\n",
      "\n",
      "Epoch 02365: val_loss did not improve from 0.00328\n",
      "Epoch 2366/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.5171e-05 - val_loss: 0.0088\n",
      "\n",
      "Epoch 02366: val_loss did not improve from 0.00328\n",
      "Epoch 2367/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.4441e-05 - val_loss: 0.0091\n",
      "\n",
      "Epoch 02367: val_loss did not improve from 0.00328\n",
      "Epoch 2368/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.2362e-05 - val_loss: 0.0094\n",
      "\n",
      "Epoch 02368: val_loss did not improve from 0.00328\n",
      "Epoch 2369/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.8252e-05 - val_loss: 0.0093\n",
      "\n",
      "Epoch 02369: val_loss did not improve from 0.00328\n",
      "Epoch 2370/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 1.8737e-05 - val_loss: 0.0090\n",
      "\n",
      "Epoch 02370: val_loss did not improve from 0.00328\n",
      "Epoch 2371/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.4452e-05 - val_loss: 0.0090\n",
      "\n",
      "Epoch 02371: val_loss did not improve from 0.00328\n",
      "Epoch 2372/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.4402e-05 - val_loss: 0.0090\n",
      "\n",
      "Epoch 02372: val_loss did not improve from 0.00328\n",
      "Epoch 2373/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.3264e-05 - val_loss: 0.0089\n",
      "\n",
      "Epoch 02373: val_loss did not improve from 0.00328\n",
      "Epoch 2374/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.1647e-05 - val_loss: 0.0090\n",
      "\n",
      "Epoch 02374: val_loss did not improve from 0.00328\n",
      "Epoch 2375/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.5823e-05 - val_loss: 0.0091\n",
      "\n",
      "Epoch 02375: val_loss did not improve from 0.00328\n",
      "Epoch 2376/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.0135e-05 - val_loss: 0.0090\n",
      "\n",
      "Epoch 02376: val_loss did not improve from 0.00328\n",
      "Epoch 2377/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.4206e-05 - val_loss: 0.0090\n",
      "\n",
      "Epoch 02377: val_loss did not improve from 0.00328\n",
      "Epoch 2378/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.3546e-05 - val_loss: 0.0091\n",
      "\n",
      "Epoch 02378: val_loss did not improve from 0.00328\n",
      "Epoch 2379/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.0222e-05 - val_loss: 0.0092\n",
      "\n",
      "Epoch 02379: val_loss did not improve from 0.00328\n",
      "Epoch 2380/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 103us/step - loss: 2.0352e-05 - val_loss: 0.0093\n",
      "\n",
      "Epoch 02380: val_loss did not improve from 0.00328\n",
      "Epoch 2381/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.0172e-05 - val_loss: 0.0091\n",
      "\n",
      "Epoch 02381: val_loss did not improve from 0.00328\n",
      "Epoch 2382/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 1.9701e-05 - val_loss: 0.0092\n",
      "\n",
      "Epoch 02382: val_loss did not improve from 0.00328\n",
      "Epoch 2383/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 1.9681e-05 - val_loss: 0.0092\n",
      "\n",
      "Epoch 02383: val_loss did not improve from 0.00328\n",
      "Epoch 2384/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.0535e-05 - val_loss: 0.0091\n",
      "\n",
      "Epoch 02384: val_loss did not improve from 0.00328\n",
      "Epoch 2385/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.7146e-05 - val_loss: 0.0090\n",
      "\n",
      "Epoch 02385: val_loss did not improve from 0.00328\n",
      "Epoch 2386/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 1.7566e-05 - val_loss: 0.0090\n",
      "\n",
      "Epoch 02386: val_loss did not improve from 0.00328\n",
      "Epoch 2387/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.3183e-05 - val_loss: 0.0091\n",
      "\n",
      "Epoch 02387: val_loss did not improve from 0.00328\n",
      "Epoch 2388/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.5375e-05 - val_loss: 0.0091\n",
      "\n",
      "Epoch 02388: val_loss did not improve from 0.00328\n",
      "Epoch 2389/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 1.8664e-05 - val_loss: 0.0095\n",
      "\n",
      "Epoch 02389: val_loss did not improve from 0.00328\n",
      "Epoch 2390/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.2892e-05 - val_loss: 0.0097\n",
      "\n",
      "Epoch 02390: val_loss did not improve from 0.00328\n",
      "Epoch 2391/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.2136e-05 - val_loss: 0.0095\n",
      "\n",
      "Epoch 02391: val_loss did not improve from 0.00328\n",
      "Epoch 2392/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 1.7238e-05 - val_loss: 0.0093\n",
      "\n",
      "Epoch 02392: val_loss did not improve from 0.00328\n",
      "Epoch 2393/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.5322e-05 - val_loss: 0.0095\n",
      "\n",
      "Epoch 02393: val_loss did not improve from 0.00328\n",
      "Epoch 2394/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.1852e-05 - val_loss: 0.0100\n",
      "\n",
      "Epoch 02394: val_loss did not improve from 0.00328\n",
      "Epoch 2395/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.5144e-05 - val_loss: 0.0097\n",
      "\n",
      "Epoch 02395: val_loss did not improve from 0.00328\n",
      "Epoch 2396/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.1996e-05 - val_loss: 0.0092\n",
      "\n",
      "Epoch 02396: val_loss did not improve from 0.00328\n",
      "Epoch 2397/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.1474e-05 - val_loss: 0.0094\n",
      "\n",
      "Epoch 02397: val_loss did not improve from 0.00328\n",
      "Epoch 2398/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 1.9802e-05 - val_loss: 0.0099\n",
      "\n",
      "Epoch 02398: val_loss did not improve from 0.00328\n",
      "Epoch 2399/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.2521e-05 - val_loss: 0.0104\n",
      "\n",
      "Epoch 02399: val_loss did not improve from 0.00328\n",
      "Epoch 2400/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.0838e-05 - val_loss: 0.0101\n",
      "\n",
      "Epoch 02400: val_loss did not improve from 0.00328\n",
      "Epoch 2401/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 1.7822e-05 - val_loss: 0.0094\n",
      "\n",
      "Epoch 02401: val_loss did not improve from 0.00328\n",
      "Epoch 2402/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.4687e-05 - val_loss: 0.0094\n",
      "\n",
      "Epoch 02402: val_loss did not improve from 0.00328\n",
      "Epoch 2403/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.0067e-05 - val_loss: 0.0099\n",
      "\n",
      "Epoch 02403: val_loss did not improve from 0.00328\n",
      "Epoch 2404/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 1.9738e-05 - val_loss: 0.0099\n",
      "\n",
      "Epoch 02404: val_loss did not improve from 0.00328\n",
      "Epoch 2405/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.2460e-05 - val_loss: 0.0095\n",
      "\n",
      "Epoch 02405: val_loss did not improve from 0.00328\n",
      "Epoch 2406/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.3632e-05 - val_loss: 0.0090\n",
      "\n",
      "Epoch 02406: val_loss did not improve from 0.00328\n",
      "Epoch 2407/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.4819e-05 - val_loss: 0.0091\n",
      "\n",
      "Epoch 02407: val_loss did not improve from 0.00328\n",
      "Epoch 2408/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.3559e-05 - val_loss: 0.0094\n",
      "\n",
      "Epoch 02408: val_loss did not improve from 0.00328\n",
      "Epoch 2409/3000\n",
      "184/184 [==============================] - 0s 163us/step - loss: 2.2232e-05 - val_loss: 0.0095\n",
      "\n",
      "Epoch 02409: val_loss did not improve from 0.00328\n",
      "Epoch 2410/3000\n",
      "184/184 [==============================] - 0s 119us/step - loss: 1.9912e-05 - val_loss: 0.0095\n",
      "\n",
      "Epoch 02410: val_loss did not improve from 0.00328\n",
      "Epoch 2411/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 1.9941e-05 - val_loss: 0.0094\n",
      "\n",
      "Epoch 02411: val_loss did not improve from 0.00328\n",
      "Epoch 2412/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.6635e-05 - val_loss: 0.0094\n",
      "\n",
      "Epoch 02412: val_loss did not improve from 0.00328\n",
      "Epoch 2413/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 1.9756e-05 - val_loss: 0.0097\n",
      "\n",
      "Epoch 02413: val_loss did not improve from 0.00328\n",
      "Epoch 2414/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.0319e-05 - val_loss: 0.0099\n",
      "\n",
      "Epoch 02414: val_loss did not improve from 0.00328\n",
      "Epoch 2415/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.2072e-05 - val_loss: 0.0099\n",
      "\n",
      "Epoch 02415: val_loss did not improve from 0.00328\n",
      "Epoch 2416/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.0538e-05 - val_loss: 0.0094\n",
      "\n",
      "Epoch 02416: val_loss did not improve from 0.00328\n",
      "Epoch 2417/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.3943e-05 - val_loss: 0.0093\n",
      "\n",
      "Epoch 02417: val_loss did not improve from 0.00328\n",
      "Epoch 2418/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.0509e-05 - val_loss: 0.0094\n",
      "\n",
      "Epoch 02418: val_loss did not improve from 0.00328\n",
      "Epoch 2419/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.2115e-05 - val_loss: 0.0096\n",
      "\n",
      "Epoch 02419: val_loss did not improve from 0.00328\n",
      "Epoch 2420/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.0588e-05 - val_loss: 0.0095\n",
      "\n",
      "Epoch 02420: val_loss did not improve from 0.00328\n",
      "Epoch 2421/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.4962e-05 - val_loss: 0.0090\n",
      "\n",
      "Epoch 02421: val_loss did not improve from 0.00328\n",
      "Epoch 2422/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.7398e-05 - val_loss: 0.0089\n",
      "\n",
      "Epoch 02422: val_loss did not improve from 0.00328\n",
      "Epoch 2423/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.5318e-05 - val_loss: 0.0094\n",
      "\n",
      "Epoch 02423: val_loss did not improve from 0.00328\n",
      "Epoch 2424/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 1.6679e-05 - val_loss: 0.0095\n",
      "\n",
      "Epoch 02424: val_loss did not improve from 0.00328\n",
      "Epoch 2425/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.4764e-05 - val_loss: 0.0094\n",
      "\n",
      "Epoch 02425: val_loss did not improve from 0.00328\n",
      "Epoch 2426/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.3780e-05 - val_loss: 0.0091\n",
      "\n",
      "Epoch 02426: val_loss did not improve from 0.00328\n",
      "Epoch 2427/3000\n",
      "184/184 [==============================] - 0s 119us/step - loss: 2.1586e-05 - val_loss: 0.0092\n",
      "\n",
      "Epoch 02427: val_loss did not improve from 0.00328\n",
      "Epoch 2428/3000\n",
      "184/184 [==============================] - 0s 94us/step - loss: 2.0506e-05 - val_loss: 0.0097\n",
      "\n",
      "Epoch 02428: val_loss did not improve from 0.00328\n",
      "Epoch 2429/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 1.9845e-05 - val_loss: 0.0099\n",
      "\n",
      "Epoch 02429: val_loss did not improve from 0.00328\n",
      "Epoch 2430/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 98us/step - loss: 2.1486e-05 - val_loss: 0.0097\n",
      "\n",
      "Epoch 02430: val_loss did not improve from 0.00328\n",
      "Epoch 2431/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.0276e-05 - val_loss: 0.0095\n",
      "\n",
      "Epoch 02431: val_loss did not improve from 0.00328\n",
      "Epoch 2432/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 1.9970e-05 - val_loss: 0.0096\n",
      "\n",
      "Epoch 02432: val_loss did not improve from 0.00328\n",
      "Epoch 2433/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 1.8794e-05 - val_loss: 0.0097\n",
      "\n",
      "Epoch 02433: val_loss did not improve from 0.00328\n",
      "Epoch 2434/3000\n",
      "184/184 [==============================] - 0s 136us/step - loss: 2.1543e-05 - val_loss: 0.0096\n",
      "\n",
      "Epoch 02434: val_loss did not improve from 0.00328\n",
      "Epoch 2435/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.1033e-05 - val_loss: 0.0093\n",
      "\n",
      "Epoch 02435: val_loss did not improve from 0.00328\n",
      "Epoch 2436/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 1.5361e-05 - val_loss: 0.0091\n",
      "\n",
      "Epoch 02436: val_loss did not improve from 0.00328\n",
      "Epoch 2437/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 1.6815e-05 - val_loss: 0.0090\n",
      "\n",
      "Epoch 02437: val_loss did not improve from 0.00328\n",
      "Epoch 2438/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.2276e-05 - val_loss: 0.0090\n",
      "\n",
      "Epoch 02438: val_loss did not improve from 0.00328\n",
      "Epoch 2439/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.5384e-05 - val_loss: 0.0092\n",
      "\n",
      "Epoch 02439: val_loss did not improve from 0.00328\n",
      "Epoch 2440/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.4517e-05 - val_loss: 0.0094\n",
      "\n",
      "Epoch 02440: val_loss did not improve from 0.00328\n",
      "Epoch 2441/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 1.8575e-05 - val_loss: 0.0092\n",
      "\n",
      "Epoch 02441: val_loss did not improve from 0.00328\n",
      "Epoch 2442/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.0613e-05 - val_loss: 0.0090\n",
      "\n",
      "Epoch 02442: val_loss did not improve from 0.00328\n",
      "Epoch 2443/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.1913e-05 - val_loss: 0.0091\n",
      "\n",
      "Epoch 02443: val_loss did not improve from 0.00328\n",
      "Epoch 2444/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.3534e-05 - val_loss: 0.0095\n",
      "\n",
      "Epoch 02444: val_loss did not improve from 0.00328\n",
      "Epoch 2445/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 1.9050e-05 - val_loss: 0.0095\n",
      "\n",
      "Epoch 02445: val_loss did not improve from 0.00328\n",
      "Epoch 2446/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 1.6132e-05 - val_loss: 0.0091\n",
      "\n",
      "Epoch 02446: val_loss did not improve from 0.00328\n",
      "Epoch 2447/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.2588e-05 - val_loss: 0.0091\n",
      "\n",
      "Epoch 02447: val_loss did not improve from 0.00328\n",
      "Epoch 2448/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.6282e-05 - val_loss: 0.0095\n",
      "\n",
      "Epoch 02448: val_loss did not improve from 0.00328\n",
      "Epoch 2449/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.6768e-05 - val_loss: 0.0094\n",
      "\n",
      "Epoch 02449: val_loss did not improve from 0.00328\n",
      "Epoch 2450/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.3105e-05 - val_loss: 0.0093\n",
      "\n",
      "Epoch 02450: val_loss did not improve from 0.00328\n",
      "Epoch 2451/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.3656e-05 - val_loss: 0.0095\n",
      "\n",
      "Epoch 02451: val_loss did not improve from 0.00328\n",
      "Epoch 2452/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 1.8558e-05 - val_loss: 0.0097\n",
      "\n",
      "Epoch 02452: val_loss did not improve from 0.00328\n",
      "Epoch 2453/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.1850e-05 - val_loss: 0.0096\n",
      "\n",
      "Epoch 02453: val_loss did not improve from 0.00328\n",
      "Epoch 2454/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.0313e-05 - val_loss: 0.0094\n",
      "\n",
      "Epoch 02454: val_loss did not improve from 0.00328\n",
      "Epoch 2455/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 1.9577e-05 - val_loss: 0.0092\n",
      "\n",
      "Epoch 02455: val_loss did not improve from 0.00328\n",
      "Epoch 2456/3000\n",
      "184/184 [==============================] - 0s 158us/step - loss: 1.7807e-05 - val_loss: 0.0091\n",
      "\n",
      "Epoch 02456: val_loss did not improve from 0.00328\n",
      "Epoch 2457/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.0662e-05 - val_loss: 0.0092\n",
      "\n",
      "Epoch 02457: val_loss did not improve from 0.00328\n",
      "Epoch 2458/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 1.9333e-05 - val_loss: 0.0092\n",
      "\n",
      "Epoch 02458: val_loss did not improve from 0.00328\n",
      "Epoch 2459/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.0825e-05 - val_loss: 0.0092\n",
      "\n",
      "Epoch 02459: val_loss did not improve from 0.00328\n",
      "Epoch 2460/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.2834e-05 - val_loss: 0.0094\n",
      "\n",
      "Epoch 02460: val_loss did not improve from 0.00328\n",
      "Epoch 2461/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 1.9883e-05 - val_loss: 0.0095\n",
      "\n",
      "Epoch 02461: val_loss did not improve from 0.00328\n",
      "Epoch 2462/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 1.9146e-05 - val_loss: 0.0096\n",
      "\n",
      "Epoch 02462: val_loss did not improve from 0.00328\n",
      "Epoch 2463/3000\n",
      "184/184 [==============================] - 0s 81us/step - loss: 1.8990e-05 - val_loss: 0.0097\n",
      "\n",
      "Epoch 02463: val_loss did not improve from 0.00328\n",
      "Epoch 2464/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.2809e-05 - val_loss: 0.0100\n",
      "\n",
      "Epoch 02464: val_loss did not improve from 0.00328\n",
      "Epoch 2465/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.3604e-05 - val_loss: 0.0100\n",
      "\n",
      "Epoch 02465: val_loss did not improve from 0.00328\n",
      "Epoch 2466/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.0169e-05 - val_loss: 0.0094\n",
      "\n",
      "Epoch 02466: val_loss did not improve from 0.00328\n",
      "Epoch 2467/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.4048e-05 - val_loss: 0.0090\n",
      "\n",
      "Epoch 02467: val_loss did not improve from 0.00328\n",
      "Epoch 2468/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.4920e-05 - val_loss: 0.0094\n",
      "\n",
      "Epoch 02468: val_loss did not improve from 0.00328\n",
      "Epoch 2469/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 1.9663e-05 - val_loss: 0.0098\n",
      "\n",
      "Epoch 02469: val_loss did not improve from 0.00328\n",
      "Epoch 2470/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.7328e-05 - val_loss: 0.0091\n",
      "\n",
      "Epoch 02470: val_loss did not improve from 0.00328\n",
      "Epoch 2471/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.3947e-05 - val_loss: 0.0087\n",
      "\n",
      "Epoch 02471: val_loss did not improve from 0.00328\n",
      "Epoch 2472/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.1838e-05 - val_loss: 0.0093\n",
      "\n",
      "Epoch 02472: val_loss did not improve from 0.00328\n",
      "Epoch 2473/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.1770e-05 - val_loss: 0.0099\n",
      "\n",
      "Epoch 02473: val_loss did not improve from 0.00328\n",
      "Epoch 2474/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.2415e-05 - val_loss: 0.0100\n",
      "\n",
      "Epoch 02474: val_loss did not improve from 0.00328\n",
      "Epoch 2475/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.0687e-05 - val_loss: 0.0095\n",
      "\n",
      "Epoch 02475: val_loss did not improve from 0.00328\n",
      "Epoch 2476/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.1914e-05 - val_loss: 0.0091\n",
      "\n",
      "Epoch 02476: val_loss did not improve from 0.00328\n",
      "Epoch 2477/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.5884e-05 - val_loss: 0.0095\n",
      "\n",
      "Epoch 02477: val_loss did not improve from 0.00328\n",
      "Epoch 2478/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.4041e-05 - val_loss: 0.0101\n",
      "\n",
      "Epoch 02478: val_loss did not improve from 0.00328\n",
      "Epoch 2479/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.2782e-05 - val_loss: 0.0101\n",
      "\n",
      "Epoch 02479: val_loss did not improve from 0.00328\n",
      "Epoch 2480/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.2420e-05 - val_loss: 0.0093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 02480: val_loss did not improve from 0.00328\n",
      "Epoch 2481/3000\n",
      "184/184 [==============================] - 0s 120us/step - loss: 2.5638e-05 - val_loss: 0.0090\n",
      "\n",
      "Epoch 02481: val_loss did not improve from 0.00328\n",
      "Epoch 2482/3000\n",
      "184/184 [==============================] - 0s 111us/step - loss: 3.1404e-05 - val_loss: 0.0093\n",
      "\n",
      "Epoch 02482: val_loss did not improve from 0.00328\n",
      "Epoch 2483/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.0512e-05 - val_loss: 0.0099\n",
      "\n",
      "Epoch 02483: val_loss did not improve from 0.00328\n",
      "Epoch 2484/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.2798e-05 - val_loss: 0.0099\n",
      "\n",
      "Epoch 02484: val_loss did not improve from 0.00328\n",
      "Epoch 2485/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.2812e-05 - val_loss: 0.0092\n",
      "\n",
      "Epoch 02485: val_loss did not improve from 0.00328\n",
      "Epoch 2486/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.4911e-05 - val_loss: 0.0088\n",
      "\n",
      "Epoch 02486: val_loss did not improve from 0.00328\n",
      "Epoch 2487/3000\n",
      "184/184 [==============================] - 0s 101us/step - loss: 2.7237e-05 - val_loss: 0.0094\n",
      "\n",
      "Epoch 02487: val_loss did not improve from 0.00328\n",
      "Epoch 2488/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.0749e-05 - val_loss: 0.0101\n",
      "\n",
      "Epoch 02488: val_loss did not improve from 0.00328\n",
      "Epoch 2489/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.2141e-05 - val_loss: 0.0102\n",
      "\n",
      "Epoch 02489: val_loss did not improve from 0.00328\n",
      "Epoch 2490/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.5036e-05 - val_loss: 0.0094\n",
      "\n",
      "Epoch 02490: val_loss did not improve from 0.00328\n",
      "Epoch 2491/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.7117e-05 - val_loss: 0.0090\n",
      "\n",
      "Epoch 02491: val_loss did not improve from 0.00328\n",
      "Epoch 2492/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 3.2324e-05 - val_loss: 0.0099\n",
      "\n",
      "Epoch 02492: val_loss did not improve from 0.00328\n",
      "Epoch 2493/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.2895e-05 - val_loss: 0.0110\n",
      "\n",
      "Epoch 02493: val_loss did not improve from 0.00328\n",
      "Epoch 2494/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 3.3793e-05 - val_loss: 0.0107\n",
      "\n",
      "Epoch 02494: val_loss did not improve from 0.00328\n",
      "Epoch 2495/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 1.9945e-05 - val_loss: 0.0096\n",
      "\n",
      "Epoch 02495: val_loss did not improve from 0.00328\n",
      "Epoch 2496/3000\n",
      "184/184 [==============================] - 0s 152us/step - loss: 2.1676e-05 - val_loss: 0.0092\n",
      "\n",
      "Epoch 02496: val_loss did not improve from 0.00328\n",
      "Epoch 2497/3000\n",
      "184/184 [==============================] - 0s 120us/step - loss: 2.5280e-05 - val_loss: 0.0096\n",
      "\n",
      "Epoch 02497: val_loss did not improve from 0.00328\n",
      "Epoch 2498/3000\n",
      "184/184 [==============================] - 0s 120us/step - loss: 3.1502e-05 - val_loss: 0.0097\n",
      "\n",
      "Epoch 02498: val_loss did not improve from 0.00328\n",
      "Epoch 2499/3000\n",
      "184/184 [==============================] - 0s 147us/step - loss: 1.7246e-05 - val_loss: 0.0092\n",
      "\n",
      "Epoch 02499: val_loss did not improve from 0.00328\n",
      "Epoch 2500/3000\n",
      "184/184 [==============================] - 0s 234us/step - loss: 2.4491e-05 - val_loss: 0.0089\n",
      "\n",
      "Epoch 02500: val_loss did not improve from 0.00328\n",
      "Epoch 2501/3000\n",
      "184/184 [==============================] - 0s 152us/step - loss: 2.6772e-05 - val_loss: 0.0092\n",
      "\n",
      "Epoch 02501: val_loss did not improve from 0.00328\n",
      "Epoch 2502/3000\n",
      "184/184 [==============================] - 0s 119us/step - loss: 2.3605e-05 - val_loss: 0.0098\n",
      "\n",
      "Epoch 02502: val_loss did not improve from 0.00328\n",
      "Epoch 2503/3000\n",
      "184/184 [==============================] - 0s 163us/step - loss: 2.0851e-05 - val_loss: 0.0097\n",
      "\n",
      "Epoch 02503: val_loss did not improve from 0.00328\n",
      "Epoch 2504/3000\n",
      "184/184 [==============================] - 0s 190us/step - loss: 2.4762e-05 - val_loss: 0.0096\n",
      "\n",
      "Epoch 02504: val_loss did not improve from 0.00328\n",
      "Epoch 2505/3000\n",
      "184/184 [==============================] - 0s 141us/step - loss: 2.4164e-05 - val_loss: 0.0096\n",
      "\n",
      "Epoch 02505: val_loss did not improve from 0.00328\n",
      "Epoch 2506/3000\n",
      "184/184 [==============================] - 0s 158us/step - loss: 1.9911e-05 - val_loss: 0.0094\n",
      "\n",
      "Epoch 02506: val_loss did not improve from 0.00328\n",
      "Epoch 2507/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 2.4205e-05 - val_loss: 0.0094\n",
      "\n",
      "Epoch 02507: val_loss did not improve from 0.00328\n",
      "Epoch 2508/3000\n",
      "184/184 [==============================] - 0s 147us/step - loss: 2.4264e-05 - val_loss: 0.0095\n",
      "\n",
      "Epoch 02508: val_loss did not improve from 0.00328\n",
      "Epoch 2509/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.3441e-05 - val_loss: 0.0093\n",
      "\n",
      "Epoch 02509: val_loss did not improve from 0.00328\n",
      "Epoch 2510/3000\n",
      "184/184 [==============================] - 0s 141us/step - loss: 2.0773e-05 - val_loss: 0.0094\n",
      "\n",
      "Epoch 02510: val_loss did not improve from 0.00328\n",
      "Epoch 2511/3000\n",
      "184/184 [==============================] - 0s 255us/step - loss: 1.9915e-05 - val_loss: 0.0094\n",
      "\n",
      "Epoch 02511: val_loss did not improve from 0.00328\n",
      "Epoch 2512/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 2.2335e-05 - val_loss: 0.0095\n",
      "\n",
      "Epoch 02512: val_loss did not improve from 0.00328\n",
      "Epoch 2513/3000\n",
      "184/184 [==============================] - 0s 130us/step - loss: 2.1509e-05 - val_loss: 0.0093\n",
      "\n",
      "Epoch 02513: val_loss did not improve from 0.00328\n",
      "Epoch 2514/3000\n",
      "184/184 [==============================] - 0s 130us/step - loss: 2.5835e-05 - val_loss: 0.0090\n",
      "\n",
      "Epoch 02514: val_loss did not improve from 0.00328\n",
      "Epoch 2515/3000\n",
      "184/184 [==============================] - 0s 119us/step - loss: 1.8724e-05 - val_loss: 0.0090\n",
      "\n",
      "Epoch 02515: val_loss did not improve from 0.00328\n",
      "Epoch 2516/3000\n",
      "184/184 [==============================] - 0s 147us/step - loss: 2.0133e-05 - val_loss: 0.0094\n",
      "\n",
      "Epoch 02516: val_loss did not improve from 0.00328\n",
      "Epoch 2517/3000\n",
      "184/184 [==============================] - 0s 190us/step - loss: 2.0594e-05 - val_loss: 0.0097\n",
      "\n",
      "Epoch 02517: val_loss did not improve from 0.00328\n",
      "Epoch 2518/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.0402e-05 - val_loss: 0.0098\n",
      "\n",
      "Epoch 02518: val_loss did not improve from 0.00328\n",
      "Epoch 2519/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.4889e-05 - val_loss: 0.0095\n",
      "\n",
      "Epoch 02519: val_loss did not improve from 0.00328\n",
      "Epoch 2520/3000\n",
      "184/184 [==============================] - ETA: 0s - loss: 1.3683e-0 - 0s 98us/step - loss: 2.3685e-05 - val_loss: 0.0095\n",
      "\n",
      "Epoch 02520: val_loss did not improve from 0.00328\n",
      "Epoch 2521/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.3635e-05 - val_loss: 0.0098\n",
      "\n",
      "Epoch 02521: val_loss did not improve from 0.00328\n",
      "Epoch 2522/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.5066e-05 - val_loss: 0.0097\n",
      "\n",
      "Epoch 02522: val_loss did not improve from 0.00328\n",
      "Epoch 2523/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.0919e-05 - val_loss: 0.0096\n",
      "\n",
      "Epoch 02523: val_loss did not improve from 0.00328\n",
      "Epoch 2524/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.4091e-05 - val_loss: 0.0094\n",
      "\n",
      "Epoch 02524: val_loss did not improve from 0.00328\n",
      "Epoch 2525/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.3757e-05 - val_loss: 0.0091\n",
      "\n",
      "Epoch 02525: val_loss did not improve from 0.00328\n",
      "Epoch 2526/3000\n",
      "184/184 [==============================] - 0s 93us/step - loss: 2.5527e-05 - val_loss: 0.0089\n",
      "\n",
      "Epoch 02526: val_loss did not improve from 0.00328\n",
      "Epoch 2527/3000\n",
      "184/184 [==============================] - 0s 119us/step - loss: 2.3479e-05 - val_loss: 0.0092\n",
      "\n",
      "Epoch 02527: val_loss did not improve from 0.00328\n",
      "Epoch 2528/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.2975e-05 - val_loss: 0.0095\n",
      "\n",
      "Epoch 02528: val_loss did not improve from 0.00328\n",
      "Epoch 2529/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 1.9215e-05 - val_loss: 0.0092\n",
      "\n",
      "Epoch 02529: val_loss did not improve from 0.00328\n",
      "Epoch 2530/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.0427e-05 - val_loss: 0.0089\n",
      "\n",
      "Epoch 02530: val_loss did not improve from 0.00328\n",
      "Epoch 2531/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 87us/step - loss: 2.6831e-05 - val_loss: 0.0091\n",
      "\n",
      "Epoch 02531: val_loss did not improve from 0.00328\n",
      "Epoch 2532/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.2762e-05 - val_loss: 0.0095\n",
      "\n",
      "Epoch 02532: val_loss did not improve from 0.00328\n",
      "Epoch 2533/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 2.0171e-05 - val_loss: 0.0094\n",
      "\n",
      "Epoch 02533: val_loss did not improve from 0.00328\n",
      "Epoch 2534/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.3572e-05 - val_loss: 0.0092\n",
      "\n",
      "Epoch 02534: val_loss did not improve from 0.00328\n",
      "Epoch 2535/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.2866e-05 - val_loss: 0.0091\n",
      "\n",
      "Epoch 02535: val_loss did not improve from 0.00328\n",
      "Epoch 2536/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 2.3640e-05 - val_loss: 0.0091\n",
      "\n",
      "Epoch 02536: val_loss did not improve from 0.00328\n",
      "Epoch 2537/3000\n",
      "184/184 [==============================] - 0s 163us/step - loss: 2.0821e-05 - val_loss: 0.0091\n",
      "\n",
      "Epoch 02537: val_loss did not improve from 0.00328\n",
      "Epoch 2538/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.1872e-05 - val_loss: 0.0093\n",
      "\n",
      "Epoch 02538: val_loss did not improve from 0.00328\n",
      "Epoch 2539/3000\n",
      "184/184 [==============================] - 0s 120us/step - loss: 2.1613e-05 - val_loss: 0.0093\n",
      "\n",
      "Epoch 02539: val_loss did not improve from 0.00328\n",
      "Epoch 2540/3000\n",
      "184/184 [==============================] - 0s 158us/step - loss: 1.9478e-05 - val_loss: 0.0092\n",
      "\n",
      "Epoch 02540: val_loss did not improve from 0.00328\n",
      "Epoch 2541/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.2115e-05 - val_loss: 0.0094\n",
      "\n",
      "Epoch 02541: val_loss did not improve from 0.00328\n",
      "Epoch 2542/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.8410e-05 - val_loss: 0.0096\n",
      "\n",
      "Epoch 02542: val_loss did not improve from 0.00328\n",
      "Epoch 2543/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 1.9486e-05 - val_loss: 0.0095\n",
      "\n",
      "Epoch 02543: val_loss did not improve from 0.00328\n",
      "Epoch 2544/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.1737e-05 - val_loss: 0.0096\n",
      "\n",
      "Epoch 02544: val_loss did not improve from 0.00328\n",
      "Epoch 2545/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.1761e-05 - val_loss: 0.0095\n",
      "\n",
      "Epoch 02545: val_loss did not improve from 0.00328\n",
      "Epoch 2546/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.5932e-05 - val_loss: 0.0094\n",
      "\n",
      "Epoch 02546: val_loss did not improve from 0.00328\n",
      "Epoch 2547/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.2813e-05 - val_loss: 0.0094\n",
      "\n",
      "Epoch 02547: val_loss did not improve from 0.00328\n",
      "Epoch 2548/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 1.8886e-05 - val_loss: 0.0099\n",
      "\n",
      "Epoch 02548: val_loss did not improve from 0.00328\n",
      "Epoch 2549/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.3404e-05 - val_loss: 0.0102\n",
      "\n",
      "Epoch 02549: val_loss did not improve from 0.00328\n",
      "Epoch 2550/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 1.7094e-05 - val_loss: 0.0099\n",
      "\n",
      "Epoch 02550: val_loss did not improve from 0.00328\n",
      "Epoch 2551/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 1.9937e-05 - val_loss: 0.0096\n",
      "\n",
      "Epoch 02551: val_loss did not improve from 0.00328\n",
      "Epoch 2552/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.2577e-05 - val_loss: 0.0097\n",
      "\n",
      "Epoch 02552: val_loss did not improve from 0.00328\n",
      "Epoch 2553/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.2366e-05 - val_loss: 0.0099\n",
      "\n",
      "Epoch 02553: val_loss did not improve from 0.00328\n",
      "Epoch 2554/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.6373e-05 - val_loss: 0.0096\n",
      "\n",
      "Epoch 02554: val_loss did not improve from 0.00328\n",
      "Epoch 2555/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.4190e-05 - val_loss: 0.0091\n",
      "\n",
      "Epoch 02555: val_loss did not improve from 0.00328\n",
      "Epoch 2556/3000\n",
      "184/184 [==============================] - 0s 158us/step - loss: 2.1945e-05 - val_loss: 0.0088\n",
      "\n",
      "Epoch 02556: val_loss did not improve from 0.00328\n",
      "Epoch 2557/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.2361e-05 - val_loss: 0.0089\n",
      "\n",
      "Epoch 02557: val_loss did not improve from 0.00328\n",
      "Epoch 2558/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 2.4329e-05 - val_loss: 0.0091\n",
      "\n",
      "Epoch 02558: val_loss did not improve from 0.00328\n",
      "Epoch 2559/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 2.4744e-05 - val_loss: 0.0091\n",
      "\n",
      "Epoch 02559: val_loss did not improve from 0.00328\n",
      "Epoch 2560/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.0383e-05 - val_loss: 0.0091\n",
      "\n",
      "Epoch 02560: val_loss did not improve from 0.00328\n",
      "Epoch 2561/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.5222e-05 - val_loss: 0.0092\n",
      "\n",
      "Epoch 02561: val_loss did not improve from 0.00328\n",
      "Epoch 2562/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.8605e-05 - val_loss: 0.0098\n",
      "\n",
      "Epoch 02562: val_loss did not improve from 0.00328\n",
      "Epoch 2563/3000\n",
      "184/184 [==============================] - 0s 152us/step - loss: 2.3583e-05 - val_loss: 0.0102\n",
      "\n",
      "Epoch 02563: val_loss did not improve from 0.00328\n",
      "Epoch 2564/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 1.7946e-05 - val_loss: 0.0100\n",
      "\n",
      "Epoch 02564: val_loss did not improve from 0.00328\n",
      "Epoch 2565/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.1512e-05 - val_loss: 0.0096\n",
      "\n",
      "Epoch 02565: val_loss did not improve from 0.00328\n",
      "Epoch 2566/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.3447e-05 - val_loss: 0.0093\n",
      "\n",
      "Epoch 02566: val_loss did not improve from 0.00328\n",
      "Epoch 2567/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.4715e-05 - val_loss: 0.0093\n",
      "\n",
      "Epoch 02567: val_loss did not improve from 0.00328\n",
      "Epoch 2568/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 1.9208e-05 - val_loss: 0.0093\n",
      "\n",
      "Epoch 02568: val_loss did not improve from 0.00328\n",
      "Epoch 2569/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 1.9337e-05 - val_loss: 0.0091\n",
      "\n",
      "Epoch 02569: val_loss did not improve from 0.00328\n",
      "Epoch 2570/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.0373e-05 - val_loss: 0.0091\n",
      "\n",
      "Epoch 02570: val_loss did not improve from 0.00328\n",
      "Epoch 2571/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.1967e-05 - val_loss: 0.0093\n",
      "\n",
      "Epoch 02571: val_loss did not improve from 0.00328\n",
      "Epoch 2572/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.0680e-05 - val_loss: 0.0095\n",
      "\n",
      "Epoch 02572: val_loss did not improve from 0.00328\n",
      "Epoch 2573/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.5982e-05 - val_loss: 0.0093\n",
      "\n",
      "Epoch 02573: val_loss did not improve from 0.00328\n",
      "Epoch 2574/3000\n",
      "184/184 [==============================] - 0s 141us/step - loss: 1.8791e-05 - val_loss: 0.0089\n",
      "\n",
      "Epoch 02574: val_loss did not improve from 0.00328\n",
      "Epoch 2575/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.3777e-05 - val_loss: 0.0091\n",
      "\n",
      "Epoch 02575: val_loss did not improve from 0.00328\n",
      "Epoch 2576/3000\n",
      "184/184 [==============================] - 0s 136us/step - loss: 2.3176e-05 - val_loss: 0.0094\n",
      "\n",
      "Epoch 02576: val_loss did not improve from 0.00328\n",
      "Epoch 2577/3000\n",
      "184/184 [==============================] - 0s 130us/step - loss: 2.4387e-05 - val_loss: 0.0093\n",
      "\n",
      "Epoch 02577: val_loss did not improve from 0.00328\n",
      "Epoch 2578/3000\n",
      "184/184 [==============================] - 0s 152us/step - loss: 1.8498e-05 - val_loss: 0.0092\n",
      "\n",
      "Epoch 02578: val_loss did not improve from 0.00328\n",
      "Epoch 2579/3000\n",
      "184/184 [==============================] - 0s 119us/step - loss: 1.7511e-05 - val_loss: 0.0093\n",
      "\n",
      "Epoch 02579: val_loss did not improve from 0.00328\n",
      "Epoch 2580/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 1.8223e-05 - val_loss: 0.0091\n",
      "\n",
      "Epoch 02580: val_loss did not improve from 0.00328\n",
      "Epoch 2581/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 101us/step - loss: 2.2332e-05 - val_loss: 0.0091\n",
      "\n",
      "Epoch 02581: val_loss did not improve from 0.00328\n",
      "Epoch 2582/3000\n",
      "184/184 [==============================] - 0s 104us/step - loss: 2.3289e-05 - val_loss: 0.0094\n",
      "\n",
      "Epoch 02582: val_loss did not improve from 0.00328\n",
      "Epoch 2583/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.0967e-05 - val_loss: 0.0097\n",
      "\n",
      "Epoch 02583: val_loss did not improve from 0.00328\n",
      "Epoch 2584/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 1.8040e-05 - val_loss: 0.0097\n",
      "\n",
      "Epoch 02584: val_loss did not improve from 0.00328\n",
      "Epoch 2585/3000\n",
      "184/184 [==============================] - 0s 130us/step - loss: 1.8829e-05 - val_loss: 0.0095\n",
      "\n",
      "Epoch 02585: val_loss did not improve from 0.00328\n",
      "Epoch 2586/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.1261e-05 - val_loss: 0.0094\n",
      "\n",
      "Epoch 02586: val_loss did not improve from 0.00328\n",
      "Epoch 2587/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.3904e-05 - val_loss: 0.0094\n",
      "\n",
      "Epoch 02587: val_loss did not improve from 0.00328\n",
      "Epoch 2588/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.4358e-05 - val_loss: 0.0094\n",
      "\n",
      "Epoch 02588: val_loss did not improve from 0.00328\n",
      "Epoch 2589/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.1024e-05 - val_loss: 0.0093\n",
      "\n",
      "Epoch 02589: val_loss did not improve from 0.00328\n",
      "Epoch 2590/3000\n",
      "184/184 [==============================] - 0s 120us/step - loss: 1.8401e-05 - val_loss: 0.0092\n",
      "\n",
      "Epoch 02590: val_loss did not improve from 0.00328\n",
      "Epoch 2591/3000\n",
      "184/184 [==============================] - 0s 136us/step - loss: 2.3573e-05 - val_loss: 0.0093\n",
      "\n",
      "Epoch 02591: val_loss did not improve from 0.00328\n",
      "Epoch 2592/3000\n",
      "184/184 [==============================] - ETA: 0s - loss: 1.3172e-0 - 0s 120us/step - loss: 2.4172e-05 - val_loss: 0.0096\n",
      "\n",
      "Epoch 02592: val_loss did not improve from 0.00328\n",
      "Epoch 2593/3000\n",
      "184/184 [==============================] - 0s 136us/step - loss: 2.0439e-05 - val_loss: 0.0098\n",
      "\n",
      "Epoch 02593: val_loss did not improve from 0.00328\n",
      "Epoch 2594/3000\n",
      "184/184 [==============================] - 0s 131us/step - loss: 1.9296e-05 - val_loss: 0.0098\n",
      "\n",
      "Epoch 02594: val_loss did not improve from 0.00328\n",
      "Epoch 2595/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 1.8918e-05 - val_loss: 0.0094\n",
      "\n",
      "Epoch 02595: val_loss did not improve from 0.00328\n",
      "Epoch 2596/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.4022e-05 - val_loss: 0.0092\n",
      "\n",
      "Epoch 02596: val_loss did not improve from 0.00328\n",
      "Epoch 2597/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.0510e-05 - val_loss: 0.0093\n",
      "\n",
      "Epoch 02597: val_loss did not improve from 0.00328\n",
      "Epoch 2598/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.0473e-05 - val_loss: 0.0099\n",
      "\n",
      "Epoch 02598: val_loss did not improve from 0.00328\n",
      "Epoch 2599/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.7187e-05 - val_loss: 0.0101\n",
      "\n",
      "Epoch 02599: val_loss did not improve from 0.00328\n",
      "Epoch 2600/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.1768e-05 - val_loss: 0.0096\n",
      "\n",
      "Epoch 02600: val_loss did not improve from 0.00328\n",
      "Epoch 2601/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.2592e-05 - val_loss: 0.0094\n",
      "\n",
      "Epoch 02601: val_loss did not improve from 0.00328\n",
      "Epoch 2602/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.1814e-05 - val_loss: 0.0095\n",
      "\n",
      "Epoch 02602: val_loss did not improve from 0.00328\n",
      "Epoch 2603/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.1030e-05 - val_loss: 0.0097\n",
      "\n",
      "Epoch 02603: val_loss did not improve from 0.00328\n",
      "Epoch 2604/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 2.3783e-05 - val_loss: 0.0095\n",
      "\n",
      "Epoch 02604: val_loss did not improve from 0.00328\n",
      "Epoch 2605/3000\n",
      "184/184 [==============================] - 0s 130us/step - loss: 2.7323e-05 - val_loss: 0.0091\n",
      "\n",
      "Epoch 02605: val_loss did not improve from 0.00328\n",
      "Epoch 2606/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.4744e-05 - val_loss: 0.0088\n",
      "\n",
      "Epoch 02606: val_loss did not improve from 0.00328\n",
      "Epoch 2607/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.5275e-05 - val_loss: 0.0090\n",
      "\n",
      "Epoch 02607: val_loss did not improve from 0.00328\n",
      "Epoch 2608/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.0588e-05 - val_loss: 0.0092\n",
      "\n",
      "Epoch 02608: val_loss did not improve from 0.00328\n",
      "Epoch 2609/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.0737e-05 - val_loss: 0.0091\n",
      "\n",
      "Epoch 02609: val_loss did not improve from 0.00328\n",
      "Epoch 2610/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.3879e-05 - val_loss: 0.0092\n",
      "\n",
      "Epoch 02610: val_loss did not improve from 0.00328\n",
      "Epoch 2611/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 1.8141e-05 - val_loss: 0.0093\n",
      "\n",
      "Epoch 02611: val_loss did not improve from 0.00328\n",
      "Epoch 2612/3000\n",
      "184/184 [==============================] - 0s 147us/step - loss: 1.8762e-05 - val_loss: 0.0095\n",
      "\n",
      "Epoch 02612: val_loss did not improve from 0.00328\n",
      "Epoch 2613/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.5900e-05 - val_loss: 0.0096\n",
      "\n",
      "Epoch 02613: val_loss did not improve from 0.00328\n",
      "Epoch 2614/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.6286e-05 - val_loss: 0.0096\n",
      "\n",
      "Epoch 02614: val_loss did not improve from 0.00328\n",
      "Epoch 2615/3000\n",
      "184/184 [==============================] - 0s 81us/step - loss: 2.5053e-05 - val_loss: 0.0094\n",
      "\n",
      "Epoch 02615: val_loss did not improve from 0.00328\n",
      "Epoch 2616/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.1077e-05 - val_loss: 0.0093\n",
      "\n",
      "Epoch 02616: val_loss did not improve from 0.00328\n",
      "Epoch 2617/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.1480e-05 - val_loss: 0.0094\n",
      "\n",
      "Epoch 02617: val_loss did not improve from 0.00328\n",
      "Epoch 2618/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.1927e-05 - val_loss: 0.0094\n",
      "\n",
      "Epoch 02618: val_loss did not improve from 0.00328\n",
      "Epoch 2619/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.0485e-05 - val_loss: 0.0091\n",
      "\n",
      "Epoch 02619: val_loss did not improve from 0.00328\n",
      "Epoch 2620/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.3171e-05 - val_loss: 0.0091\n",
      "\n",
      "Epoch 02620: val_loss did not improve from 0.00328\n",
      "Epoch 2621/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.3616e-05 - val_loss: 0.0097\n",
      "\n",
      "Epoch 02621: val_loss did not improve from 0.00328\n",
      "Epoch 2622/3000\n",
      "184/184 [==============================] - 0s 120us/step - loss: 2.5437e-05 - val_loss: 0.0101\n",
      "\n",
      "Epoch 02622: val_loss did not improve from 0.00328\n",
      "Epoch 2623/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.3428e-05 - val_loss: 0.0098\n",
      "\n",
      "Epoch 02623: val_loss did not improve from 0.00328\n",
      "Epoch 2624/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.0490e-05 - val_loss: 0.0094\n",
      "\n",
      "Epoch 02624: val_loss did not improve from 0.00328\n",
      "Epoch 2625/3000\n",
      "184/184 [==============================] - 0s 81us/step - loss: 1.9146e-05 - val_loss: 0.0093\n",
      "\n",
      "Epoch 02625: val_loss did not improve from 0.00328\n",
      "Epoch 2626/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.1186e-05 - val_loss: 0.0092\n",
      "\n",
      "Epoch 02626: val_loss did not improve from 0.00328\n",
      "Epoch 2627/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.6972e-05 - val_loss: 0.0090\n",
      "\n",
      "Epoch 02627: val_loss did not improve from 0.00328\n",
      "Epoch 2628/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.2032e-05 - val_loss: 0.0087\n",
      "\n",
      "Epoch 02628: val_loss did not improve from 0.00328\n",
      "Epoch 2629/3000\n",
      "184/184 [==============================] - 0s 119us/step - loss: 2.0574e-05 - val_loss: 0.0087\n",
      "\n",
      "Epoch 02629: val_loss did not improve from 0.00328\n",
      "Epoch 2630/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 1.9307e-05 - val_loss: 0.0086\n",
      "\n",
      "Epoch 02630: val_loss did not improve from 0.00328\n",
      "Epoch 2631/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 98us/step - loss: 2.1784e-05 - val_loss: 0.0086\n",
      "\n",
      "Epoch 02631: val_loss did not improve from 0.00328\n",
      "Epoch 2632/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.1211e-05 - val_loss: 0.0090\n",
      "\n",
      "Epoch 02632: val_loss did not improve from 0.00328\n",
      "Epoch 2633/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.0100e-05 - val_loss: 0.0092\n",
      "\n",
      "Epoch 02633: val_loss did not improve from 0.00328\n",
      "Epoch 2634/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 1.7983e-05 - val_loss: 0.0092\n",
      "\n",
      "Epoch 02634: val_loss did not improve from 0.00328\n",
      "Epoch 2635/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.1775e-05 - val_loss: 0.0094\n",
      "\n",
      "Epoch 02635: val_loss did not improve from 0.00328\n",
      "Epoch 2636/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.6760e-05 - val_loss: 0.0095\n",
      "\n",
      "Epoch 02636: val_loss did not improve from 0.00328\n",
      "Epoch 2637/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.1862e-05 - val_loss: 0.0097\n",
      "\n",
      "Epoch 02637: val_loss did not improve from 0.00328\n",
      "Epoch 2638/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.5762e-05 - val_loss: 0.0094\n",
      "\n",
      "Epoch 02638: val_loss did not improve from 0.00328\n",
      "Epoch 2639/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.3638e-05 - val_loss: 0.0092\n",
      "\n",
      "Epoch 02639: val_loss did not improve from 0.00328\n",
      "Epoch 2640/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 2.2600e-05 - val_loss: 0.0093\n",
      "\n",
      "Epoch 02640: val_loss did not improve from 0.00328\n",
      "Epoch 2641/3000\n",
      "184/184 [==============================] - 0s 136us/step - loss: 2.4667e-05 - val_loss: 0.0093\n",
      "\n",
      "Epoch 02641: val_loss did not improve from 0.00328\n",
      "Epoch 2642/3000\n",
      "184/184 [==============================] - 0s 120us/step - loss: 2.2652e-05 - val_loss: 0.0092\n",
      "\n",
      "Epoch 02642: val_loss did not improve from 0.00328\n",
      "Epoch 2643/3000\n",
      "184/184 [==============================] - 0s 130us/step - loss: 2.1506e-05 - val_loss: 0.0093\n",
      "\n",
      "Epoch 02643: val_loss did not improve from 0.00328\n",
      "Epoch 2644/3000\n",
      "184/184 [==============================] - 0s 147us/step - loss: 2.4160e-05 - val_loss: 0.0093\n",
      "\n",
      "Epoch 02644: val_loss did not improve from 0.00328\n",
      "Epoch 2645/3000\n",
      "184/184 [==============================] - 0s 201us/step - loss: 1.9919e-05 - val_loss: 0.0092\n",
      "\n",
      "Epoch 02645: val_loss did not improve from 0.00328\n",
      "Epoch 2646/3000\n",
      "184/184 [==============================] - 0s 141us/step - loss: 1.9951e-05 - val_loss: 0.0094\n",
      "\n",
      "Epoch 02646: val_loss did not improve from 0.00328\n",
      "Epoch 2647/3000\n",
      "184/184 [==============================] - 0s 119us/step - loss: 2.3744e-05 - val_loss: 0.0097\n",
      "\n",
      "Epoch 02647: val_loss did not improve from 0.00328\n",
      "Epoch 2648/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.5501e-05 - val_loss: 0.0095\n",
      "\n",
      "Epoch 02648: val_loss did not improve from 0.00328\n",
      "Epoch 2649/3000\n",
      "184/184 [==============================] - 0s 119us/step - loss: 2.3582e-05 - val_loss: 0.0095\n",
      "\n",
      "Epoch 02649: val_loss did not improve from 0.00328\n",
      "Epoch 2650/3000\n",
      "184/184 [==============================] - 0s 147us/step - loss: 2.0153e-05 - val_loss: 0.0098\n",
      "\n",
      "Epoch 02650: val_loss did not improve from 0.00328\n",
      "Epoch 2651/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.1521e-05 - val_loss: 0.0101\n",
      "\n",
      "Epoch 02651: val_loss did not improve from 0.00328\n",
      "Epoch 2652/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.1812e-05 - val_loss: 0.0102\n",
      "\n",
      "Epoch 02652: val_loss did not improve from 0.00328\n",
      "Epoch 2653/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.6864e-05 - val_loss: 0.0100\n",
      "\n",
      "Epoch 02653: val_loss did not improve from 0.00328\n",
      "Epoch 2654/3000\n",
      "184/184 [==============================] - 0s 119us/step - loss: 2.0617e-05 - val_loss: 0.0097\n",
      "\n",
      "Epoch 02654: val_loss did not improve from 0.00328\n",
      "Epoch 2655/3000\n",
      "184/184 [==============================] - 0s 152us/step - loss: 2.5580e-05 - val_loss: 0.0098\n",
      "\n",
      "Epoch 02655: val_loss did not improve from 0.00328\n",
      "Epoch 2656/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.3612e-05 - val_loss: 0.0100\n",
      "\n",
      "Epoch 02656: val_loss did not improve from 0.00328\n",
      "Epoch 2657/3000\n",
      "184/184 [==============================] - 0s 272us/step - loss: 2.3848e-05 - val_loss: 0.0100\n",
      "\n",
      "Epoch 02657: val_loss did not improve from 0.00328\n",
      "Epoch 2658/3000\n",
      "184/184 [==============================] - 0s 364us/step - loss: 1.9619e-05 - val_loss: 0.0096\n",
      "\n",
      "Epoch 02658: val_loss did not improve from 0.00328\n",
      "Epoch 2659/3000\n",
      "184/184 [==============================] - 0s 277us/step - loss: 1.9687e-05 - val_loss: 0.0096\n",
      "\n",
      "Epoch 02659: val_loss did not improve from 0.00328\n",
      "Epoch 2660/3000\n",
      "184/184 [==============================] - 0s 130us/step - loss: 1.8807e-05 - val_loss: 0.0098\n",
      "\n",
      "Epoch 02660: val_loss did not improve from 0.00328\n",
      "Epoch 2661/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.5101e-05 - val_loss: 0.0097\n",
      "\n",
      "Epoch 02661: val_loss did not improve from 0.00328\n",
      "Epoch 2662/3000\n",
      "184/184 [==============================] - 0s 119us/step - loss: 2.4194e-05 - val_loss: 0.0096\n",
      "\n",
      "Epoch 02662: val_loss did not improve from 0.00328\n",
      "Epoch 2663/3000\n",
      "184/184 [==============================] - 0s 136us/step - loss: 2.2095e-05 - val_loss: 0.0095\n",
      "\n",
      "Epoch 02663: val_loss did not improve from 0.00328\n",
      "Epoch 2664/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 1.7846e-05 - val_loss: 0.0095\n",
      "\n",
      "Epoch 02664: val_loss did not improve from 0.00328\n",
      "Epoch 2665/3000\n",
      "184/184 [==============================] - 0s 141us/step - loss: 1.7994e-05 - val_loss: 0.0096\n",
      "\n",
      "Epoch 02665: val_loss did not improve from 0.00328\n",
      "Epoch 2666/3000\n",
      "184/184 [==============================] - 0s 136us/step - loss: 2.5497e-05 - val_loss: 0.0098\n",
      "\n",
      "Epoch 02666: val_loss did not improve from 0.00328\n",
      "Epoch 2667/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 1.7699e-05 - val_loss: 0.0097\n",
      "\n",
      "Epoch 02667: val_loss did not improve from 0.00328\n",
      "Epoch 2668/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.3843e-05 - val_loss: 0.0095\n",
      "\n",
      "Epoch 02668: val_loss did not improve from 0.00328\n",
      "Epoch 2669/3000\n",
      "184/184 [==============================] - 0s 136us/step - loss: 2.0587e-05 - val_loss: 0.0097\n",
      "\n",
      "Epoch 02669: val_loss did not improve from 0.00328\n",
      "Epoch 2670/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 2.0797e-05 - val_loss: 0.0098\n",
      "\n",
      "Epoch 02670: val_loss did not improve from 0.00328\n",
      "Epoch 2671/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 2.4104e-05 - val_loss: 0.0098\n",
      "\n",
      "Epoch 02671: val_loss did not improve from 0.00328\n",
      "Epoch 2672/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.0072e-05 - val_loss: 0.0093\n",
      "\n",
      "Epoch 02672: val_loss did not improve from 0.00328\n",
      "Epoch 2673/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.3073e-05 - val_loss: 0.0093\n",
      "\n",
      "Epoch 02673: val_loss did not improve from 0.00328\n",
      "Epoch 2674/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.2446e-05 - val_loss: 0.0099\n",
      "\n",
      "Epoch 02674: val_loss did not improve from 0.00328\n",
      "Epoch 2675/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.5640e-05 - val_loss: 0.0102\n",
      "\n",
      "Epoch 02675: val_loss did not improve from 0.00328\n",
      "Epoch 2676/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.3441e-05 - val_loss: 0.0098\n",
      "\n",
      "Epoch 02676: val_loss did not improve from 0.00328\n",
      "Epoch 2677/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.1236e-05 - val_loss: 0.0095\n",
      "\n",
      "Epoch 02677: val_loss did not improve from 0.00328\n",
      "Epoch 2678/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.1396e-05 - val_loss: 0.0097\n",
      "\n",
      "Epoch 02678: val_loss did not improve from 0.00328\n",
      "Epoch 2679/3000\n",
      "184/184 [==============================] - ETA: 0s - loss: 1.5027e-0 - 0s 125us/step - loss: 1.7587e-05 - val_loss: 0.0100\n",
      "\n",
      "Epoch 02679: val_loss did not improve from 0.00328\n",
      "Epoch 2680/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.1449e-05 - val_loss: 0.0100\n",
      "\n",
      "Epoch 02680: val_loss did not improve from 0.00328\n",
      "Epoch 2681/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 98us/step - loss: 2.3262e-05 - val_loss: 0.0095\n",
      "\n",
      "Epoch 02681: val_loss did not improve from 0.00328\n",
      "Epoch 2682/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 1.6688e-05 - val_loss: 0.0091\n",
      "\n",
      "Epoch 02682: val_loss did not improve from 0.00328\n",
      "Epoch 2683/3000\n",
      "184/184 [==============================] - 0s 130us/step - loss: 2.0974e-05 - val_loss: 0.0090\n",
      "\n",
      "Epoch 02683: val_loss did not improve from 0.00328\n",
      "Epoch 2684/3000\n",
      "184/184 [==============================] - 0s 141us/step - loss: 2.7676e-05 - val_loss: 0.0092\n",
      "\n",
      "Epoch 02684: val_loss did not improve from 0.00328\n",
      "Epoch 2685/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.4438e-05 - val_loss: 0.0092\n",
      "\n",
      "Epoch 02685: val_loss did not improve from 0.00328\n",
      "Epoch 2686/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.1373e-05 - val_loss: 0.0089\n",
      "\n",
      "Epoch 02686: val_loss did not improve from 0.00328\n",
      "Epoch 2687/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.3780e-05 - val_loss: 0.0092\n",
      "\n",
      "Epoch 02687: val_loss did not improve from 0.00328\n",
      "Epoch 2688/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 1.8803e-05 - val_loss: 0.0101\n",
      "\n",
      "Epoch 02688: val_loss did not improve from 0.00328\n",
      "Epoch 2689/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.4595e-05 - val_loss: 0.0102\n",
      "\n",
      "Epoch 02689: val_loss did not improve from 0.00328\n",
      "Epoch 2690/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 1.8811e-05 - val_loss: 0.0099\n",
      "\n",
      "Epoch 02690: val_loss did not improve from 0.00328\n",
      "Epoch 2691/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.0156e-05 - val_loss: 0.0099\n",
      "\n",
      "Epoch 02691: val_loss did not improve from 0.00328\n",
      "Epoch 2692/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.1185e-05 - val_loss: 0.0102\n",
      "\n",
      "Epoch 02692: val_loss did not improve from 0.00328\n",
      "Epoch 2693/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 1.9610e-05 - val_loss: 0.0101\n",
      "\n",
      "Epoch 02693: val_loss did not improve from 0.00328\n",
      "Epoch 2694/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 1.9238e-05 - val_loss: 0.0099\n",
      "\n",
      "Epoch 02694: val_loss did not improve from 0.00328\n",
      "Epoch 2695/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.3343e-05 - val_loss: 0.0098\n",
      "\n",
      "Epoch 02695: val_loss did not improve from 0.00328\n",
      "Epoch 2696/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.1255e-05 - val_loss: 0.0095\n",
      "\n",
      "Epoch 02696: val_loss did not improve from 0.00328\n",
      "Epoch 2697/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 1.9017e-05 - val_loss: 0.0092\n",
      "\n",
      "Epoch 02697: val_loss did not improve from 0.00328\n",
      "Epoch 2698/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.4692e-05 - val_loss: 0.0093\n",
      "\n",
      "Epoch 02698: val_loss did not improve from 0.00328\n",
      "Epoch 2699/3000\n",
      "184/184 [==============================] - 0s 163us/step - loss: 1.9755e-05 - val_loss: 0.0096\n",
      "\n",
      "Epoch 02699: val_loss did not improve from 0.00328\n",
      "Epoch 2700/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.1561e-05 - val_loss: 0.0098\n",
      "\n",
      "Epoch 02700: val_loss did not improve from 0.00328\n",
      "Epoch 2701/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.8150e-05 - val_loss: 0.0095\n",
      "\n",
      "Epoch 02701: val_loss did not improve from 0.00328\n",
      "Epoch 2702/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.8036e-05 - val_loss: 0.0091\n",
      "\n",
      "Epoch 02702: val_loss did not improve from 0.00328\n",
      "Epoch 2703/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.7310e-05 - val_loss: 0.0092\n",
      "\n",
      "Epoch 02703: val_loss did not improve from 0.00328\n",
      "Epoch 2704/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.2841e-05 - val_loss: 0.0096\n",
      "\n",
      "Epoch 02704: val_loss did not improve from 0.00328\n",
      "Epoch 2705/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.4394e-05 - val_loss: 0.0096\n",
      "\n",
      "Epoch 02705: val_loss did not improve from 0.00328\n",
      "Epoch 2706/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.2604e-05 - val_loss: 0.0093\n",
      "\n",
      "Epoch 02706: val_loss did not improve from 0.00328\n",
      "Epoch 2707/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.5266e-05 - val_loss: 0.0089\n",
      "\n",
      "Epoch 02707: val_loss did not improve from 0.00328\n",
      "Epoch 2708/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.8433e-05 - val_loss: 0.0091\n",
      "\n",
      "Epoch 02708: val_loss did not improve from 0.00328\n",
      "Epoch 2709/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.3959e-05 - val_loss: 0.0096\n",
      "\n",
      "Epoch 02709: val_loss did not improve from 0.00328\n",
      "Epoch 2710/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.6330e-05 - val_loss: 0.0096\n",
      "\n",
      "Epoch 02710: val_loss did not improve from 0.00328\n",
      "Epoch 2711/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 1.8815e-05 - val_loss: 0.0094\n",
      "\n",
      "Epoch 02711: val_loss did not improve from 0.00328\n",
      "Epoch 2712/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 1.7128e-05 - val_loss: 0.0094\n",
      "\n",
      "Epoch 02712: val_loss did not improve from 0.00328\n",
      "Epoch 2713/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.3833e-05 - val_loss: 0.0098\n",
      "\n",
      "Epoch 02713: val_loss did not improve from 0.00328\n",
      "Epoch 2714/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.4421e-05 - val_loss: 0.0100\n",
      "\n",
      "Epoch 02714: val_loss did not improve from 0.00328\n",
      "Epoch 2715/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 1.9992e-05 - val_loss: 0.0102\n",
      "\n",
      "Epoch 02715: val_loss did not improve from 0.00328\n",
      "Epoch 2716/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.4581e-05 - val_loss: 0.0100\n",
      "\n",
      "Epoch 02716: val_loss did not improve from 0.00328\n",
      "Epoch 2717/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 1.6866e-05 - val_loss: 0.0096\n",
      "\n",
      "Epoch 02717: val_loss did not improve from 0.00328\n",
      "Epoch 2718/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.4287e-05 - val_loss: 0.0094\n",
      "\n",
      "Epoch 02718: val_loss did not improve from 0.00328\n",
      "Epoch 2719/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.0431e-05 - val_loss: 0.0096\n",
      "\n",
      "Epoch 02719: val_loss did not improve from 0.00328\n",
      "Epoch 2720/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.0143e-05 - val_loss: 0.0097\n",
      "\n",
      "Epoch 02720: val_loss did not improve from 0.00328\n",
      "Epoch 2721/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.4269e-05 - val_loss: 0.0094\n",
      "\n",
      "Epoch 02721: val_loss did not improve from 0.00328\n",
      "Epoch 2722/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 1.8943e-05 - val_loss: 0.0092\n",
      "\n",
      "Epoch 02722: val_loss did not improve from 0.00328\n",
      "Epoch 2723/3000\n",
      "184/184 [==============================] - 0s 120us/step - loss: 2.5073e-05 - val_loss: 0.0093\n",
      "\n",
      "Epoch 02723: val_loss did not improve from 0.00328\n",
      "Epoch 2724/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 1.8622e-05 - val_loss: 0.0096\n",
      "\n",
      "Epoch 02724: val_loss did not improve from 0.00328\n",
      "Epoch 2725/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.3820e-05 - val_loss: 0.0096\n",
      "\n",
      "Epoch 02725: val_loss did not improve from 0.00328\n",
      "Epoch 2726/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 1.7046e-05 - val_loss: 0.0095\n",
      "\n",
      "Epoch 02726: val_loss did not improve from 0.00328\n",
      "Epoch 2727/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.0556e-05 - val_loss: 0.0094\n",
      "\n",
      "Epoch 02727: val_loss did not improve from 0.00328\n",
      "Epoch 2728/3000\n",
      "184/184 [==============================] - ETA: 0s - loss: 1.4017e-0 - 0s 98us/step - loss: 2.5667e-05 - val_loss: 0.0095\n",
      "\n",
      "Epoch 02728: val_loss did not improve from 0.00328\n",
      "Epoch 2729/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.3934e-05 - val_loss: 0.0099\n",
      "\n",
      "Epoch 02729: val_loss did not improve from 0.00328\n",
      "Epoch 2730/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.1305e-05 - val_loss: 0.0103\n",
      "\n",
      "Epoch 02730: val_loss did not improve from 0.00328\n",
      "Epoch 2731/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 98us/step - loss: 2.2255e-05 - val_loss: 0.0102\n",
      "\n",
      "Epoch 02731: val_loss did not improve from 0.00328\n",
      "Epoch 2732/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 1.9215e-05 - val_loss: 0.0103\n",
      "\n",
      "Epoch 02732: val_loss did not improve from 0.00328\n",
      "Epoch 2733/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 1.8605e-05 - val_loss: 0.0104\n",
      "\n",
      "Epoch 02733: val_loss did not improve from 0.00328\n",
      "Epoch 2734/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.0263e-05 - val_loss: 0.0100\n",
      "\n",
      "Epoch 02734: val_loss did not improve from 0.00328\n",
      "Epoch 2735/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.0818e-05 - val_loss: 0.0098\n",
      "\n",
      "Epoch 02735: val_loss did not improve from 0.00328\n",
      "Epoch 2736/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.1179e-05 - val_loss: 0.0099\n",
      "\n",
      "Epoch 02736: val_loss did not improve from 0.00328\n",
      "Epoch 2737/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 1.9194e-05 - val_loss: 0.0098\n",
      "\n",
      "Epoch 02737: val_loss did not improve from 0.00328\n",
      "Epoch 2738/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.2612e-05 - val_loss: 0.0097\n",
      "\n",
      "Epoch 02738: val_loss did not improve from 0.00328\n",
      "Epoch 2739/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.0282e-05 - val_loss: 0.0098\n",
      "\n",
      "Epoch 02739: val_loss did not improve from 0.00328\n",
      "Epoch 2740/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.1842e-05 - val_loss: 0.0099\n",
      "\n",
      "Epoch 02740: val_loss did not improve from 0.00328\n",
      "Epoch 2741/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 1.9310e-05 - val_loss: 0.0102\n",
      "\n",
      "Epoch 02741: val_loss did not improve from 0.00328\n",
      "Epoch 2742/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 1.9985e-05 - val_loss: 0.0102\n",
      "\n",
      "Epoch 02742: val_loss did not improve from 0.00328\n",
      "Epoch 2743/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.7315e-05 - val_loss: 0.0101\n",
      "\n",
      "Epoch 02743: val_loss did not improve from 0.00328\n",
      "Epoch 2744/3000\n",
      "184/184 [==============================] - 0s 163us/step - loss: 1.7472e-05 - val_loss: 0.0100\n",
      "\n",
      "Epoch 02744: val_loss did not improve from 0.00328\n",
      "Epoch 2745/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.0744e-05 - val_loss: 0.0100\n",
      "\n",
      "Epoch 02745: val_loss did not improve from 0.00328\n",
      "Epoch 2746/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.0505e-05 - val_loss: 0.0101\n",
      "\n",
      "Epoch 02746: val_loss did not improve from 0.00328\n",
      "Epoch 2747/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.0593e-05 - val_loss: 0.0105\n",
      "\n",
      "Epoch 02747: val_loss did not improve from 0.00328\n",
      "Epoch 2748/3000\n",
      "184/184 [==============================] - 0s 131us/step - loss: 2.9772e-05 - val_loss: 0.0102\n",
      "\n",
      "Epoch 02748: val_loss did not improve from 0.00328\n",
      "Epoch 2749/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.1448e-05 - val_loss: 0.0097\n",
      "\n",
      "Epoch 02749: val_loss did not improve from 0.00328\n",
      "Epoch 2750/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.3422e-05 - val_loss: 0.0100\n",
      "\n",
      "Epoch 02750: val_loss did not improve from 0.00328\n",
      "Epoch 2751/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.1915e-05 - val_loss: 0.0103\n",
      "\n",
      "Epoch 02751: val_loss did not improve from 0.00328\n",
      "Epoch 2752/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.4622e-05 - val_loss: 0.0096\n",
      "\n",
      "Epoch 02752: val_loss did not improve from 0.00328\n",
      "Epoch 2753/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.1275e-05 - val_loss: 0.0091\n",
      "\n",
      "Epoch 02753: val_loss did not improve from 0.00328\n",
      "Epoch 2754/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.0026e-05 - val_loss: 0.0092\n",
      "\n",
      "Epoch 02754: val_loss did not improve from 0.00328\n",
      "Epoch 2755/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.4358e-05 - val_loss: 0.0096\n",
      "\n",
      "Epoch 02755: val_loss did not improve from 0.00328\n",
      "Epoch 2756/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 1.7302e-05 - val_loss: 0.0094\n",
      "\n",
      "Epoch 02756: val_loss did not improve from 0.00328\n",
      "Epoch 2757/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 1.5296e-05 - val_loss: 0.0092\n",
      "\n",
      "Epoch 02757: val_loss did not improve from 0.00328\n",
      "Epoch 2758/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.4312e-05 - val_loss: 0.0095\n",
      "\n",
      "Epoch 02758: val_loss did not improve from 0.00328\n",
      "Epoch 2759/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.3561e-05 - val_loss: 0.0102\n",
      "\n",
      "Epoch 02759: val_loss did not improve from 0.00328\n",
      "Epoch 2760/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.2095e-05 - val_loss: 0.0105\n",
      "\n",
      "Epoch 02760: val_loss did not improve from 0.00328\n",
      "Epoch 2761/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.3084e-05 - val_loss: 0.0103\n",
      "\n",
      "Epoch 02761: val_loss did not improve from 0.00328\n",
      "Epoch 2762/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 1.8936e-05 - val_loss: 0.0100\n",
      "\n",
      "Epoch 02762: val_loss did not improve from 0.00328\n",
      "Epoch 2763/3000\n",
      "184/184 [==============================] - 0s 95us/step - loss: 2.1330e-05 - val_loss: 0.0100\n",
      "\n",
      "Epoch 02763: val_loss did not improve from 0.00328\n",
      "Epoch 2764/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.4679e-05 - val_loss: 0.0100\n",
      "\n",
      "Epoch 02764: val_loss did not improve from 0.00328\n",
      "Epoch 2765/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.0202e-05 - val_loss: 0.0100\n",
      "\n",
      "Epoch 02765: val_loss did not improve from 0.00328\n",
      "Epoch 2766/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.1222e-05 - val_loss: 0.0099\n",
      "\n",
      "Epoch 02766: val_loss did not improve from 0.00328\n",
      "Epoch 2767/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.5400e-05 - val_loss: 0.0095\n",
      "\n",
      "Epoch 02767: val_loss did not improve from 0.00328\n",
      "Epoch 2768/3000\n",
      "184/184 [==============================] - 0s 136us/step - loss: 1.9339e-05 - val_loss: 0.0096\n",
      "\n",
      "Epoch 02768: val_loss did not improve from 0.00328\n",
      "Epoch 2769/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.2029e-05 - val_loss: 0.0100\n",
      "\n",
      "Epoch 02769: val_loss did not improve from 0.00328\n",
      "Epoch 2770/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 1.8168e-05 - val_loss: 0.0102\n",
      "\n",
      "Epoch 02770: val_loss did not improve from 0.00328\n",
      "Epoch 2771/3000\n",
      "184/184 [==============================] - 0s 152us/step - loss: 2.6944e-05 - val_loss: 0.0102\n",
      "\n",
      "Epoch 02771: val_loss did not improve from 0.00328\n",
      "Epoch 2772/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 1.7664e-05 - val_loss: 0.0102\n",
      "\n",
      "Epoch 02772: val_loss did not improve from 0.00328\n",
      "Epoch 2773/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.5863e-05 - val_loss: 0.0103\n",
      "\n",
      "Epoch 02773: val_loss did not improve from 0.00328\n",
      "Epoch 2774/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 1.9867e-05 - val_loss: 0.0103\n",
      "\n",
      "Epoch 02774: val_loss did not improve from 0.00328\n",
      "Epoch 2775/3000\n",
      "184/184 [==============================] - 0s 139us/step - loss: 2.0920e-05 - val_loss: 0.0101\n",
      "\n",
      "Epoch 02775: val_loss did not improve from 0.00328\n",
      "Epoch 2776/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 1.9510e-05 - val_loss: 0.0099\n",
      "\n",
      "Epoch 02776: val_loss did not improve from 0.00328\n",
      "Epoch 2777/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.2490e-05 - val_loss: 0.0102\n",
      "\n",
      "Epoch 02777: val_loss did not improve from 0.00328\n",
      "Epoch 2778/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 1.8157e-05 - val_loss: 0.0106\n",
      "\n",
      "Epoch 02778: val_loss did not improve from 0.00328\n",
      "Epoch 2779/3000\n",
      "184/184 [==============================] - 0s 131us/step - loss: 2.4977e-05 - val_loss: 0.0101\n",
      "\n",
      "Epoch 02779: val_loss did not improve from 0.00328\n",
      "Epoch 2780/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.4152e-05 - val_loss: 0.0095\n",
      "\n",
      "Epoch 02780: val_loss did not improve from 0.00328\n",
      "Epoch 2781/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 131us/step - loss: 2.9975e-05 - val_loss: 0.0098\n",
      "\n",
      "Epoch 02781: val_loss did not improve from 0.00328\n",
      "Epoch 2782/3000\n",
      "184/184 [==============================] - 0s 141us/step - loss: 2.3931e-05 - val_loss: 0.0102\n",
      "\n",
      "Epoch 02782: val_loss did not improve from 0.00328\n",
      "Epoch 2783/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 1.9179e-05 - val_loss: 0.0098\n",
      "\n",
      "Epoch 02783: val_loss did not improve from 0.00328\n",
      "Epoch 2784/3000\n",
      "184/184 [==============================] - 0s 121us/step - loss: 2.4587e-05 - val_loss: 0.0093\n",
      "\n",
      "Epoch 02784: val_loss did not improve from 0.00328\n",
      "Epoch 2785/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.8430e-05 - val_loss: 0.0093\n",
      "\n",
      "Epoch 02785: val_loss did not improve from 0.00328\n",
      "Epoch 2786/3000\n",
      "184/184 [==============================] - ETA: 0s - loss: 1.3529e-0 - 0s 212us/step - loss: 2.4980e-05 - val_loss: 0.0100\n",
      "\n",
      "Epoch 02786: val_loss did not improve from 0.00328\n",
      "Epoch 2787/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.2603e-05 - val_loss: 0.0101\n",
      "\n",
      "Epoch 02787: val_loss did not improve from 0.00328\n",
      "Epoch 2788/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.3929e-05 - val_loss: 0.0100\n",
      "\n",
      "Epoch 02788: val_loss did not improve from 0.00328\n",
      "Epoch 2789/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.1936e-05 - val_loss: 0.0098\n",
      "\n",
      "Epoch 02789: val_loss did not improve from 0.00328\n",
      "Epoch 2790/3000\n",
      "184/184 [==============================] - 0s 119us/step - loss: 1.9245e-05 - val_loss: 0.0100\n",
      "\n",
      "Epoch 02790: val_loss did not improve from 0.00328\n",
      "Epoch 2791/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 1.7895e-05 - val_loss: 0.0106\n",
      "\n",
      "Epoch 02791: val_loss did not improve from 0.00328\n",
      "Epoch 2792/3000\n",
      "184/184 [==============================] - 0s 119us/step - loss: 2.2488e-05 - val_loss: 0.0106\n",
      "\n",
      "Epoch 02792: val_loss did not improve from 0.00328\n",
      "Epoch 2793/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 1.9727e-05 - val_loss: 0.0102\n",
      "\n",
      "Epoch 02793: val_loss did not improve from 0.00328\n",
      "Epoch 2794/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.3523e-05 - val_loss: 0.0099\n",
      "\n",
      "Epoch 02794: val_loss did not improve from 0.00328\n",
      "Epoch 2795/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.3246e-05 - val_loss: 0.0097\n",
      "\n",
      "Epoch 02795: val_loss did not improve from 0.00328\n",
      "Epoch 2796/3000\n",
      "184/184 [==============================] - 0s 136us/step - loss: 2.4564e-05 - val_loss: 0.0094\n",
      "\n",
      "Epoch 02796: val_loss did not improve from 0.00328\n",
      "Epoch 2797/3000\n",
      "184/184 [==============================] - 0s 130us/step - loss: 1.7967e-05 - val_loss: 0.0092\n",
      "\n",
      "Epoch 02797: val_loss did not improve from 0.00328\n",
      "Epoch 2798/3000\n",
      "184/184 [==============================] - 0s 196us/step - loss: 2.0170e-05 - val_loss: 0.0091\n",
      "\n",
      "Epoch 02798: val_loss did not improve from 0.00328\n",
      "Epoch 2799/3000\n",
      "184/184 [==============================] - 0s 212us/step - loss: 2.0786e-05 - val_loss: 0.0094\n",
      "\n",
      "Epoch 02799: val_loss did not improve from 0.00328\n",
      "Epoch 2800/3000\n",
      "184/184 [==============================] - 0s 141us/step - loss: 2.3355e-05 - val_loss: 0.0103\n",
      "\n",
      "Epoch 02800: val_loss did not improve from 0.00328\n",
      "Epoch 2801/3000\n",
      "184/184 [==============================] - 0s 147us/step - loss: 3.0749e-05 - val_loss: 0.0107\n",
      "\n",
      "Epoch 02801: val_loss did not improve from 0.00328\n",
      "Epoch 2802/3000\n",
      "184/184 [==============================] - 0s 147us/step - loss: 2.2707e-05 - val_loss: 0.0100\n",
      "\n",
      "Epoch 02802: val_loss did not improve from 0.00328\n",
      "Epoch 2803/3000\n",
      "184/184 [==============================] - 0s 152us/step - loss: 2.2318e-05 - val_loss: 0.0097\n",
      "\n",
      "Epoch 02803: val_loss did not improve from 0.00328\n",
      "Epoch 2804/3000\n",
      "184/184 [==============================] - 0s 147us/step - loss: 3.2212e-05 - val_loss: 0.0101\n",
      "\n",
      "Epoch 02804: val_loss did not improve from 0.00328\n",
      "Epoch 2805/3000\n",
      "184/184 [==============================] - 0s 130us/step - loss: 1.9294e-05 - val_loss: 0.0104\n",
      "\n",
      "Epoch 02805: val_loss did not improve from 0.00328\n",
      "Epoch 2806/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 1.9455e-05 - val_loss: 0.0103\n",
      "\n",
      "Epoch 02806: val_loss did not improve from 0.00328\n",
      "Epoch 2807/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.0953e-05 - val_loss: 0.0099\n",
      "\n",
      "Epoch 02807: val_loss did not improve from 0.00328\n",
      "Epoch 2808/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.5809e-05 - val_loss: 0.0098\n",
      "\n",
      "Epoch 02808: val_loss did not improve from 0.00328\n",
      "Epoch 2809/3000\n",
      "184/184 [==============================] - 0s 117us/step - loss: 2.5960e-05 - val_loss: 0.0100\n",
      "\n",
      "Epoch 02809: val_loss did not improve from 0.00328\n",
      "Epoch 2810/3000\n",
      "184/184 [==============================] - 0s 130us/step - loss: 1.9728e-05 - val_loss: 0.0099\n",
      "\n",
      "Epoch 02810: val_loss did not improve from 0.00328\n",
      "Epoch 2811/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.0697e-05 - val_loss: 0.0096\n",
      "\n",
      "Epoch 02811: val_loss did not improve from 0.00328\n",
      "Epoch 2812/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.1319e-05 - val_loss: 0.0094\n",
      "\n",
      "Epoch 02812: val_loss did not improve from 0.00328\n",
      "Epoch 2813/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.3037e-05 - val_loss: 0.0096\n",
      "\n",
      "Epoch 02813: val_loss did not improve from 0.00328\n",
      "Epoch 2814/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.3300e-05 - val_loss: 0.0100\n",
      "\n",
      "Epoch 02814: val_loss did not improve from 0.00328\n",
      "Epoch 2815/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.3773e-05 - val_loss: 0.0100\n",
      "\n",
      "Epoch 02815: val_loss did not improve from 0.00328\n",
      "Epoch 2816/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 2.1994e-05 - val_loss: 0.0097\n",
      "\n",
      "Epoch 02816: val_loss did not improve from 0.00328\n",
      "Epoch 2817/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.2074e-05 - val_loss: 0.0099\n",
      "\n",
      "Epoch 02817: val_loss did not improve from 0.00328\n",
      "Epoch 2818/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.4192e-05 - val_loss: 0.0104\n",
      "\n",
      "Epoch 02818: val_loss did not improve from 0.00328\n",
      "Epoch 2819/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 1.8010e-05 - val_loss: 0.0101\n",
      "\n",
      "Epoch 02819: val_loss did not improve from 0.00328\n",
      "Epoch 2820/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.1835e-05 - val_loss: 0.0099\n",
      "\n",
      "Epoch 02820: val_loss did not improve from 0.00328\n",
      "Epoch 2821/3000\n",
      "184/184 [==============================] - 0s 261us/step - loss: 2.1863e-05 - val_loss: 0.0101\n",
      "\n",
      "Epoch 02821: val_loss did not improve from 0.00328\n",
      "Epoch 2822/3000\n",
      "184/184 [==============================] - 0s 179us/step - loss: 2.9311e-05 - val_loss: 0.0101\n",
      "\n",
      "Epoch 02822: val_loss did not improve from 0.00328\n",
      "Epoch 2823/3000\n",
      "184/184 [==============================] - 0s 152us/step - loss: 2.0460e-05 - val_loss: 0.0099\n",
      "\n",
      "Epoch 02823: val_loss did not improve from 0.00328\n",
      "Epoch 2824/3000\n",
      "184/184 [==============================] - 0s 130us/step - loss: 2.3516e-05 - val_loss: 0.0099\n",
      "\n",
      "Epoch 02824: val_loss did not improve from 0.00328\n",
      "Epoch 2825/3000\n",
      "184/184 [==============================] - 0s 119us/step - loss: 2.4376e-05 - val_loss: 0.0099\n",
      "\n",
      "Epoch 02825: val_loss did not improve from 0.00328\n",
      "Epoch 2826/3000\n",
      "184/184 [==============================] - 0s 119us/step - loss: 1.5905e-05 - val_loss: 0.0100\n",
      "\n",
      "Epoch 02826: val_loss did not improve from 0.00328\n",
      "Epoch 2827/3000\n",
      "184/184 [==============================] - 0s 120us/step - loss: 2.1170e-05 - val_loss: 0.0100\n",
      "\n",
      "Epoch 02827: val_loss did not improve from 0.00328\n",
      "Epoch 2828/3000\n",
      "184/184 [==============================] - 0s 130us/step - loss: 2.4320e-05 - val_loss: 0.0101\n",
      "\n",
      "Epoch 02828: val_loss did not improve from 0.00328\n",
      "Epoch 2829/3000\n",
      "184/184 [==============================] - 0s 120us/step - loss: 2.5662e-05 - val_loss: 0.0103\n",
      "\n",
      "Epoch 02829: val_loss did not improve from 0.00328\n",
      "Epoch 2830/3000\n",
      "184/184 [==============================] - 0s 147us/step - loss: 2.0855e-05 - val_loss: 0.0101\n",
      "\n",
      "Epoch 02830: val_loss did not improve from 0.00328\n",
      "Epoch 2831/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 141us/step - loss: 2.3598e-05 - val_loss: 0.0099\n",
      "\n",
      "Epoch 02831: val_loss did not improve from 0.00328\n",
      "Epoch 2832/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.4171e-05 - val_loss: 0.0099\n",
      "\n",
      "Epoch 02832: val_loss did not improve from 0.00328\n",
      "Epoch 2833/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.2767e-05 - val_loss: 0.0100\n",
      "\n",
      "Epoch 02833: val_loss did not improve from 0.00328\n",
      "Epoch 2834/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 1.9549e-05 - val_loss: 0.0100\n",
      "\n",
      "Epoch 02834: val_loss did not improve from 0.00328\n",
      "Epoch 2835/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 1.7322e-05 - val_loss: 0.0097\n",
      "\n",
      "Epoch 02835: val_loss did not improve from 0.00328\n",
      "Epoch 2836/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.0963e-05 - val_loss: 0.0096\n",
      "\n",
      "Epoch 02836: val_loss did not improve from 0.00328\n",
      "Epoch 2837/3000\n",
      "184/184 [==============================] - 0s 130us/step - loss: 2.2274e-05 - val_loss: 0.0099\n",
      "\n",
      "Epoch 02837: val_loss did not improve from 0.00328\n",
      "Epoch 2838/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 1.6019e-05 - val_loss: 0.0102\n",
      "\n",
      "Epoch 02838: val_loss did not improve from 0.00328\n",
      "Epoch 2839/3000\n",
      "184/184 [==============================] - 0s 141us/step - loss: 2.1686e-05 - val_loss: 0.0103\n",
      "\n",
      "Epoch 02839: val_loss did not improve from 0.00328\n",
      "Epoch 2840/3000\n",
      "184/184 [==============================] - 0s 163us/step - loss: 1.9610e-05 - val_loss: 0.0103\n",
      "\n",
      "Epoch 02840: val_loss did not improve from 0.00328\n",
      "Epoch 2841/3000\n",
      "184/184 [==============================] - 0s 217us/step - loss: 2.3029e-05 - val_loss: 0.0104\n",
      "\n",
      "Epoch 02841: val_loss did not improve from 0.00328\n",
      "Epoch 2842/3000\n",
      "184/184 [==============================] - 0s 180us/step - loss: 2.2567e-05 - val_loss: 0.0101\n",
      "\n",
      "Epoch 02842: val_loss did not improve from 0.00328\n",
      "Epoch 2843/3000\n",
      "184/184 [==============================] - 0s 201us/step - loss: 2.2274e-05 - val_loss: 0.0097\n",
      "\n",
      "Epoch 02843: val_loss did not improve from 0.00328\n",
      "Epoch 2844/3000\n",
      "184/184 [==============================] - 0s 179us/step - loss: 2.2723e-05 - val_loss: 0.0096\n",
      "\n",
      "Epoch 02844: val_loss did not improve from 0.00328\n",
      "Epoch 2845/3000\n",
      "184/184 [==============================] - 0s 131us/step - loss: 1.8069e-05 - val_loss: 0.0097\n",
      "\n",
      "Epoch 02845: val_loss did not improve from 0.00328\n",
      "Epoch 2846/3000\n",
      "184/184 [==============================] - 0s 130us/step - loss: 2.2552e-05 - val_loss: 0.0100\n",
      "\n",
      "Epoch 02846: val_loss did not improve from 0.00328\n",
      "Epoch 2847/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 2.2773e-05 - val_loss: 0.0099\n",
      "\n",
      "Epoch 02847: val_loss did not improve from 0.00328\n",
      "Epoch 2848/3000\n",
      "184/184 [==============================] - 0s 152us/step - loss: 2.0651e-05 - val_loss: 0.0095\n",
      "\n",
      "Epoch 02848: val_loss did not improve from 0.00328\n",
      "Epoch 2849/3000\n",
      "184/184 [==============================] - 0s 136us/step - loss: 2.4781e-05 - val_loss: 0.0095\n",
      "\n",
      "Epoch 02849: val_loss did not improve from 0.00328\n",
      "Epoch 2850/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.5322e-05 - val_loss: 0.0100\n",
      "\n",
      "Epoch 02850: val_loss did not improve from 0.00328\n",
      "Epoch 2851/3000\n",
      "184/184 [==============================] - 0s 179us/step - loss: 1.8856e-05 - val_loss: 0.0101\n",
      "\n",
      "Epoch 02851: val_loss did not improve from 0.00328\n",
      "Epoch 2852/3000\n",
      "184/184 [==============================] - 0s 272us/step - loss: 1.7372e-05 - val_loss: 0.0098\n",
      "\n",
      "Epoch 02852: val_loss did not improve from 0.00328\n",
      "Epoch 2853/3000\n",
      "184/184 [==============================] - 0s 272us/step - loss: 3.0024e-05 - val_loss: 0.0095\n",
      "\n",
      "Epoch 02853: val_loss did not improve from 0.00328\n",
      "Epoch 2854/3000\n",
      "184/184 [==============================] - 0s 136us/step - loss: 2.2514e-05 - val_loss: 0.0095\n",
      "\n",
      "Epoch 02854: val_loss did not improve from 0.00328\n",
      "Epoch 2855/3000\n",
      "184/184 [==============================] - 0s 174us/step - loss: 2.5012e-05 - val_loss: 0.0098\n",
      "\n",
      "Epoch 02855: val_loss did not improve from 0.00328\n",
      "Epoch 2856/3000\n",
      "184/184 [==============================] - 0s 158us/step - loss: 1.9860e-05 - val_loss: 0.0098\n",
      "\n",
      "Epoch 02856: val_loss did not improve from 0.00328\n",
      "Epoch 2857/3000\n",
      "184/184 [==============================] - 0s 158us/step - loss: 2.0487e-05 - val_loss: 0.0097\n",
      "\n",
      "Epoch 02857: val_loss did not improve from 0.00328\n",
      "Epoch 2858/3000\n",
      "184/184 [==============================] - 0s 130us/step - loss: 2.1546e-05 - val_loss: 0.0097\n",
      "\n",
      "Epoch 02858: val_loss did not improve from 0.00328\n",
      "Epoch 2859/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 1.9859e-05 - val_loss: 0.0098\n",
      "\n",
      "Epoch 02859: val_loss did not improve from 0.00328\n",
      "Epoch 2860/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.3010e-05 - val_loss: 0.0097\n",
      "\n",
      "Epoch 02860: val_loss did not improve from 0.00328\n",
      "Epoch 2861/3000\n",
      "184/184 [==============================] - 0s 136us/step - loss: 1.7349e-05 - val_loss: 0.0096\n",
      "\n",
      "Epoch 02861: val_loss did not improve from 0.00328\n",
      "Epoch 2862/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.7984e-05 - val_loss: 0.0093\n",
      "\n",
      "Epoch 02862: val_loss did not improve from 0.00328\n",
      "Epoch 2863/3000\n",
      "184/184 [==============================] - 0s 141us/step - loss: 2.4545e-05 - val_loss: 0.0093\n",
      "\n",
      "Epoch 02863: val_loss did not improve from 0.00328\n",
      "Epoch 2864/3000\n",
      "184/184 [==============================] - 0s 130us/step - loss: 1.6579e-05 - val_loss: 0.0097\n",
      "\n",
      "Epoch 02864: val_loss did not improve from 0.00328\n",
      "Epoch 2865/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 1.8205e-05 - val_loss: 0.0100\n",
      "\n",
      "Epoch 02865: val_loss did not improve from 0.00328\n",
      "Epoch 2866/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.1395e-05 - val_loss: 0.0098\n",
      "\n",
      "Epoch 02866: val_loss did not improve from 0.00328\n",
      "Epoch 2867/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 1.8781e-05 - val_loss: 0.0097\n",
      "\n",
      "Epoch 02867: val_loss did not improve from 0.00328\n",
      "Epoch 2868/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 1.9990e-05 - val_loss: 0.0097\n",
      "\n",
      "Epoch 02868: val_loss did not improve from 0.00328\n",
      "Epoch 2869/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.1463e-05 - val_loss: 0.0100\n",
      "\n",
      "Epoch 02869: val_loss did not improve from 0.00328\n",
      "Epoch 2870/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.1795e-05 - val_loss: 0.0101\n",
      "\n",
      "Epoch 02870: val_loss did not improve from 0.00328\n",
      "Epoch 2871/3000\n",
      "184/184 [==============================] - 0s 120us/step - loss: 2.1834e-05 - val_loss: 0.0100\n",
      "\n",
      "Epoch 02871: val_loss did not improve from 0.00328\n",
      "Epoch 2872/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.1650e-05 - val_loss: 0.0098\n",
      "\n",
      "Epoch 02872: val_loss did not improve from 0.00328\n",
      "Epoch 2873/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.2479e-05 - val_loss: 0.0099\n",
      "\n",
      "Epoch 02873: val_loss did not improve from 0.00328\n",
      "Epoch 2874/3000\n",
      "184/184 [==============================] - 0s 115us/step - loss: 2.5745e-05 - val_loss: 0.0101\n",
      "\n",
      "Epoch 02874: val_loss did not improve from 0.00328\n",
      "Epoch 2875/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.1426e-05 - val_loss: 0.0100\n",
      "\n",
      "Epoch 02875: val_loss did not improve from 0.00328\n",
      "Epoch 2876/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 1.8824e-05 - val_loss: 0.0099\n",
      "\n",
      "Epoch 02876: val_loss did not improve from 0.00328\n",
      "Epoch 2877/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.3210e-05 - val_loss: 0.0099\n",
      "\n",
      "Epoch 02877: val_loss did not improve from 0.00328\n",
      "Epoch 2878/3000\n",
      "184/184 [==============================] - 0s 106us/step - loss: 2.4930e-05 - val_loss: 0.0097\n",
      "\n",
      "Epoch 02878: val_loss did not improve from 0.00328\n",
      "Epoch 2879/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.0619e-05 - val_loss: 0.0095\n",
      "\n",
      "Epoch 02879: val_loss did not improve from 0.00328\n",
      "Epoch 2880/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 1.8743e-05 - val_loss: 0.0095\n",
      "\n",
      "Epoch 02880: val_loss did not improve from 0.00328\n",
      "Epoch 2881/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 103us/step - loss: 2.1058e-05 - val_loss: 0.0096\n",
      "\n",
      "Epoch 02881: val_loss did not improve from 0.00328\n",
      "Epoch 2882/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 2.3000e-05 - val_loss: 0.0098\n",
      "\n",
      "Epoch 02882: val_loss did not improve from 0.00328\n",
      "Epoch 2883/3000\n",
      "184/184 [==============================] - 0s 152us/step - loss: 2.1066e-05 - val_loss: 0.0098\n",
      "\n",
      "Epoch 02883: val_loss did not improve from 0.00328\n",
      "Epoch 2884/3000\n",
      "184/184 [==============================] - 0s 120us/step - loss: 2.0292e-05 - val_loss: 0.0099\n",
      "\n",
      "Epoch 02884: val_loss did not improve from 0.00328\n",
      "Epoch 2885/3000\n",
      "184/184 [==============================] - 0s 147us/step - loss: 1.9857e-05 - val_loss: 0.0100\n",
      "\n",
      "Epoch 02885: val_loss did not improve from 0.00328\n",
      "Epoch 2886/3000\n",
      "184/184 [==============================] - 0s 168us/step - loss: 2.4430e-05 - val_loss: 0.0101\n",
      "\n",
      "Epoch 02886: val_loss did not improve from 0.00328\n",
      "Epoch 2887/3000\n",
      "184/184 [==============================] - 0s 141us/step - loss: 2.1012e-05 - val_loss: 0.0102\n",
      "\n",
      "Epoch 02887: val_loss did not improve from 0.00328\n",
      "Epoch 2888/3000\n",
      "184/184 [==============================] - 0s 147us/step - loss: 2.0087e-05 - val_loss: 0.0101\n",
      "\n",
      "Epoch 02888: val_loss did not improve from 0.00328\n",
      "Epoch 2889/3000\n",
      "184/184 [==============================] - 0s 152us/step - loss: 2.4868e-05 - val_loss: 0.0099\n",
      "\n",
      "Epoch 02889: val_loss did not improve from 0.00328\n",
      "Epoch 2890/3000\n",
      "184/184 [==============================] - 0s 130us/step - loss: 2.2473e-05 - val_loss: 0.0098\n",
      "\n",
      "Epoch 02890: val_loss did not improve from 0.00328\n",
      "Epoch 2891/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.1472e-05 - val_loss: 0.0099\n",
      "\n",
      "Epoch 02891: val_loss did not improve from 0.00328\n",
      "Epoch 2892/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.2447e-05 - val_loss: 0.0101\n",
      "\n",
      "Epoch 02892: val_loss did not improve from 0.00328\n",
      "Epoch 2893/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.3134e-05 - val_loss: 0.0102\n",
      "\n",
      "Epoch 02893: val_loss did not improve from 0.00328\n",
      "Epoch 2894/3000\n",
      "184/184 [==============================] - 0s 120us/step - loss: 2.0936e-05 - val_loss: 0.0100\n",
      "\n",
      "Epoch 02894: val_loss did not improve from 0.00328\n",
      "Epoch 2895/3000\n",
      "184/184 [==============================] - 0s 119us/step - loss: 2.1907e-05 - val_loss: 0.0099\n",
      "\n",
      "Epoch 02895: val_loss did not improve from 0.00328\n",
      "Epoch 2896/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.2002e-05 - val_loss: 0.0099\n",
      "\n",
      "Epoch 02896: val_loss did not improve from 0.00328\n",
      "Epoch 2897/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.1423e-05 - val_loss: 0.0098\n",
      "\n",
      "Epoch 02897: val_loss did not improve from 0.00328\n",
      "Epoch 2898/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.6431e-05 - val_loss: 0.0099\n",
      "\n",
      "Epoch 02898: val_loss did not improve from 0.00328\n",
      "Epoch 2899/3000\n",
      "184/184 [==============================] - 0s 141us/step - loss: 2.1639e-05 - val_loss: 0.0098\n",
      "\n",
      "Epoch 02899: val_loss did not improve from 0.00328\n",
      "Epoch 2900/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.1296e-05 - val_loss: 0.0100\n",
      "\n",
      "Epoch 02900: val_loss did not improve from 0.00328\n",
      "Epoch 2901/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.2345e-05 - val_loss: 0.0103\n",
      "\n",
      "Epoch 02901: val_loss did not improve from 0.00328\n",
      "Epoch 2902/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.4890e-05 - val_loss: 0.0104\n",
      "\n",
      "Epoch 02902: val_loss did not improve from 0.00328\n",
      "Epoch 2903/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.6576e-05 - val_loss: 0.0100\n",
      "\n",
      "Epoch 02903: val_loss did not improve from 0.00328\n",
      "Epoch 2904/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.3567e-05 - val_loss: 0.0099\n",
      "\n",
      "Epoch 02904: val_loss did not improve from 0.00328\n",
      "Epoch 2905/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 1.9595e-05 - val_loss: 0.0100\n",
      "\n",
      "Epoch 02905: val_loss did not improve from 0.00328\n",
      "Epoch 2906/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.8433e-05 - val_loss: 0.0104\n",
      "\n",
      "Epoch 02906: val_loss did not improve from 0.00328\n",
      "Epoch 2907/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.4175e-05 - val_loss: 0.0104\n",
      "\n",
      "Epoch 02907: val_loss did not improve from 0.00328\n",
      "Epoch 2908/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 1.7555e-05 - val_loss: 0.0100\n",
      "\n",
      "Epoch 02908: val_loss did not improve from 0.00328\n",
      "Epoch 2909/3000\n",
      "184/184 [==============================] - 0s 130us/step - loss: 2.2386e-05 - val_loss: 0.0097\n",
      "\n",
      "Epoch 02909: val_loss did not improve from 0.00328\n",
      "Epoch 2910/3000\n",
      "184/184 [==============================] - 0s 174us/step - loss: 2.3930e-05 - val_loss: 0.0097\n",
      "\n",
      "Epoch 02910: val_loss did not improve from 0.00328\n",
      "Epoch 2911/3000\n",
      "184/184 [==============================] - 0s 120us/step - loss: 1.9499e-05 - val_loss: 0.0097\n",
      "\n",
      "Epoch 02911: val_loss did not improve from 0.00328\n",
      "Epoch 2912/3000\n",
      "184/184 [==============================] - 0s 147us/step - loss: 1.8053e-05 - val_loss: 0.0097\n",
      "\n",
      "Epoch 02912: val_loss did not improve from 0.00328\n",
      "Epoch 2913/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.3715e-05 - val_loss: 0.0098\n",
      "\n",
      "Epoch 02913: val_loss did not improve from 0.00328\n",
      "Epoch 2914/3000\n",
      "184/184 [==============================] - 0s 158us/step - loss: 1.8554e-05 - val_loss: 0.0098\n",
      "\n",
      "Epoch 02914: val_loss did not improve from 0.00328\n",
      "Epoch 2915/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.1206e-05 - val_loss: 0.0099\n",
      "\n",
      "Epoch 02915: val_loss did not improve from 0.00328\n",
      "Epoch 2916/3000\n",
      "184/184 [==============================] - 0s 131us/step - loss: 2.0913e-05 - val_loss: 0.0102\n",
      "\n",
      "Epoch 02916: val_loss did not improve from 0.00328\n",
      "Epoch 2917/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.1913e-05 - val_loss: 0.0102\n",
      "\n",
      "Epoch 02917: val_loss did not improve from 0.00328\n",
      "Epoch 2918/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.1570e-05 - val_loss: 0.0105\n",
      "\n",
      "Epoch 02918: val_loss did not improve from 0.00328\n",
      "Epoch 2919/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.3138e-05 - val_loss: 0.0104\n",
      "\n",
      "Epoch 02919: val_loss did not improve from 0.00328\n",
      "Epoch 2920/3000\n",
      "184/184 [==============================] - 0s 120us/step - loss: 2.0516e-05 - val_loss: 0.0099\n",
      "\n",
      "Epoch 02920: val_loss did not improve from 0.00328\n",
      "Epoch 2921/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.4381e-05 - val_loss: 0.0097\n",
      "\n",
      "Epoch 02921: val_loss did not improve from 0.00328\n",
      "Epoch 2922/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.0233e-05 - val_loss: 0.0101\n",
      "\n",
      "Epoch 02922: val_loss did not improve from 0.00328\n",
      "Epoch 2923/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.5618e-05 - val_loss: 0.0099\n",
      "\n",
      "Epoch 02923: val_loss did not improve from 0.00328\n",
      "Epoch 2924/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.1667e-05 - val_loss: 0.0097\n",
      "\n",
      "Epoch 02924: val_loss did not improve from 0.00328\n",
      "Epoch 2925/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 2.2774e-05 - val_loss: 0.0098\n",
      "\n",
      "Epoch 02925: val_loss did not improve from 0.00328\n",
      "Epoch 2926/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 1.6115e-05 - val_loss: 0.0101\n",
      "\n",
      "Epoch 02926: val_loss did not improve from 0.00328\n",
      "Epoch 2927/3000\n",
      "184/184 [==============================] - 0s 111us/step - loss: 2.1112e-05 - val_loss: 0.0101\n",
      "\n",
      "Epoch 02927: val_loss did not improve from 0.00328\n",
      "Epoch 2928/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.1784e-05 - val_loss: 0.0098\n",
      "\n",
      "Epoch 02928: val_loss did not improve from 0.00328\n",
      "Epoch 2929/3000\n",
      "184/184 [==============================] - 0s 163us/step - loss: 2.3555e-05 - val_loss: 0.0100\n",
      "\n",
      "Epoch 02929: val_loss did not improve from 0.00328\n",
      "Epoch 2930/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.1473e-05 - val_loss: 0.0104\n",
      "\n",
      "Epoch 02930: val_loss did not improve from 0.00328\n",
      "Epoch 2931/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 98us/step - loss: 1.9142e-05 - val_loss: 0.0107\n",
      "\n",
      "Epoch 02931: val_loss did not improve from 0.00328\n",
      "Epoch 2932/3000\n",
      "184/184 [==============================] - 0s 119us/step - loss: 1.5933e-05 - val_loss: 0.0107\n",
      "\n",
      "Epoch 02932: val_loss did not improve from 0.00328\n",
      "Epoch 2933/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 1.6641e-05 - val_loss: 0.0107\n",
      "\n",
      "Epoch 02933: val_loss did not improve from 0.00328\n",
      "Epoch 2934/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 1.9867e-05 - val_loss: 0.0107\n",
      "\n",
      "Epoch 02934: val_loss did not improve from 0.00328\n",
      "Epoch 2935/3000\n",
      "184/184 [==============================] - 0s 117us/step - loss: 1.9717e-05 - val_loss: 0.0108\n",
      "\n",
      "Epoch 02935: val_loss did not improve from 0.00328\n",
      "Epoch 2936/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.0070e-05 - val_loss: 0.0108\n",
      "\n",
      "Epoch 02936: val_loss did not improve from 0.00328\n",
      "Epoch 2937/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.1944e-05 - val_loss: 0.0103\n",
      "\n",
      "Epoch 02937: val_loss did not improve from 0.00328\n",
      "Epoch 2938/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 2.3548e-05 - val_loss: 0.0102\n",
      "\n",
      "Epoch 02938: val_loss did not improve from 0.00328\n",
      "Epoch 2939/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.3195e-05 - val_loss: 0.0105\n",
      "\n",
      "Epoch 02939: val_loss did not improve from 0.00328\n",
      "Epoch 2940/3000\n",
      "184/184 [==============================] - 0s 119us/step - loss: 2.3421e-05 - val_loss: 0.0104\n",
      "\n",
      "Epoch 02940: val_loss did not improve from 0.00328\n",
      "Epoch 2941/3000\n",
      "184/184 [==============================] - 0s 119us/step - loss: 2.3244e-05 - val_loss: 0.0099\n",
      "\n",
      "Epoch 02941: val_loss did not improve from 0.00328\n",
      "Epoch 2942/3000\n",
      "184/184 [==============================] - 0s 131us/step - loss: 2.4469e-05 - val_loss: 0.0101\n",
      "\n",
      "Epoch 02942: val_loss did not improve from 0.00328\n",
      "Epoch 2943/3000\n",
      "184/184 [==============================] - 0s 174us/step - loss: 1.8862e-05 - val_loss: 0.0107\n",
      "\n",
      "Epoch 02943: val_loss did not improve from 0.00328\n",
      "Epoch 2944/3000\n",
      "184/184 [==============================] - 0s 141us/step - loss: 1.8206e-05 - val_loss: 0.0107\n",
      "\n",
      "Epoch 02944: val_loss did not improve from 0.00328\n",
      "Epoch 2945/3000\n",
      "184/184 [==============================] - 0s 119us/step - loss: 2.2642e-05 - val_loss: 0.0108\n",
      "\n",
      "Epoch 02945: val_loss did not improve from 0.00328\n",
      "Epoch 2946/3000\n",
      "184/184 [==============================] - 0s 120us/step - loss: 1.8455e-05 - val_loss: 0.0107\n",
      "\n",
      "Epoch 02946: val_loss did not improve from 0.00328\n",
      "Epoch 2947/3000\n",
      "184/184 [==============================] - 0s 130us/step - loss: 1.9068e-05 - val_loss: 0.0104\n",
      "\n",
      "Epoch 02947: val_loss did not improve from 0.00328\n",
      "Epoch 2948/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 1.8919e-05 - val_loss: 0.0104\n",
      "\n",
      "Epoch 02948: val_loss did not improve from 0.00328\n",
      "Epoch 2949/3000\n",
      "184/184 [==============================] - 0s 158us/step - loss: 2.0658e-05 - val_loss: 0.0107\n",
      "\n",
      "Epoch 02949: val_loss did not improve from 0.00328\n",
      "Epoch 2950/3000\n",
      "184/184 [==============================] - 0s 152us/step - loss: 2.2170e-05 - val_loss: 0.0104\n",
      "\n",
      "Epoch 02950: val_loss did not improve from 0.00328\n",
      "Epoch 2951/3000\n",
      "184/184 [==============================] - 0s 144us/step - loss: 2.4102e-05 - val_loss: 0.0101\n",
      "\n",
      "Epoch 02951: val_loss did not improve from 0.00328\n",
      "Epoch 2952/3000\n",
      "184/184 [==============================] - 0s 141us/step - loss: 1.7979e-05 - val_loss: 0.0103\n",
      "\n",
      "Epoch 02952: val_loss did not improve from 0.00328\n",
      "Epoch 2953/3000\n",
      "184/184 [==============================] - 0s 120us/step - loss: 2.1956e-05 - val_loss: 0.0104\n",
      "\n",
      "Epoch 02953: val_loss did not improve from 0.00328\n",
      "Epoch 2954/3000\n",
      "184/184 [==============================] - 0s 130us/step - loss: 2.3440e-05 - val_loss: 0.0105\n",
      "\n",
      "Epoch 02954: val_loss did not improve from 0.00328\n",
      "Epoch 2955/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 2.2024e-05 - val_loss: 0.0106\n",
      "\n",
      "Epoch 02955: val_loss did not improve from 0.00328\n",
      "Epoch 2956/3000\n",
      "184/184 [==============================] - 0s 119us/step - loss: 2.0329e-05 - val_loss: 0.0104\n",
      "\n",
      "Epoch 02956: val_loss did not improve from 0.00328\n",
      "Epoch 2957/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.5472e-05 - val_loss: 0.0104\n",
      "\n",
      "Epoch 02957: val_loss did not improve from 0.00328\n",
      "Epoch 2958/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 1.7717e-05 - val_loss: 0.0109\n",
      "\n",
      "Epoch 02958: val_loss did not improve from 0.00328\n",
      "Epoch 2959/3000\n",
      "184/184 [==============================] - 0s 136us/step - loss: 2.6197e-05 - val_loss: 0.0110\n",
      "\n",
      "Epoch 02959: val_loss did not improve from 0.00328\n",
      "Epoch 2960/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.1930e-05 - val_loss: 0.0106\n",
      "\n",
      "Epoch 02960: val_loss did not improve from 0.00328\n",
      "Epoch 2961/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.1984e-05 - val_loss: 0.0104\n",
      "\n",
      "Epoch 02961: val_loss did not improve from 0.00328\n",
      "Epoch 2962/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.6782e-05 - val_loss: 0.0103\n",
      "\n",
      "Epoch 02962: val_loss did not improve from 0.00328\n",
      "Epoch 2963/3000\n",
      "184/184 [==============================] - 0s 119us/step - loss: 2.0023e-05 - val_loss: 0.0104\n",
      "\n",
      "Epoch 02963: val_loss did not improve from 0.00328\n",
      "Epoch 2964/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 1.8951e-05 - val_loss: 0.0107\n",
      "\n",
      "Epoch 02964: val_loss did not improve from 0.00328\n",
      "Epoch 2965/3000\n",
      "184/184 [==============================] - 0s 761us/step - loss: 1.8744e-05 - val_loss: 0.0107\n",
      "\n",
      "Epoch 02965: val_loss did not improve from 0.00328\n",
      "Epoch 2966/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.3322e-05 - val_loss: 0.0101\n",
      "\n",
      "Epoch 02966: val_loss did not improve from 0.00328\n",
      "Epoch 2967/3000\n",
      "184/184 [==============================] - 0s 120us/step - loss: 2.6998e-05 - val_loss: 0.0099\n",
      "\n",
      "Epoch 02967: val_loss did not improve from 0.00328\n",
      "Epoch 2968/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.5178e-05 - val_loss: 0.0106\n",
      "\n",
      "Epoch 02968: val_loss did not improve from 0.00328\n",
      "Epoch 2969/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.0876e-05 - val_loss: 0.0108\n",
      "\n",
      "Epoch 02969: val_loss did not improve from 0.00328\n",
      "Epoch 2970/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.3847e-05 - val_loss: 0.0102\n",
      "\n",
      "Epoch 02970: val_loss did not improve from 0.00328\n",
      "Epoch 2971/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.9910e-05 - val_loss: 0.0098\n",
      "\n",
      "Epoch 02971: val_loss did not improve from 0.00328\n",
      "Epoch 2972/3000\n",
      "184/184 [==============================] - 0s 120us/step - loss: 2.9719e-05 - val_loss: 0.0102\n",
      "\n",
      "Epoch 02972: val_loss did not improve from 0.00328\n",
      "Epoch 2973/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.0845e-05 - val_loss: 0.0106\n",
      "\n",
      "Epoch 02973: val_loss did not improve from 0.00328\n",
      "Epoch 2974/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.6004e-05 - val_loss: 0.0104\n",
      "\n",
      "Epoch 02974: val_loss did not improve from 0.00328\n",
      "Epoch 2975/3000\n",
      "184/184 [==============================] - 0s 130us/step - loss: 2.1453e-05 - val_loss: 0.0100\n",
      "\n",
      "Epoch 02975: val_loss did not improve from 0.00328\n",
      "Epoch 2976/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 3.2305e-05 - val_loss: 0.0100\n",
      "\n",
      "Epoch 02976: val_loss did not improve from 0.00328\n",
      "Epoch 2977/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 2.2282e-05 - val_loss: 0.0108\n",
      "\n",
      "Epoch 02977: val_loss did not improve from 0.00328\n",
      "Epoch 2978/3000\n",
      "184/184 [==============================] - 0s 109us/step - loss: 2.7104e-05 - val_loss: 0.0111\n",
      "\n",
      "Epoch 02978: val_loss did not improve from 0.00328\n",
      "Epoch 2979/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.4943e-05 - val_loss: 0.0105\n",
      "\n",
      "Epoch 02979: val_loss did not improve from 0.00328\n",
      "Epoch 2980/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.0011e-05 - val_loss: 0.0102\n",
      "\n",
      "Epoch 02980: val_loss did not improve from 0.00328\n",
      "Epoch 2981/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184/184 [==============================] - 0s 103us/step - loss: 1.9847e-05 - val_loss: 0.0107\n",
      "\n",
      "Epoch 02981: val_loss did not improve from 0.00328\n",
      "Epoch 2982/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 1.5981e-05 - val_loss: 0.0113\n",
      "\n",
      "Epoch 02982: val_loss did not improve from 0.00328\n",
      "Epoch 2983/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.9460e-05 - val_loss: 0.0111\n",
      "\n",
      "Epoch 02983: val_loss did not improve from 0.00328\n",
      "Epoch 2984/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.3093e-05 - val_loss: 0.0103\n",
      "\n",
      "Epoch 02984: val_loss did not improve from 0.00328\n",
      "Epoch 2985/3000\n",
      "184/184 [==============================] - 0s 141us/step - loss: 2.7487e-05 - val_loss: 0.0101\n",
      "\n",
      "Epoch 02985: val_loss did not improve from 0.00328\n",
      "Epoch 2986/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.3724e-05 - val_loss: 0.0101\n",
      "\n",
      "Epoch 02986: val_loss did not improve from 0.00328\n",
      "Epoch 2987/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 1.6195e-05 - val_loss: 0.0102\n",
      "\n",
      "Epoch 02987: val_loss did not improve from 0.00328\n",
      "Epoch 2988/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 2.0732e-05 - val_loss: 0.0099\n",
      "\n",
      "Epoch 02988: val_loss did not improve from 0.00328\n",
      "Epoch 2989/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 1.9807e-05 - val_loss: 0.0098\n",
      "\n",
      "Epoch 02989: val_loss did not improve from 0.00328\n",
      "Epoch 2990/3000\n",
      "184/184 [==============================] - 0s 120us/step - loss: 2.2611e-05 - val_loss: 0.0099\n",
      "\n",
      "Epoch 02990: val_loss did not improve from 0.00328\n",
      "Epoch 2991/3000\n",
      "184/184 [==============================] - 0s 125us/step - loss: 2.4894e-05 - val_loss: 0.0100\n",
      "\n",
      "Epoch 02991: val_loss did not improve from 0.00328\n",
      "Epoch 2992/3000\n",
      "184/184 [==============================] - 0s 114us/step - loss: 1.9218e-05 - val_loss: 0.0100\n",
      "\n",
      "Epoch 02992: val_loss did not improve from 0.00328\n",
      "Epoch 2993/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.1903e-05 - val_loss: 0.0099\n",
      "\n",
      "Epoch 02993: val_loss did not improve from 0.00328\n",
      "Epoch 2994/3000\n",
      "184/184 [==============================] - 0s 92us/step - loss: 1.9765e-05 - val_loss: 0.0101\n",
      "\n",
      "Epoch 02994: val_loss did not improve from 0.00328\n",
      "Epoch 2995/3000\n",
      "184/184 [==============================] - 0s 103us/step - loss: 2.5419e-05 - val_loss: 0.0107\n",
      "\n",
      "Epoch 02995: val_loss did not improve from 0.00328\n",
      "Epoch 2996/3000\n",
      "184/184 [==============================] - 0s 98us/step - loss: 2.2002e-05 - val_loss: 0.0109\n",
      "\n",
      "Epoch 02996: val_loss did not improve from 0.00328\n",
      "Epoch 2997/3000\n",
      "184/184 [==============================] - 0s 93us/step - loss: 1.9654e-05 - val_loss: 0.0105\n",
      "\n",
      "Epoch 02997: val_loss did not improve from 0.00328\n",
      "Epoch 2998/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.2234e-05 - val_loss: 0.0103\n",
      "\n",
      "Epoch 02998: val_loss did not improve from 0.00328\n",
      "Epoch 2999/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 2.1198e-05 - val_loss: 0.0104\n",
      "\n",
      "Epoch 02999: val_loss did not improve from 0.00328\n",
      "Epoch 3000/3000\n",
      "184/184 [==============================] - 0s 87us/step - loss: 1.8250e-05 - val_loss: 0.0106\n",
      "\n",
      "Epoch 03000: val_loss did not improve from 0.00328\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 50)                14200     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 14,251\n",
      "Trainable params: 14,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "filepath = './model_epoch_{epoch:02d}.hdf5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath = filepath,\n",
    "                             monitor='val_loss',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True,\n",
    "                             mode='min')\n",
    "history = model.fit(X_train, Y_train, epochs=3000, batch_size=80, validation_data=(X_test, Y_test),\n",
    "                   callbacks=[checkpoint], verbose=1, shuffle=False)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why we chose the model at epoch 89"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model at epoch 89 had the most similar training and validation losses, which implies that the model is not doing a lot of over or under fitting. As such, we load that model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "best_model = load_model('./model_epoch_89.hdf5')\n",
    "\n",
    "# Predicting and inverse transforming the predictions\n",
    "\n",
    "train_predict = best_model.predict(X_train)\n",
    "\n",
    "Y_hat_train = scaler.inverse_transform(train_predict)\n",
    "\n",
    "test_predict = best_model.predict(X_test)\n",
    "\n",
    "Y_hat_test = scaler.inverse_transform(test_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inverse transforming the actual values, to return them to their original values\n",
    "Y_test = scaler.inverse_transform([Y_test])\n",
    "Y_train = scaler.inverse_transform([Y_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_hat_train = np.reshape(Y_hat_train, newshape = 184)\n",
    "Y_hat_test = np.reshape(Y_hat_test, newshape = 31)\n",
    "\n",
    "Y_train = np.reshape(Y_train, newshape = 184)\n",
    "Y_test = np.reshape(Y_test, newshape = 31)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Model Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing the RMSE for the training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE is: \n",
      "0.9940331207194725 \n",
      "\n",
      "Test RMSE is: \n",
      "11.993337517298645\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "train_RMSE = np.sqrt(mean_squared_error(Y_train, Y_hat_train))\n",
    "\n",
    "test_RMSE = np.sqrt(mean_squared_error(Y_test, Y_hat_test))\n",
    "\n",
    "print('Train RMSE is: ')\n",
    "print(train_RMSE, '\\n')\n",
    "print('Test RMSE is: ')\n",
    "print(test_RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the actual vs. predicted stock prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.append(Y_train, Y_test)\n",
    "Y_hat = np.append(Y_hat_train, Y_hat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual_Y</th>\n",
       "      <th>Predicted_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.15</td>\n",
       "      <td>4.566595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.14</td>\n",
       "      <td>4.543998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.04</td>\n",
       "      <td>4.536726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.70</td>\n",
       "      <td>4.512764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.56</td>\n",
       "      <td>4.473363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Actual_Y  Predicted_Y\n",
       "0      4.15     4.566595\n",
       "1      4.14     4.543998\n",
       "2      4.04     4.536726\n",
       "3      3.70     4.512764\n",
       "4      3.56     4.473363"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = pd.DataFrame()\n",
    "\n",
    "result_df['Actual_Y'] = Y\n",
    "result_df['Predicted_Y'] = Y_hat\n",
    "\n",
    "\n",
    "result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (12,6))\n",
    "plt.plot(result_df[\"Actual_Y\"],linewidth=2.0,label = \"Actual\")\n",
    "plt.plot(result_df[\"Predicted_Y\"],linewidth=2.0, label = \"Predicted\")\n",
    "plt.rcParams.update({'font.size': 13})\n",
    "plt.legend(loc=\"upper left\", bbox_to_anchor=(0.03,1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
